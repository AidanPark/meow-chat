"""ëƒ¥ë‹¥í„° (Meow Chat) - ê³ ì–‘ì´ ê±´ê°•ê²€ì§„ OCR ì±—ë´‡

ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ - Step 5: ìŠ¤ëª°í†¡ + ë‹¨ê¸° ë©”ëª¨ë¦¬ + ì˜ë„ë¶„ì„ + OCR + ê²€ì‚¬ ë¶„ì„
st.write_stream()ì„ ì‚¬ìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ë©€í‹°í„´ ëŒ€í™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
ì‚¬ìš©ì ì…ë ¥ì—ì„œ 'ê²€ì‚¬ ë¶„ì„ ìš”ì²­' ì˜ë„ë¥¼ ê°ì§€í•˜ì—¬ í™•ì¸ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
ê²€ì§„ ê²°ê³¼ì§€ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ OCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”ëœ í…Œì´ë¸”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ë§ì¶¤í˜• ê±´ê°• ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path

import streamlit as st
import pandas as pd

# src ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
ROOT_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT_DIR))

from src.services.llm.base import Message
from src.services.llm.factory import get_llm_service
from src.services.ocr.factory import get_ocr_service
from src.services.lab_extraction import LabTableExtractor
from src.services.lab_extraction.line_preprocessor import LinePreprocessor
from src.settings import settings
from src.utils.images import load_image_from_bytes, resize_image
from src.utils.pdf import is_pdf, pdf_bytes_to_images

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ëƒ¥ë‹¥í„° ğŸ± - ê³ ì–‘ì´ ê±´ê°•ê²€ì§„ ì±—ë´‡",
    page_icon="ğŸ±",
    layout="centered",
    initial_sidebar_state="expanded",
)

# ë‹¨ê¸° ë©”ëª¨ë¦¬ ì„¤ì •
MAX_HISTORY_TURNS = 20  # ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (user+assistant í•©ì³ì„œ)

# Step 3: ì˜ë„ë¶„ì„ í‚¤ì›Œë“œ ì„¤ì •
ANALYSIS_INTENT_KEYWORDS = [
    "ë¶„ì„", "í•´ì„", "ê²€ì‚¬ê²°ê³¼", "ê±´ê°•ê²€ì§„", "í˜ˆì•¡ê²€ì‚¬",
    "ê²°ê³¼ì§€", "ê²€ì§„", "ìˆ˜ì¹˜", "ì •ìƒë²”ìœ„", "ì´ìƒ",
    "ê²€ì‚¬", "ì§„ë‹¨", "íŒë…", "ë¦¬í¬íŠ¸", "ê²°ê³¼"
]


def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "llm_service" not in st.session_state:
        try:
            st.session_state.llm_service = get_llm_service()
            st.session_state.llm_error = None
        except Exception as e:
            st.session_state.llm_service = None
            st.session_state.llm_error = str(e)

    if "ocr_service" not in st.session_state:
        try:
            st.session_state.ocr_service = get_ocr_service()
            st.session_state.ocr_error = None
        except Exception as e:
            st.session_state.ocr_service = None
            st.session_state.ocr_error = str(e)

    if "line_preprocessor" not in st.session_state:
        try:
            st.session_state.line_preprocessor = LinePreprocessor()
        except Exception:
            st.session_state.line_preprocessor = None

    if "lab_extractor" not in st.session_state:
        try:
            st.session_state.lab_extractor = LabTableExtractor()
        except Exception:
            st.session_state.lab_extractor = None

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Step 3: ë¶„ì„ ëª¨ë“œ ìƒíƒœ
    if "analysis_mode_pending" not in st.session_state:
        st.session_state.analysis_mode_pending = False

    # Step 4: OCR ê²°ê³¼ ì €ì¥
    if "ocr_text" not in st.session_state:
        st.session_state.ocr_text = None

    if "ocr_structured" not in st.session_state:
        st.session_state.ocr_structured = None

    if "ocr_debug_output" not in st.session_state:
        st.session_state.ocr_debug_output = None

    if "uploaded_image" not in st.session_state:
        st.session_state.uploaded_image = None


def display_chat_history():
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])


def get_system_prompt() -> str:
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì¼ë°˜ ìŠ¤ëª°í†¡ìš©)"""
    return """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê°ì ì¸ ê³ ì–‘ì´ ê±´ê°• ìƒë‹´ ë„ìš°ë¯¸ 'ëƒ¥ë‹¥í„°'ì…ë‹ˆë‹¤.

ê¸°ë³¸ ì„±ê²©:
- ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤
- ê³ ì–‘ì´ì™€ ë°˜ë ¤ë™ë¬¼ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •ì„±ê» ë‹µë³€í•©ë‹ˆë‹¤

ì¤‘ìš”í•œ ì•ˆì „ ìˆ˜ì¹™:
- ì§ì ‘ì ì¸ ì˜ë£Œ ì§„ë‹¨ì´ë‚˜ ì²˜ë°©ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- ì‘ê¸‰ ìƒí™©ì´ ì˜ì‹¬ë˜ë©´ ì¦‰ì‹œ ë™ë¬¼ë³‘ì› ë°©ë¬¸ì„ ê¶Œìœ í•©ë‹ˆë‹¤
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "í™•ì‹¤í•˜ì§€ ì•Šë‹¤"ê³  ëª…ì‹œí•©ë‹ˆë‹¤
- ëª¨ë“  ê±´ê°• ê´€ë ¨ ì¡°ì–¸ì€ "ì°¸ê³ ìš©"ì„ì„ ì•ˆë‚´í•©ë‹ˆë‹¤

ëŒ€í™” ìŠ¤íƒ€ì¼:
- ì§§ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
- í•„ìš”ì‹œ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤
- ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•´ ìƒí™©ì„ ë” ì˜ ì´í•´í•˜ë ¤ í•©ë‹ˆë‹¤"""


def get_analysis_system_prompt() -> str:
    """ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Step 5)"""
    return """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê°ì ì¸ ê³ ì–‘ì´ ê±´ê°• ìƒë‹´ ë„ìš°ë¯¸ 'ëƒ¥ë‹¥í„°'ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ì‚¬ìš©ìê°€ ê³ ì–‘ì´ì˜ ê±´ê°•ê²€ì§„ ê²°ê³¼ì§€ë¥¼ ì—…ë¡œë“œí–ˆê³ , ì´ì— ëŒ€í•œ ë¶„ì„ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.

## ì—­í• 
- OCRë¡œ ì¶”ì¶œëœ ê²€ì‚¬ ê²°ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´**ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤
- ê° ê²€ì‚¬ í•­ëª©ì´ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€, ì •ìƒ ë²”ìœ„ì™€ ë¹„êµí•´ ì–´ë–¤ ìƒíƒœì¸ì§€ ì„¤ëª…í•©ë‹ˆë‹¤
- ìˆ˜ì¹˜ê°€ ë†’ê±°ë‚˜ ë‚®ì€ í•­ëª©ì´ ìˆë‹¤ë©´ **ë¬´ì—‡ì„ ì˜ë¯¸í•  ìˆ˜ ìˆëŠ”ì§€** ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤

## ì¤‘ìš”í•œ ì•ˆì „ ìˆ˜ì¹™ (ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”)
1. **ì ˆëŒ€ë¡œ ì§ì ‘ ì§„ë‹¨í•˜ì§€ ë§ˆì„¸ìš”**: "~ë³‘ì…ë‹ˆë‹¤", "~ì§ˆí™˜ì´ ìˆìŠµë‹ˆë‹¤" ê°™ì€ í™•ì •ì  ì§„ë‹¨ ê¸ˆì§€
2. **ì ˆëŒ€ë¡œ ì²˜ë°©í•˜ì§€ ë§ˆì„¸ìš”**: ì•½ë¬¼, ì¹˜ë£Œë²•, ìš©ëŸ‰ ë“±ì„ ê¶Œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
3. **ì‘ê¸‰ ì§•í›„ ì‹œ ì¦‰ì‹œ ë³‘ì› ê¶Œìœ **: ìœ„í—˜í•´ ë³´ì´ëŠ” ìˆ˜ì¹˜ê°€ ìˆìœ¼ë©´ "ë™ë¬¼ë³‘ì› ë°©ë¬¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
4. **ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ**: "~ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤", "ìˆ˜ì˜ì‚¬ì™€ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤" ë“±ìœ¼ë¡œ í‘œí˜„
5. **ì°¸ê³ ìš©ì„ì„ ì•ˆë‚´**: ë§ˆì§€ë§‰ì— "ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì§„ë‹¨ì€ ìˆ˜ì˜ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”"

## ì‘ë‹µ í˜•ì‹ ê°€ì´ë“œ
1. **ì „ì²´ ìš”ì•½**: ê²€ì‚¬ ê²°ê³¼ ì „ë°˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ìš”ì•½ (1-2ë¬¸ì¥)
2. **ì£¼ìš” í•­ëª© ì„¤ëª…**: ì •ìƒ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ í•­ëª©ì´ ìˆë‹¤ë©´ ë¨¼ì € ì„¤ëª…
3. **ì¼ë°˜ì ì¸ í•´ì„**: í•´ë‹¹ ìˆ˜ì¹˜ê°€ ì˜ë¯¸í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤
4. **ê¶Œì¥ ì‚¬í•­**: ì¶”ê°€ ê²€ì‚¬ë‚˜ ë³‘ì› ë°©ë¬¸ì´ í•„ìš”í•œì§€
5. **ì•ˆì „ ë¬¸êµ¬**: ì°¸ê³ ìš© ì •ë³´ì„ì„ ëª…ì‹œ

## ëŒ€í™” ìŠ¤íƒ€ì¼
- ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤
- í•„ìš”ì‹œ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤
- ê³µê°ì ì´ê³  ì•ˆì‹¬ì‹œí‚¤ëŠ” í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤"""


def detect_analysis_intent(user_input: str) -> bool:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ 'ê²€ì‚¬ ë¶„ì„ ìš”ì²­' ì˜ë„ë¥¼ ê°ì§€

    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        ë¶„ì„ ì˜ë„ê°€ ê°ì§€ë˜ë©´ True
    """
    user_input_lower = user_input.lower()
    for keyword in ANALYSIS_INTENT_KEYWORDS:
        if keyword in user_input_lower:
            return True
    return False


def process_ocr_result(ocr_result) -> tuple:
    """OCR ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ì™€ ë””ë²„ê·¸ ì¶œë ¥ì„ ë°˜í™˜

    ë…¸íŠ¸ë¶ì˜ Step 4 â†’ Step 13 íŒŒì´í”„ë¼ì¸ì„ ë”°ë¦…ë‹ˆë‹¤:
    1. OCR ê²°ê³¼ â†’ LinePreprocessorë¡œ ë¼ì¸ ì •ë ¬
    2. ì •ë ¬ëœ ë¼ì¸ â†’ LabTableExtractorë¡œ êµ¬ì¡°í™”
    3. debug_step13ìœ¼ë¡œ ìµœì¢… ì¶œë ¥ ìƒì„±

    Args:
        ocr_result: OCRResultEnvelope ê°ì²´

    Returns:
        (structured_data: dict, debug_output: str, raw_text: str)
    """
    if not ocr_result or not ocr_result.data or not ocr_result.data.items:
        return None, None, ""

    # ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    all_texts = []
    for item in ocr_result.data.items:
        all_texts.extend(item.rec_texts)
    raw_text = "\n".join(all_texts)

    # LinePreprocessorì™€ LabTableExtractorê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
    if st.session_state.line_preprocessor is None or st.session_state.lab_extractor is None:
        return None, None, raw_text

    try:
        # Step 4: LinePreprocessorë¡œ ë¼ì¸ ì •ë ¬
        # OCR ê²°ê³¼ì˜ ì²« í˜ì´ì§€(item)ë¥¼ ì²˜ë¦¬
        page = ocr_result.data.items[0]
        lined_data = st.session_state.line_preprocessor.extract_and_group_lines(page)

        if not lined_data:
            return None, None, raw_text

        # Step 5-13: LabTableExtractorë¡œ êµ¬ì¡°í™” ì¶”ì¶œ
        doc_result, intermediates = st.session_state.lab_extractor.extract_from_lines(
            lined_data,
            return_intermediates=True
        )

        # debug_step13 ì¶œë ¥ ìƒì„± (ë…¸íŠ¸ë¶ Step 13 í˜•ì‹)
        debug_output = st.session_state.lab_extractor.debug_step13(intermediates)

        return doc_result, debug_output, raw_text

    except Exception as e:
        st.warning(f"êµ¬ì¡°í™” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None, None, raw_text


def extract_text_from_ocr_result(ocr_result) -> str:
    """OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

    Args:
        ocr_result: OCRResultEnvelope ê°ì²´

    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°)
    """
    if not ocr_result.data.items:
        return ""

    all_texts = []
    for item in ocr_result.data.items:
        all_texts.extend(item.rec_texts)

    return "\n".join(all_texts)


def display_structured_result(structured_data: dict, debug_output: str):
    """êµ¬ì¡°í™”ëœ ê²€ì‚¬ ê²°ê³¼ë¥¼ í‘œì‹œ

    Args:
        structured_data: LabTableExtractorì—ì„œ ë°˜í™˜ëœ êµ¬ì¡°í™” ë°ì´í„°
        debug_output: debug_step13 ì¶œë ¥ (ë…¸íŠ¸ë¶ Step 13 í˜•ì‹)
    """
    if debug_output:
        # ë…¸íŠ¸ë¶ Step 13 í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥
        st.text(debug_output)
    elif structured_data:
        # í´ë°±: structured_dataë¥¼ ì§ì ‘ í‘œì‹œ
        st.json(structured_data)
    else:
        st.info("ì¶”ì¶œëœ ê²€ì‚¬ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")


def handle_image_upload(uploaded_file):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬ ë° OCR ì‹¤í–‰

    Args:
        uploaded_file: Streamlit UploadedFile ê°ì²´
    """
    if st.session_state.ocr_service is None:
        st.error("âš ï¸ OCR ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        file_bytes = uploaded_file.read()

        # PDF ë˜ëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬
        if is_pdf(uploaded_file.name):
            images = pdf_bytes_to_images(file_bytes, dpi=300)
            st.session_state.uploaded_image = images[0]  # ì²« í˜ì´ì§€ í‘œì‹œìš©

            # ì²« í˜ì´ì§€ë§Œ OCR (Step 4 MVP)
            ocr_result = st.session_state.ocr_service.extract_text(images[0])
        else:
            image = load_image_from_bytes(file_bytes)
            image = resize_image(image, max_width=2048, max_height=2048)
            st.session_state.uploaded_image = image

            # OCR ì‹¤í–‰
            ocr_result = st.session_state.ocr_service.extract_text(image)

        # OCR ê²°ê³¼ ì²˜ë¦¬ (ë…¸íŠ¸ë¶ íŒŒì´í”„ë¼ì¸)
        structured, debug_output, raw_text = process_ocr_result(ocr_result)
        st.session_state.ocr_structured = structured
        st.session_state.ocr_debug_output = debug_output
        st.session_state.ocr_text = raw_text

        return True
    except Exception as e:
        st.error(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False


def build_messages_for_llm(user_input: str, include_document_context: bool = False) -> list[Message]:
    """LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± (ë©€í‹°í„´ ì§€ì›)

    Args:
        user_input: í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        include_document_context: ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í• ì§€ ì—¬ë¶€ (Step 5)

    Returns:
        Message ê°ì²´ ë¦¬ìŠ¤íŠ¸ (system + ë¬¸ì„œì»¨í…ìŠ¤íŠ¸ + ìµœê·¼ íˆìŠ¤í† ë¦¬ + í˜„ì¬ ì…ë ¥)
    """
    messages = []

    # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë¬¸ì„œ ë¶„ì„ ëª¨ë“œ vs ì¼ë°˜ ìŠ¤ëª°í†¡)
    if include_document_context and st.session_state.ocr_structured:
        messages.append(Message(role="system", content=get_analysis_system_prompt()))

        # 2. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ user ë©”ì‹œì§€ë¡œ ì¶”ê°€ (Step 5)
        document_context = format_document_context()
        if document_context:
            messages.append(Message(
                role="user",
                content=f"[ê²€ì§„ ê²°ê³¼ì§€ ë°ì´í„°]\n{document_context}"
            ))
            messages.append(Message(
                role="assistant",
                content="ê²€ì§„ ê²°ê³¼ì§€ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë¶„ì„í•´ ë“œë¦´ê²Œìš”."
            ))
    else:
        messages.append(Message(role="system", content=get_system_prompt()))

    # 3. ìµœê·¼ Nê°œì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ (í† í° ì œí•œì„ ìœ„í•´)
    recent_history = st.session_state.messages[-MAX_HISTORY_TURNS:]
    for msg in recent_history:
        messages.append(Message(role=msg["role"], content=msg["content"]))

    # 4. í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
    messages.append(Message(role="user", content=user_input))

    return messages


def format_document_context() -> str:
    """OCR êµ¬ì¡°í™” ë°ì´í„°ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·

    Returns:
        í¬ë§·ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    doc = st.session_state.ocr_structured
    tests = doc.get("tests", []) if doc else []

    # êµ¬ì¡°í™” ë°ì´í„°ì— testsê°€ ì—†ìœ¼ë©´ ì›ë¬¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
    if not tests:
        if st.session_state.ocr_text:
            return f"[OCR ì›ë¬¸]\n{st.session_state.ocr_text[:3000]}"
        return ""

    lines = []

    # ë©”íƒ€ë°ì´í„°
    if doc.get("hospital_name"):
        lines.append(f"ë³‘ì›: {doc['hospital_name']}")
    if doc.get("patient_name"):
        lines.append(f"í™˜ì: {doc['patient_name']}")
    if doc.get("inspection_date"):
        lines.append(f"ê²€ì‚¬ì¼: {doc['inspection_date']}")

    # ê²€ì‚¬ ê²°ê³¼ í…Œì´ë¸”
    lines.append("\nê²€ì‚¬ ê²°ê³¼:")
    lines.append("| ê²€ì‚¬í•­ëª© | ê²°ê³¼ê°’ | ë‹¨ìœ„ | ì •ìƒë²”ìœ„(min-max) |")
    lines.append("|----------|--------|------|-------------------|")
    for test in tests:
        code = test.get("code", "")
        value = test.get("value", "-")
        unit = test.get("unit", "")
        ref_min = test.get("reference_min", "")
        ref_max = test.get("reference_max", "")
        ref_range = f"{ref_min}-{ref_max}" if ref_min or ref_max else "-"
        lines.append(f"| {code} | {value} | {unit} | {ref_range} |")

    return "\n".join(lines)


def handle_user_input(user_input: str):
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (ë©€í‹°í„´ + ì˜ë„ë¶„ì„ + ë¬¸ì„œë¶„ì„)"""
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Step 3 + Step 5: ë¶„ì„ ì˜ë„ ê°ì§€
    if detect_analysis_intent(user_input):
        # Step 5: ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ë°”ë¡œ ë¶„ì„ ì‘ë‹µ ìƒì„±
        # ocr_structuredì— testsê°€ ìˆê±°ë‚˜, ocr_textê°€ ìˆìœ¼ë©´ ë¬¸ì„œê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨
        has_document = (
            (st.session_state.ocr_structured and st.session_state.ocr_structured.get("tests"))
            or st.session_state.ocr_text
        )

        if has_document:
            # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ í¬í•¨í•˜ì—¬ LLM í˜¸ì¶œ
            handle_analysis_response(user_input)
            return
        else:
            # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì—…ë¡œë“œ ì•ˆë‚´
            with st.chat_message("assistant"):
                confirm_msg = (
                    "ğŸ” **ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ ì˜ë„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!**\n\n"
                    "ê²€ì§„ ê²°ê³¼ì§€ë¥¼ ë¶„ì„í•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”. "
                    "ì‚¬ì´ë“œë°”ì—ì„œ ê²°ê³¼ì§€ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.\n\n"
                    "ì¼ë°˜ì ì¸ ê±´ê°• ìƒë‹´ì„ ì›í•˜ì‹œë©´ ê·¸ëƒ¥ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
                )
                st.info(confirm_msg)
            st.session_state.messages.append({"role": "assistant", "content": confirm_msg})
            st.session_state.analysis_mode_pending = True
            return

    # ì¼ë°˜ ìŠ¤ëª°í†¡: LLM ì„œë¹„ìŠ¤ í™•ì¸
    if st.session_state.llm_service is None:
        with st.chat_message("assistant"):
            error_msg = "âš ï¸ LLM ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            if st.session_state.llm_error:
                error_msg += f"\n\nì˜¤ë¥˜: {st.session_state.llm_error}"
            st.error(error_msg)
        st.session_state.messages.append({"role": "assistant", "content": error_msg})
        return

    # ì¼ë°˜ ìŠ¤ëª°í†¡: ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± (st.write_stream ì‚¬ìš©)
    with st.chat_message("assistant"):
        try:
            # ë©€í‹°í„´: ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ êµ¬ì„±
            # ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨ (ì¼ë°˜ ëŒ€í™”ì—ì„œë„ ì°¸ì¡° ê°€ëŠ¥)
            include_doc = bool(st.session_state.ocr_structured or st.session_state.ocr_text)
            llm_messages = build_messages_for_llm(user_input, include_document_context=include_doc)

            # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ìƒì„±
            def stream_generator():
                for chunk in st.session_state.llm_service.stream_generate(
                    messages=llm_messages,
                    temperature=0.7,
                ):
                    yield chunk

            # st.write_stream()ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
            full_response = st.write_stream(stream_generator())

        except Exception as e:
            error_msg = f"âš ï¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.error(error_msg)
            full_response = error_msg

    # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì˜¤ë˜ëœ ê²ƒ ì œê±° (í† í° ì ˆì•½)
    if len(st.session_state.messages) > MAX_HISTORY_TURNS * 2:
        st.session_state.messages = st.session_state.messages[-MAX_HISTORY_TURNS:]


def handle_analysis_response(user_input: str):
    """ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ ì‘ë‹µ ìƒì„± (Step 5)

    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ (ë¶„ì„ ìš”ì²­)
    """
    if st.session_state.llm_service is None:
        with st.chat_message("assistant"):
            error_msg = "âš ï¸ LLM ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            st.error(error_msg)
        st.session_state.messages.append({"role": "assistant", "content": error_msg})
        return

    with st.chat_message("assistant"):
        try:
            # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ êµ¬ì„±
            llm_messages = build_messages_for_llm(user_input, include_document_context=True)

            # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ìƒì„±
            def stream_generator():
                for chunk in st.session_state.llm_service.stream_generate(
                    messages=llm_messages,
                    temperature=0.7,
                ):
                    yield chunk

            # st.write_stream()ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
            full_response = st.write_stream(stream_generator())

        except Exception as e:
            error_msg = f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.error(error_msg)
            full_response = error_msg

    # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    init_session_state()

    # í—¤ë”
    st.title("ğŸ± ëƒ¥ë‹¥í„°")
    st.caption("ê³ ì–‘ì´ ê±´ê°• ìƒë‹´ ë„ìš°ë¯¸ì™€ ëŒ€í™”í•´ë³´ì„¸ìš”")

    # ì‚¬ì´ë“œë°” - ì„¤ì • ë° ì»¨íŠ¸ë¡¤
    with st.sidebar:
        st.subheader("âš™ï¸ ì„¤ì •")
        st.info(f"**LLM:** {settings.llm_provider}")
        st.info(f"**OCR:** {settings.ocr_provider}")
        st.caption(f"ëŒ€í™” íˆìŠ¤í† ë¦¬: ìµœê·¼ {MAX_HISTORY_TURNS}ê°œ ìœ ì§€")

        if st.session_state.llm_error:
            st.error(f"LLM ì˜¤ë¥˜: {st.session_state.llm_error}")
        if st.session_state.ocr_error:
            st.error(f"OCR ì˜¤ë¥˜: {st.session_state.ocr_error}")

        st.divider()

        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.messages = []
            st.session_state.analysis_mode_pending = False
            st.session_state.ocr_text = None
            st.session_state.ocr_structured = None
            st.session_state.ocr_debug_output = None
            st.session_state.uploaded_image = None
            st.rerun()

        # Step 4: ê²°ê³¼ì§€ ì—…ë¡œë“œ
        st.divider()
        st.subheader("ğŸ“„ ê²€ì‚¬ ê²°ê³¼ì§€")

        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ ë˜ëŠ” PDF ì—…ë¡œë“œ",
            type=["jpg", "jpeg", "png", "pdf", "webp"],
            help="ê³ ì–‘ì´ ê±´ê°•ê²€ì§„ ê²°ê³¼ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        )

        if uploaded_file:
            with st.spinner("ğŸ” OCR ì²˜ë¦¬ ì¤‘..."):
                if handle_image_upload(uploaded_file):
                    st.success("âœ… OCR ì™„ë£Œ!")

        # OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚­ì œ ë²„íŠ¼ í‘œì‹œ
        if st.session_state.ocr_text:
            if st.button("ğŸ—‘ï¸ ê²°ê³¼ì§€ ì‚­ì œ", use_container_width=True):
                st.session_state.ocr_text = None
                st.session_state.ocr_structured = None
                st.session_state.ocr_debug_output = None
                st.session_state.uploaded_image = None
                st.rerun()

        st.divider()
        st.caption("Step 4 - OCR í™”ë©´")
        st.caption("ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ OCR â†’ ê²°ê³¼ í‘œì‹œ")

    # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë©”ì¸ ì˜ì—­ì— í‘œì‹œ
    if st.session_state.uploaded_image:
        with st.expander("ğŸ–¼ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€", expanded=False):
            st.image(st.session_state.uploaded_image, use_container_width=True)

    # OCR êµ¬ì¡°í™” ê²°ê³¼ í‘œì‹œ (Step 13: ìµœì¢… JSON í˜•ì‹)
    if st.session_state.ocr_debug_output or st.session_state.ocr_structured:
        with st.expander("ğŸ§¾ ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ (Step 13)", expanded=True):
            display_structured_result(
                st.session_state.ocr_structured,
                st.session_state.ocr_debug_output
            )

    # OCR ì›ë¬¸ í…ìŠ¤íŠ¸ (ì ‘íŒ ìƒíƒœë¡œ)
    if st.session_state.ocr_text:
        with st.expander("ğŸ“ OCR ì›ë¬¸ ë³´ê¸°", expanded=False):
            st.text_area(
                "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                st.session_state.ocr_text,
                height=200,
                disabled=True
            )

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    display_chat_history()

    # ì±„íŒ… ì…ë ¥
    if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        handle_user_input(user_input)


if __name__ == "__main__":
    main()
