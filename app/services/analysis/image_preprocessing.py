import io
from typing import List, Dict, Any, Tuple, Callable, Sequence, Optional
import fitz
import tempfile
from PIL import Image, ImageFilter, ImageOps
import numpy as np
from pytesseract import image_to_data, Output
import cv2
import os

# ---------- ê³µí†µ ë³´ì¡° ----------
def _pil_to_cv(img: Image.Image) -> np.ndarray:
    arr = np.array(img)
    if arr.ndim == 2:
        return arr
    if arr.shape[2] == 4:
        # RGBA -> RGB
        arr = cv2.cvtColor(arr, cv2.COLOR_RGBA2RGB) if cv2 is not None else arr[:, :, :3]
    # RGB -> BGR
    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR) if cv2 is not None else arr[:, :, ::-1]

def _cv_to_pil(arr: np.ndarray) -> Image.Image:
    if arr.ndim == 2:
        return Image.fromarray(arr)
    # BGR -> RGB
    if cv2 is not None:
        arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)
    else:
        arr = arr[:, :, ::-1]
    return Image.fromarray(arr)

def _order_quad(pts: np.ndarray) -> np.ndarray:
    # pts: (4,2)
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1).ravel()
    tl = pts[np.argmin(s)]
    br = pts[np.argmax(s)]
    tr = pts[np.argmin(diff)]
    bl = pts[np.argmax(diff)]
    return np.array([tl, tr, br, bl], dtype=np.float32)

def pdf_to_images(pdf_path: str, resolution_scale: float = 1.5) -> List[bytes]:
    """
    PDF íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ ê° í˜ì´ì§€ë¥¼ PNG ë°”ì´íŠ¸ë¡œ ë³€í™˜í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    png_list: List[bytes] = []
    doc = None
    try:
        doc = fitz.open(pdf_path)
        mat = fitz.Matrix(resolution_scale, resolution_scale)
        for page in doc:
            pix = page.get_pixmap(matrix=mat, alpha=False)
            png_list.append(pix.tobytes("png"))
    finally:
        try:
            if doc is not None:
                doc.close()
        except Exception:
            pass
    return png_list

# ---------- ë¡œë“œ+EXIF íšŒì „ êµì • ----------
def open_with_exif(img_bytes: bytes):
    """
    1) ë¡œë“œ + EXIF íšŒì „ êµì •: ì¹´ë©”ë¼ íšŒì „ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‹¤ì œ í”½ì…€ì„ íšŒì „
    """
    img = Image.open(io.BytesIO(img_bytes))
    try:
        img = ImageOps.exif_transpose(img)
    except Exception:
        pass
    return img

# ---------- íˆ¬ëª… ì±„ë„ í”Œë˜íŠ¼ ----------
def flatten_transparency(img: Image.Image) -> Image.Image:
    """
    2) íˆ¬ëª… ì±„ë„ í”Œë˜íŠ¼: RGBA/LA â†’ í° ë°°ê²½ ìœ„ì— í•©ì„± (ê¸°í˜¸/ì  ì£¼ë³€ í—¤ì¼ë¡œ ë°©ì§€)
    """
    if img.mode in ("RGBA", "LA"):
        bg = Image.new("RGB", img.size, (255, 255, 255))
        alpha = img.split()[-1]
        return Image.composite(img.convert("RGB"), bg, alpha)
    return img

# ---------- ì—¬ë°± ê¸°ë°˜ ìë™ í¬ë¡­ ----------
def auto_crop_with_margin(img: Image.Image, margin: int = 20) -> Image.Image:
    """
    3) ìë™ í¬ë¡­: í° ë°°ê²½ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ìš©ë¬¼ bboxë¥¼ ì°¾ê³  marginë§Œí¼ ì—¬ìœ 
    """
    gray = img.convert("L")
    inv = ImageOps.invert(gray)  # í°ìƒ‰ ë°°ê²½ â†’ 0, ì‰í¬ â†’ ì–‘ìˆ˜
    bbox = inv.getbbox()
    if not bbox:
        return img
    x0, y0, x1, y1 = bbox
    x0 = max(0, x0 - margin)
    y0 = max(0, y0 - margin)
    x1 = min(img.width,  x1 + margin)
    y1 = min(img.height, y1 + margin)
    return img.crop((x0, y0, x1, y1))

# ---------- ë¬¸ì„œ ì™¸ê³½ ì‚¬ë³€í˜• ê²½ê³„ íƒì§€ ----------
def detect_document_quad(img: Image.Image, min_area_ratio: float = 0.2, debug: bool = False) -> Optional[List[Tuple[int, int]]]:
    """
    new detect_document_quad(ë¬¸ì„œ ì™¸ê³½ ì‚¬ë³€í˜• ê²½ê³„ íƒì§€)
    - ì„±ê³µ ì‹œ ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜ 4ì  ë°˜í™˜, ì‹¤íŒ¨ ì‹œ None
    """
    if cv2 is None:
        if debug: print("[detect_document_quad] OpenCV ë¯¸ì„¤ì¹˜ - ê±´ë„ˆëœ€")
        return None
    im = _pil_to_cv(img)
    h, w = im.shape[:2]
    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) if im.ndim == 3 else im
    gray = cv2.GaussianBlur(gray, (5,5), 0)
    edges = cv2.Canny(gray, 50, 150)
    edges = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=1)
    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
    img_area = w*h
    for c in cnts[:8]:
        area = cv2.contourArea(c)
        if area < img_area * min_area_ratio:
            continue
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
        if len(approx) == 4:
            quad = approx.reshape(-1, 2).astype(np.float32)
            quad = _order_quad(quad)
            if debug: print(f"[detect_document_quad] ì‚¬ë³€í˜• ë°œê²¬ - area ratio={area/img_area:.2f}")
            return [(int(x), int(y)) for x, y in quad]
    if debug: print("[detect_document_quad] ì‚¬ë³€í˜• ë¯¸ë°œê²¬")
    return None

# ---------- ì‚¬ë³€í˜• â†’ ì§ì‚¬ê° íˆ¬ì‹œ ë³´ì • ----------
def perspective_unwarp(img: Image.Image, quad: Optional[List[Tuple[int,int]]] = None, keep_aspect: bool = True, padding: int = 0, debug: bool = False) -> Image.Image:
    """
    new perspective_unwarp(ì‚¬ë³€í˜• â†’ ì§ì‚¬ê° íˆ¬ì‹œ ë³´ì •)
    - quadê°€ ì—†ìœ¼ë©´ ìë™ ê²€ì¶œì„ ì‹œë„
    """
    if cv2 is None:
        if debug: print("[perspective_unwarp] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img
    if quad is None:
        quad = detect_document_quad(img, debug=debug)
    if quad is None:
        if debug: print("[perspective_unwarp] ê²½ê³„ ë¯¸ê²€ì¶œ - ì›ë³¸ ë°˜í™˜")
        return img

    im = _pil_to_cv(img)
    h, w = im.shape[:2]
    src = np.array(quad, dtype=np.float32)

    # ëª©í‘œ í¬ê¸° ì¶”ì •
    tl, tr, br, bl = src
    widthA = np.linalg.norm(br - bl)
    widthB = np.linalg.norm(tr - tl)
    heightA = np.linalg.norm(tr - br)
    heightB = np.linalg.norm(tl - bl)
    dst_w = int(max(widthA, widthB))
    dst_h = int(max(heightA, heightB))
    if keep_aspect and dst_w > 0 and dst_h > 0:
        aspect = dst_w / (dst_h + 1e-6)
        # ì˜ë£Œ ì–‘ì‹(ì„¸ë¡œí˜•)ì´ í”í•´ ì•½ê°„ì˜ ì •ê·œí™”
        if aspect < 0.6:  # ë„ˆë¬´ ì„¸ë¡œ ê¸¸ë©´ ì‚´ì§ ë³´ì •
            dst_w = int(dst_h * 0.7)

    dst = np.array([[0,0],[dst_w-1,0],[dst_w-1,dst_h-1],[0,dst_h-1]], dtype=np.float32)
    M = cv2.getPerspectiveTransform(src, dst)
    warped = cv2.warpPerspective(im, M, (dst_w, dst_h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

    if padding > 0:
        warped = cv2.copyMakeBorder(warped, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=(255,255,255))
    if debug: print(f"[perspective_unwarp] ì™„ë£Œ â†’ {dst_w}x{dst_h}")
    return _cv_to_pil(warped)

# ---------- OSD + í…ìŠ¤íŠ¸ ë¼ì¸ ê¸°ë°˜ ë¯¸ì„¸ ê¸°ìš¸ê¸° ë³´ì • ----------
def deskew_textlines(
    img: Image.Image,
    max_angle: float = 12.0,
    refine: bool = True,
    refine_range: float = 1.0,   # Â± íƒìƒ‰ ë²”ìœ„(ë„)
    refine_step: float = 0.05,   # íƒìƒ‰ ê°„ê²©(ë„)
    pad: int = 12,               # íšŒì „ ì „ ì—¬ë°±(í´ë¦¬í•‘ ë°©ì§€)
    debug: bool = True,
) -> Image.Image:
    """
    Tesseract OSDë¡œ 'ì´ˆê¸° ê°ë„' ì¶”ì • í›„, ì‘ì€ ë²”ìœ„ì—ì„œ
    í–‰ í”„ë¡œì ì…˜ ì ìˆ˜ë¡œ ì •ë°€ íƒìƒ‰í•´ êµì •. OSD ì‹¤íŒ¨ ì‹œ Hough ë³€í™˜ ì‚¬ìš©.
    """
    if cv2 is None:
        if debug: print("[deskew_textlines] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img

    # 1) Tesseract OSDë¡œ ì´ˆê¸° ê°ë„ ì¶”ì •
    osd_angle = 0.0
    try:
        from pytesseract import image_to_osd, Output
        osd = image_to_osd(img, output_type=Output.DICT, config="--psm 0")
        # TesseractëŠ” ì‹œê³„ ë°©í–¥ì„ ì–‘ìˆ˜ë¡œ ë³´ê³ , ìš°ë¦¬ëŠ” ë°˜ì‹œê³„ ë°©í–¥ì„ ì–‘ìˆ˜ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ë¶€í˜¸ ë°˜ì „
        angle_candidate = -float(osd.get('rotate', 0))
        if abs(angle_candidate) <= max_angle:
            osd_angle = angle_candidate
            if debug: print(f"[deskew_textlines] Tesseract OSD angle: {osd_angle:.2f}Â°")
    except Exception as e:
        if debug: print(f"[deskew_textlines] Tesseract OSD ì‹¤íŒ¨: {e}, Hough ë³€í™˜ìœ¼ë¡œ ëŒ€ì²´")
        osd_angle = 0.0 # ì‹¤íŒ¨ ì‹œ 0ìœ¼ë¡œ ì´ˆê¸°í™”

    im0 = _pil_to_cv(img)
    if pad > 0:
        im = cv2.copyMakeBorder(im0, pad, pad, pad, pad, cv2.BORDER_REPLICATE)
    else:
        im = im0

    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) if im.ndim == 3 else im
    h, w = gray.shape[:2]

    # 2) OSD ê°ë„ê°€ 0ì— ê°€ê¹Œìš°ë©´ Hough ë³€í™˜ìœ¼ë¡œ ë³´ì¡°/ëŒ€ì²´
    coarse = osd_angle
    if abs(osd_angle) < 0.1:
        gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)
        thr = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
        bw_inv = 255 - thr

        kx = max(21, w // 30)
        hker = cv2.getStructuringElement(cv2.MORPH_RECT, (kx, 1))
        horiz = cv2.morphologyEx(bw_inv, cv2.MORPH_OPEN, hker)
        edges = cv2.max(cv2.Canny(bw_inv, 50, 150), cv2.Canny(horiz, 50, 150))

        min_len = max(60, int(w * 0.35))
        linesP = cv2.HoughLinesP(
            edges, 1, np.pi / 180,
            threshold=max(50, int(0.0025 * w)),
            minLineLength=min_len,
            maxLineGap=30
        )
        angles, weights = [], []
        if linesP is not None:
            for x1, y1, x2, y2 in linesP[:, 0]:
                ang = np.degrees(np.arctan2(y2 - y1, x2 - x1))
                if -max_angle <= ang <= max_angle:
                    L = float(np.hypot(x2 - x1, y2 - y1))
                    angles.append(ang); weights.append(L)
        
        hough_angle = float(np.average(angles, weights=weights)) if angles else 0.0
        if debug: print(f"[deskew_textlines] Hough angle: {hough_angle:.2f}Â°")
        # OSD ê²°ê³¼ê°€ ê±°ì˜ ì—†ì„ ë•Œë§Œ Hough ê²°ê³¼ ì‚¬ìš©
        if abs(osd_angle) < 0.1 and abs(hough_angle) > abs(osd_angle):
             coarse = hough_angle

    final_angle = coarse

    # 3) ì •ë°€ íƒìƒ‰(Â±refine_range, step=refine_step) - í–‰ í”„ë¡œì ì…˜ ì ìˆ˜ ìµœëŒ€í™”
    if refine and abs(coarse) < max_angle : # coarseê°€ max_angleì„ ë„˜ìœ¼ë©´ refine ê±´ë„ˆëœ€
        # ì´ì§„í™” ì´ë¯¸ì§€ê°€ í•„ìš”í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ë‹¤ì‹œ ê³„ì‚°
        gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)
        thr = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
        bw_inv = 255 - thr

        scale = 1000.0 / max(h, w)
        small = cv2.resize(bw_inv, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA) if scale < 1.0 else bw_inv
        sh, sw = small.shape[:2]

        def score(a_deg: float) -> float:
            M = cv2.getRotationMatrix2D((sw / 2, sh / 2), a_deg, 1.0)
            r = cv2.warpAffine(small, M, (sw, sh), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)
            proj = r.mean(axis=1)
            d = np.diff(proj)
            return float(proj.var() + 0.5 * (d * d).mean())

        best_s, best_a = -1e9, coarse
        for a in np.arange(coarse - refine_range, coarse + refine_range + 1e-9, refine_step):
            s = score(a)
            if s > best_s:
                best_s, best_a = s, a
        final_angle = best_a

    if debug:
        print(f"[deskew_textlines] coarse={coarse:.2f}Â°, final={final_angle:.2f}Â°")

    if abs(final_angle) < 0.05:
        return img

    M = cv2.getRotationMatrix2D((w / 2, h / 2), final_angle, 1.0)
    rotated = cv2.warpAffine(im, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    if pad > 0 and rotated.shape[0] > 2 * pad and rotated.shape[1] > 2 * pad:
        rotated = rotated[pad:-pad, pad:-pad]
    return _cv_to_pil(rotated)

# ---------- í˜ì´ì§€ ë§ë¦¼/ê³¡ë©´ ë³´ì •Â·í•„ìš” ì‹œë§Œ ----------
def conditional_dewarp(
    img: Image.Image,
    strength: float = 0.6,
    min_lines: int = 10,
    min_amplitude_px: float = 2.0,   # ê³¡ë¥  ì§„í­ì´ ì´ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
    r2_min: float = 0.85,            # 2ì°¨ ë‹¤í•­ ì í•© í’ˆì§ˆ í•˜í•œ
    r2_gain_min: float = 0.03,       # ì„ í˜•â†’2ì°¨ë¡œì˜ ê°œì„ í­ í•˜í•œ
    max_shift_px: float = 6.0,       # ì»¬ëŸ¼ë³„ ìµœëŒ€ ì„¸ë¡œ ì´ë™ í´ë¨í”„
    debug: bool = True
) -> Image.Image:
    """
    í˜ì´ì§€ ë§ë¦¼/ê³¡ë©´ ë³´ì •(í•„ìš” ì‹œë§Œ)
    - ìˆ˜í‰ ë¼ì¸ ìƒ˜í”Œ â†’ x-ì¢Œí‘œì— ëŒ€í•œ ë² ì´ìŠ¤ë¼ì¸ì„ 2ì°¨ ë‹¤í•­ìœ¼ë¡œ ê·¼ì‚¬
    - 'ê³¡ë¥ ì´ ì¶©ë¶„íˆ í´ ë•Œ'ì—ë§Œ ì ìš©. ë°˜ë“¯í•œ ë¬¸ì„œëŠ” ìŠ¤í‚µ.
    """
    if cv2 is None:
        if debug: print("[conditional_dewarp] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img

    im = _pil_to_cv(img)
    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) if im.ndim == 3 else im
    bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                               cv2.THRESH_BINARY_INV, 35, 15)

    lines = cv2.HoughLinesP(
        bw, 1, np.pi/180, threshold=100,
        minLineLength=max(40, gray.shape[1]//10),
        maxLineGap=10
    )
    if lines is None:
        if debug: print("[conditional_dewarp] ë¼ì¸ ë¯¸ê²€ì¶œ - ìŠ¤í‚µ")
        return img

    pts_x, pts_y = [], []
    for x1, y1, x2, y2 in lines[:, 0]:
        if abs(y2 - y1) <= 2:  # ë” ì—„ê²©í•œ ìˆ˜í‰ íŒì •
            pts_x.append(0.5*(x1+x2))
            pts_y.append(0.5*(y1+y2))

    if len(pts_x) < min_lines:
        if debug: print(f"[conditional_dewarp] ìœ íš¨ ìˆ˜í‰ ë¼ì¸ ë¶€ì¡±({len(pts_x)}<{min_lines}) - ìŠ¤í‚µ")
        return img

    x = np.asarray(pts_x, dtype=np.float32)
    y = np.asarray(pts_y, dtype=np.float32)

    # ì„ í˜•/2ì°¨ ëª¨ë‘ ì í•© í›„ í’ˆì§ˆ ë¹„êµ
    p1 = np.poly1d(np.polyfit(x, y, deg=1))
    p2 = np.poly1d(np.polyfit(x, y, deg=2))
    yhat1 = p1(x)
    yhat2 = p2(x)
    ss_tot = float(((y - y.mean())**2).sum()) + 1e-6
    r2_lin = 1.0 - float(((y - yhat1)**2).sum())/ss_tot
    r2_quad = 1.0 - float(((y - yhat2)**2).sum())/ss_tot
    r2_gain = r2_quad - r2_lin

    h, w = gray.shape[:2]
    xs = np.arange(w, dtype=np.float32)
    curve = p2(xs).astype(np.float32)
    amplitude = float(np.percentile(curve, 95) - np.percentile(curve, 5))

    if debug:
        print(f"[conditional_dewarp] r2_lin={r2_lin:.3f}, r2_quad={r2_quad:.3f}, gain={r2_gain:.3f}, amp={amplitude:.2f}px")

    # ì•ˆì „ ê²Œì´íŠ¸: ê³¡ë¥ Â·ì í•© í’ˆì§ˆì´ ì¶©ë¶„í•  ë•Œë§Œ ì ìš©
    if (amplitude < min_amplitude_px) or (r2_quad < r2_min) or (r2_gain < r2_gain_min):
        if debug: print("[conditional_dewarp] ê³¡ë¥ /ì í•© í’ˆì§ˆ ë¶€ì¡± - ìŠ¤í‚µ")
        return img

    # ê°•ë„ ìë™ ì¡°ì ˆ + ì´ë™ëŸ‰ í´ë¨í”„
    strength_eff = min(strength, max_shift_px / (0.5*amplitude + 1e-6))
    shift = (curve - curve.mean()) * strength_eff
    shift = np.clip(shift, -max_shift_px, max_shift_px).astype(np.float32)

    map_x = np.tile(xs, (h, 1)).astype(np.float32)
    ys = np.arange(h, dtype=np.float32)
    map_y = (np.tile(ys[:, None], (1, w)) - shift[None, :]).astype(np.float32)
    map_y = np.clip(map_y, 0, h - 1)

    dewarped = cv2.remap(im, map_x, map_y, interpolation=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    if debug: print("[conditional_dewarp] ë””ì›Œí”„ ì ìš© (ì•ˆì „ ê²Œì´íŠ¸ í†µê³¼)")
    return _cv_to_pil(dewarped)

# ---------- ìµœì†Œ í•´ìƒë„ í™•ë³´ ì—…ìŠ¤ì¼€ì¼ ----------
def upscale_min_resolution(img: Image.Image, min_long_edge: int = 1920) -> Image.Image:
    """
    4) í•´ìƒë„ í‘œì¤€í™”(ì—…ìŠ¤ì¼€ì¼ë§Œ): ì†Œìˆ˜ì /ê¸°í˜¸ ì„ ëª…ë„ë¥¼ ìœ„í•´ ìµœì†Œ í•´ìƒë„ í™•ë³´, ê³¼ëŒ€ í¬ê¸°ëŠ” ì¶•ì†Œí•˜ì§€ ì•ŠìŒ
    """
    w, h = img.size
    long_edge = max(w, h)
    if long_edge < min_long_edge:
        scale = min_long_edge / float(long_edge)
        img = img.resize((int(round(w * scale)), int(round(h * scale))), Image.LANCZOS)
    return img

# ---------- ë°°ê²½ í‰íƒ„í™”Â·ê·¸ë¼ë””ì–¸íŠ¸/ê·¸ë¦¼ì ì œê±° ----------
def illumination_flatten(img: Image.Image, blur_ratio: float = 0.03, debug: bool = False) -> Image.Image:
    """
    new illumination_flatten(ë°°ê²½ í‰íƒ„í™”Â·ê·¸ë¦¼ì ì œê±°)
    - í° ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë°°ê²½ì„ ì¶”ì • í›„ L(ë°ê¸°) ì±„ë„ì—ì„œ í‰íƒ„í™”
    """
    if cv2 is None:
        if debug: print("[illumination_flatten] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img
    im = _pil_to_cv(img)
    if im.ndim == 3:
        lab = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)
        L, A, B = cv2.split(lab)
        k = max(3, int(round(max(im.shape[:2]) * blur_ratio)) | 1)
        bg = cv2.GaussianBlur(L, (k, k), 0)
        flat = cv2.normalize(cv2.subtract(L, bg) + 128, None, 0, 255, cv2.NORM_MINMAX)
        lab = cv2.merge([flat, A, B])
        out = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    else:
        k = max(3, int(round(max(im.shape[:2]) * blur_ratio)) | 1)
        bg = cv2.GaussianBlur(im, (k, k), 0)
        out = cv2.normalize(cv2.subtract(im, bg) + 128, None, 0, 255, cv2.NORM_MINMAX)
    if debug: print(f"[illumination_flatten] k={k} ì ìš©")
    return _cv_to_pil(out)

# ---------- í•˜ì´ë¼ì´íŠ¸/ë¹›ë°˜ì‚¬ ê°ì‡  ----------
def suppress_glare(img: Image.Image, v_high: int = 230, s_low: int = 40, debug: bool = False) -> Image.Image:
    """
    new suppress_glare(í•˜ì´ë¼ì´íŠ¸/ë¹›ë°˜ì‚¬ ê°ì‡ )
    - HSVì—ì„œ S ë‚®ê³  V ë†’ì€ ì˜ì—­ì„ ì™„ë§Œíˆ ì–µì œ
    """
    if cv2 is None:
        if debug: print("[suppress_glare] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img
    im = _pil_to_cv(img)
    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV) if im.ndim == 3 else cv2.cvtColor(cv2.cvtColor(im, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)
    H, S, V = cv2.split(hsv)
    mask = cv2.inRange(S, 0, s_low) & cv2.inRange(V, v_high, 255)
    # ë°ê¸° ì™„ë§Œ ê°ì†Œ
    V2 = V.copy()
    V2[mask > 0] = (0.85 * V2[mask > 0]).astype(np.uint8)
    hsv2 = cv2.merge([H, S, V2])
    out = cv2.cvtColor(hsv2, cv2.COLOR_HSV2BGR)
    if debug: print("[suppress_glare] ê¸€ë ˆì–´ ê°ì‡  ì ìš©")
    return _cv_to_pil(out)

# ---------- ì´ë¯¸ì§€ ëª¨ë“œ ì •ê·œí™” ----------
def normalize_mode(img: Image.Image) -> Image.Image:
    """
    5) ëª¨ë“œ ì •ê·œí™”: ì´í›„ ì—°ì‚° í˜¸í™˜ì„ ìœ„í•´ L ë˜ëŠ” RGBë¡œ ì œí•œ
    """
    if img.mode not in ("L", "RGB"):
        return img.convert("RGB")
    return img

# ---------- ì•½í•œ ì „ì—­ ëŒ€ë¹„ ë³´ì • ----------
def weak_autocontrast(img: Image.Image, cutoff: float = 0.4) -> Image.Image:
    """
    6) ìë™ ëŒ€ë¹„: ë‚®ì€ ì»·ì˜¤í”„(0.4%)ë¡œ ë¯¸ì„¸ í”½ì…€(ì†Œìˆ˜ì Â·ë‹¨ìœ„) í´ë¦¬í•‘ ë°©ì§€
    """
    return ImageOps.autocontrast(img, cutoff=cutoff)

# ---------- ë¡œì»¬ ëŒ€ë¹„ í–¥ìƒÂ·ê³¼ë„ ì‹œ ë¹„í™œì„±í™” ----------
def apply_clahe(img: Image.Image, clip_limit: float = 2.0, tile_grid: Tuple[int,int] = (8,8), debug: bool = False) -> Image.Image:
    """
    new apply_clahe(ë¡œì»¬ ëŒ€ë¹„ í–¥ìƒÂ·ê³¼ë„ ì‹œ ë¹„í™œì„±í™”)
    """
    if cv2 is None:
        if debug: print("[apply_clahe] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img
    im = _pil_to_cv(img)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)
    if im.ndim == 3:
        lab = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)
        L, A, B = cv2.split(lab)
        L2 = clahe.apply(L)
        lab2 = cv2.merge([L2, A, B])
        out = cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)
    else:
        out = clahe.apply(im)
    if debug: print("[apply_clahe] ì ìš© ì™„ë£Œ")
    return _cv_to_pil(out)

# ---------- ë³´ìˆ˜ì  ìƒ¤í”„ë‹ ----------
def conservative_sharpen(img: Image.Image, radius: float = 1.0, percent: int = 120, threshold: int = 4) -> Image.Image:
    """
    7) ë³´ìˆ˜ì  ìƒ¤í”ˆ: ì†Œìˆ˜ì  ì£¼ë³€ í—¤ì¼ë¡œ ì—†ì´ ìŠ¤íŠ¸ë¡œí¬ë§Œ ê°•í™”
    """
    return img.filter(ImageFilter.UnsharpMask(radius=radius, percent=percent, threshold=threshold))

# ---------- ì -í‘ ë³€í™˜ ----------
def blacken_reddish_text(
    img: Image.Image,
    hue_band: int = 8,     # 0Â°(ë¹¨ê°•) ì£¼ë³€ í—ˆìš© ë²”ìœ„(ë„, OpenCVëŠ” 0~180 ìŠ¤ì¼€ì¼)
    sat_thr: int = 70,      # ì±„ë„ ì„ê³„
    min_v: int = 70,        # ìµœì†Œ ëª…ë„(ë°°ê²½ ì œì™¸)
    darken: float = 0.10,   # V(ë°ê¸°) ê°ì‡  ë¹„ìœ¨(0~1, ë‚®ì„ìˆ˜ë¡ ë” ê²€ê²Œ)
    thicken: int = 0,       # ë§ˆìŠ¤í¬ íŒ½ì°½ íšŸìˆ˜(íš ë³´ê°•)
    debug: bool = False
) -> Image.Image:
    """
    ë¶‰ì€/ì£¼í™© ê³„ì—´ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ì „ì— 'ê²€ì •ì— ê°€ê¹ê²Œ' ì–´ë‘¡ê²Œ ë§Œë“ ë‹¤.
    - í° ë°°ê²½ê³¼ì˜ ëŒ€ë¹„ë¥¼ í‚¤ì›Œ OCRì—ì„œ ì˜…ì–´ì§€ëŠ” í˜„ìƒì„ ì™„í™”.
    - HSVì—ì„œ ë¹¨ê°•(0Â° ë¶€ê·¼, 0~hue_band ë˜ëŠ” 180-hue_band~180)ì„ ì¡ì•„ Vë¥¼ ê°ì‡ .
    """
    if cv2 is None:
        if debug: print("[blacken_reddish_text] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img

    arr = _pil_to_cv(img)
    if arr.ndim == 2:
        return img  # ì´ë¯¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼

    hsv = cv2.cvtColor(arr, cv2.COLOR_BGR2HSV)
    H, S, V = cv2.split(hsv)

    band = int(max(1, min(hue_band, 30)))
    # ë¹¨ê°• ì˜ì—­ ë§ˆìŠ¤í¬: 0~band ë˜ëŠ” 180-band~180
    mask_red = ((H <= band) | (H >= 180 - band)) & (S >= sat_thr) & (V >= min_v)
    mask = mask_red.astype(np.uint8) * 255

    if thicken > 0:
        ker = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        mask = cv2.dilate(mask, ker, iterations=int(thicken))

    V2 = V.copy()
    V2[mask > 0] = (V2[mask > 0].astype(np.float32) * float(max(0.01, min(darken, 1.0)))).astype(np.uint8)

    hsv2 = cv2.merge([H, S, V2])
    out = cv2.cvtColor(hsv2, cv2.COLOR_HSV2BGR)
    if debug: print("[blacken_reddish_text] ì ìš© ì™„ë£Œ")
    return _cv_to_pil(out)

# ---------- ì²­-í‘ ë³€í™˜ ----------
def blacken_bluish_text(
    img: Image.Image,
    hue_center: int = 120,  # íŒŒë‘ ì¤‘ì‹¬ Hue(0~180, OpenCV HSV ìŠ¤ì¼€ì¼ì—ì„œ íŒŒë‘â‰ˆ120)
    hue_band: int = 16,     # ì¤‘ì‹¬ ì£¼ë³€ í—ˆìš© ë²”ìœ„
    sat_thr: int = 55,      # ì±„ë„ ì„ê³„
    min_v: int = 55,        # ìµœì†Œ ëª…ë„(ë°°ê²½ ì œì™¸)
    darken: float = 0.1,   # V(ë°ê¸°) ê°ì‡  ë¹„ìœ¨(0~1, ë‚®ì„ìˆ˜ë¡ ë” ê²€ê²Œ)
    thicken: int = 0.3,       # ë§ˆìŠ¤í¬ íŒ½ì°½(íš ë³´ê°•)
    debug: bool = False
) -> Image.Image:
    """
    íŒŒë€/ì²­ë¡ ê³„ì—´ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ì „ì— 'ê²€ì •ì— ê°€ê¹ê²Œ' ì–´ë‘¡ê²Œ ë§Œë“ ë‹¤.
    - í° ë°°ê²½ê³¼ì˜ ëŒ€ë¹„ë¥¼ í‚¤ì›Œ OCRì—ì„œ ì˜…ì–´ì§€ëŠ” í˜„ìƒì„ ì™„í™”.
    - HSVì—ì„œ hue_centerÂ±hue_band ë²”ìœ„ë¥¼ ì¡ì•„ Vë¥¼ ê°ì‡ .
    """
    if cv2 is None:
        if debug: print("[blacken_bluish_text] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img

    arr = _pil_to_cv(img)
    if arr.ndim == 2:
        return img  # ì´ë¯¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼

    hsv = cv2.cvtColor(arr, cv2.COLOR_BGR2HSV)
    H, S, V = cv2.split(hsv)

    band = int(max(1, min(hue_band, 30)))
    c = int(np.clip(hue_center, 0, 180))
    low, high = c - band, c + band
    if low >= 0 and high <= 180:
        mask_h = (H >= low) & (H <= high)
    else:
        # 0~180 ê²½ê³„ë© ì²˜ë¦¬
        mask_h = (H >= (low % 180)) | (H <= (high % 180))

    mask = (mask_h & (S >= sat_thr) & (V >= min_v)).astype(np.uint8) * 255

    if thicken > 0:
        ker = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        mask = cv2.dilate(mask, ker, iterations=int(thicken))

    V2 = V.copy()
    V2[mask > 0] = (V2[mask > 0].astype(np.float32) * float(max(0.01, min(darken, 1.0)))).astype(np.uint8)

    hsv2 = cv2.merge([H, S, V2])
    out = cv2.cvtColor(hsv2, cv2.COLOR_HSV2BGR)
    if debug: print("[blacken_bluish_text] ì ìš© ì™„ë£Œ (center=%d, band=%d)" % (c, band))
    return _cv_to_pil(out)

# ---------- ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ----------
def to_grayscale(img: Image.Image) -> Image.Image:
    """
    8) ê·¸ë ˆì´ìŠ¤ì¼€ì¼: ë¬¸ì„œí˜• ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ëŒ€ë¹„ë¥¼ ë†’ì—¬ ì¸ì‹ ì•ˆì •í™”
    """
    if img.mode != "L":
        return img.convert("L")
    return img

# ---------- ì ì‘í˜• ì´ì§„í™”Â·ë¬¸ì„œìš© ----------
def adaptive_binarize_for_ocr(img: Image.Image, block_size: int = 25, k: float = 0.15, debug: bool = False) -> Image.Image:
    """
    new adaptive_binarize_for_ocr(ì ì‘í˜• ì´ì§„í™”Â·ë¬¸ì„œìš©)
    - scikit-imageì˜ Sauvolaê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ OpenCV ê°€ìš°ì‹œì•ˆ ì ì‘ ì´ì§„í™”
    """
    arr = _pil_to_cv(img)
    gray = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY) if (cv2 is not None and arr.ndim == 3) else (arr if arr.ndim == 2 else arr[:, :, 0])
    try:
        from skimage.filters import threshold_sauvola  # type: ignore
        win = block_size if block_size % 2 == 1 else block_size + 1
        thresh = threshold_sauvola(gray, window_size=win, k=k)
        bw = (gray > thresh).astype(np.uint8) * 255
        if debug: print("[adaptive_binarize_for_ocr] Sauvola ì ìš©")
    except Exception:
        if cv2 is None:
            if debug: print("[adaptive_binarize_for_ocr] OpenCV/Skimage ì—†ìŒ - ì›ë³¸ ë°˜í™˜")
            return img
        win = block_size if block_size % 2 == 1 else block_size + 1
        bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, win, 10)
        if debug: print("[adaptive_binarize_for_ocr] OpenCV ì ì‘ ì´ì§„í™” ì ìš©")
    return Image.fromarray(bw)

# ---------- ëª¨í´ë¡œì§€ë¡œ í‘œ ìˆ˜í‰/ìˆ˜ì§ ë¼ì¸ ì•½ ê°•í™” ----------
def enhance_table_lines(img: Image.Image, strength: float = 0.5, debug: bool = False) -> Image.Image:
    """
    new enhance_table_lines(ëª¨í´ë¡œì§€ë¡œ í‘œ ìˆ˜í‰/ìˆ˜ì§ ë¼ì¸ ì•½ ê°•í™”)
    - ë¸”ë™í–‡(black-hat)ìœ¼ë¡œ ì–´ë‘ìš´ ì„ ì„ ê°•ì¡° í›„ ì›ë³¸ì—ì„œ ì†ŒëŸ‰ ê°ì‚°
    """
    if cv2 is None:
        if debug: print("[enhance_table_lines] OpenCV ë¯¸ì„¤ì¹˜ - ì›ë³¸ ë°˜í™˜")
        return img
    im = _pil_to_cv(img)
    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) if im.ndim == 3 else im
    h, w = gray.shape[:2]
    hk = max(3, (w // 80) | 1)
    vk = max(3, (h // 80) | 1)
    hker = cv2.getStructuringElement(cv2.MORPH_RECT, (hk, 1))
    vker = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vk))
    hhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, hker)
    vhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, vker)
    comb = cv2.max(hhat, vhat)
    delta = (comb * np.clip(strength, 0.0, 1.0)).astype(np.uint8)
    enhanced = cv2.subtract(gray, delta)
    if im.ndim == 3:
        out = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
    else:
        out = enhanced
    if debug: print("[enhance_table_lines] ë¼ì¸ ê°•í™” ì™„ë£Œ")
    return _cv_to_pil(out)

# ---------- TSV ì•µì»¤ ê¸°ë°˜ í…Œì´ë¸” ìŠ¤ë§ˆíŠ¸ í¬ë¡­ ----------
def table_smart_crop(
    img: Image.Image,
    lang: str = "eng+kor",
    conf_min: int = 30,
    top_margin: int = 18,
    bottom_margin: int = 10,
    min_header_hits: int = 2,
    first_col_tolerance: int = 80,
    gap_multiplier: float = 2.8,
    min_rows: int = 5,
    debug: bool = True,
    min_table_height: int = 100,  # ğŸ†• ìµœì†Œ í…Œì´ë¸” ë†’ì´ íŒŒë¼ë¯¸í„°
) -> Image.Image:
    """
    í…Œì´ë¸” ìŠ¤ë§ˆíŠ¸ í¬ë¡­(1ìˆœìœ„: Tesseract TSV ì•µì»¤)
    - ìƒë‹¨: í—¤ë”(êµ­/ì˜ í‚¤ì›Œë“œ) ë˜ëŠ” ë°”ì´ì˜¤ë§ˆì»¤ ì—´ì˜ ì²« í´ëŸ¬ìŠ¤í„° ì‹œì‘
    - í•˜ë‹¨: ë‹¤ìŒ í—¤ë” ì§ì „ ë˜ëŠ” í° ìˆ˜ì§ ê³µë°±(í–‰ê°„ ì¤‘ì•™ê°’*k) ì§ì „
    - ì—¬ëŸ¬ í…Œì´ë¸”ì´ ìˆì–´ë„ ê°€ì¥ ìœ„ í…Œì´ë¸” 1ê°œë§Œ ë‚¨ê¹€
    """
    if debug:
        print(f"[table_smart_crop] ğŸš€ ì‹œì‘ - ì´ë¯¸ì§€ í¬ê¸°: {img.size}")
    
    try:
        pil = img if img.mode in ("L", "RGB") else img.convert("RGB")
        if debug:
            print(f"[table_smart_crop] ğŸ–¼ï¸ ì´ë¯¸ì§€ ëª¨ë“œ: {pil.mode}")

        # OCR
        if debug:
            print("[table_smart_crop] ğŸ“ OCR ì‹œì‘ (Tesseract)...")
        config = "--oem 3 --psm 4"
        data = image_to_data(pil, lang=lang, config=config, output_type=Output.DICT)
        n = len(data.get("text", []))
        if debug:
            print(f"[table_smart_crop] ğŸ“Š OCR ì™„ë£Œ - ì´ {n}ê°œ í…ìŠ¤íŠ¸ ìš”ì†Œ ê°ì§€")
        
        if n == 0:
            if debug:
                print("[table_smart_crop] âš ï¸ OCR ê²°ê³¼ ì—†ìŒ - ì›ë³¸ ë°˜í™˜")
            return img

        # ë‹¨ì–´ í† í° í•„í„°ë§
        if debug:
            print(f"[table_smart_crop] ğŸ” í† í° í•„í„°ë§ (ìµœì†Œ ì‹ ë¢°ë„: {conf_min})...")
        tokens = []
        for i in range(n):
            txt = (data["text"][i] or "").strip()
            if not txt:
                continue
            try:
                conf = float(data["conf"][i])
            except Exception:
                conf = -1
            if conf < conf_min:
                continue
            tokens.append(
                {
                    "text": txt,
                    "x": int(data["left"][i]),
                    "y": int(data["top"][i]),
                    "w": int(data["width"][i]),
                    "h": int(data["height"][i]),
                    "page": int(data["page_num"][i]),
                    "block": int(data["block_num"][i]),
                    "par": int(data["par_num"][i]),
                    "line": int(data["line_num"][i]),
                }
            )
        
        if debug:
            print(f"[table_smart_crop] âœ… ìœ íš¨í•œ í† í°: {len(tokens)}ê°œ")
        
        if not tokens:
            if debug:
                print("[table_smart_crop] âš ï¸ ìœ íš¨í•œ í† í° ì—†ìŒ - ì›ë³¸ ë°˜í™˜")
            return img

        # ë¼ì¸ ê·¸ë£¹í•‘
        if debug:
            print("[table_smart_crop] ğŸ“‹ ë¼ì¸ ê·¸ë£¹í•‘ ì‹œì‘...")
        from collections import defaultdict
        groups = defaultdict(list)
        for t in tokens:
            key = (t["page"], t["block"], t["par"], t["line"])
            groups[key].append(t)

        lines = []
        for key, group in groups.items():
            x0 = min(g["x"] for g in group)
            y0 = min(g["y"] for g in group)
            x1 = max(g["x"] + g["w"] for g in group)
            y1 = max(g["y"] + g["h"] for g in group)
            text_norm = " ".join(g["text"] for g in group).lower()
            lines.append({"x0": x0, "y0": y0, "x1": x1, "y1": y1, "text": text_norm})
        
        if debug:
            print(f"[table_smart_crop] âœ… ë¼ì¸ ê·¸ë£¹í•‘ ì™„ë£Œ: {len(lines)}ê°œ ë¼ì¸")
        
        if not lines:
            if debug:
                print("[table_smart_crop] âš ï¸ ë¼ì¸ ì—†ìŒ - ì›ë³¸ ë°˜í™˜")
            return img
        
        lines.sort(key=lambda l: l["y0"])

        # í—¤ë” í›„ë³´ íŒë‹¨(êµ­/ì˜ í˜¼í•©)
        if debug:
            print("[table_smart_crop] ğŸ” í—¤ë” ë¼ì¸ ê²€ìƒ‰ ì¤‘...")
        header_kws = {
            "name", "unit", "result", "reference", "ref", "min", "max",
            "í•­ëª©", "ê²€ì‚¬í•­ëª©", "ê²°ê³¼", "ë‹¨ìœ„", "ê¸°ì¤€ì¹˜", "ì°¸ì¡°ì¹˜", "ì°¸ê³ ì¹˜"
        }
        def is_header(l) -> bool:
            hits = sum(1 for kw in header_kws if kw in l["text"])
            return hits >= min_header_hits and len(l["text"]) >= 4

        header_lines = [l for l in lines if is_header(l)]
        header_lines.sort(key=lambda l: l["y0"])
        
        if debug:
            print(f"[table_smart_crop] ğŸ“Œ í—¤ë” ë¼ì¸ ë°œê²¬: {len(header_lines)}ê°œ")
            if header_lines:
                for idx, h in enumerate(header_lines[:5]):  # ğŸ†• ìµœëŒ€ 5ê°œë§Œ ì¶œë ¥
                    print(f"[table_smart_crop]    í—¤ë” {idx+1}: y={h['y0']}, text='{h['text'][:50]}...'")

        # ë°”ì´ì˜¤ë§ˆì»¤ ì•µì»¤(í—¤ë” ì‹¤íŒ¨ ëŒ€ë¹„)
        if debug:
            print("[table_smart_crop] ğŸ§¬ ë°”ì´ì˜¤ë§ˆì»¤ ê²€ìƒ‰ ì¤‘...")
        biomarker_kws = {
            "rbc","hct","hgb","mcv","mch","mchc","plt","wbc",
            "retic","glucose","glu","bun","crea","creatinine","ast","alt","alp",
            "mpv","pct","rdw","neut","lymph","mono","eos","baso"
        }
        def has_biomarker(l) -> bool:
            t = l["text"].replace("âˆ’", "-")
            return any(kw in t for kw in biomarker_kws)

        # ìƒë‹¨ y ê²°ì •
        if header_lines:
            if debug:
                print("[table_smart_crop] âœ… í—¤ë” ê¸°ë°˜ìœ¼ë¡œ ìƒë‹¨ ê³„ì‚°")
            top_header = header_lines[0]
            y_top = max(0, top_header["y0"] - top_margin)
            anchor_x = top_header["x0"]
            if debug:
                print(f"[table_smart_crop]    y_top={y_top}, anchor_x={anchor_x}")
        else:
            if debug:
                print("[table_smart_crop] ğŸ”„ í—¤ë” ì—†ìŒ - ë°”ì´ì˜¤ë§ˆì»¤ ì•µì»¤ ì‚¬ìš©")
            biomarker_lines = [l for l in lines if has_biomarker(l)]
            if not biomarker_lines:
                if debug:
                    print("[table_smart_crop] âŒ ë°”ì´ì˜¤ë§ˆì»¤ë„ ì—†ìŒ - ì›ë³¸ ë°˜í™˜")
                return img
            
            if debug:
                print(f"[table_smart_crop] âœ… ë°”ì´ì˜¤ë§ˆì»¤ ë¼ì¸: {len(biomarker_lines)}ê°œ")
            
            biomarker_lines.sort(key=lambda l: l["y0"])
            xs = np.array([l["x0"] for l in biomarker_lines])
            anchor_x = int(np.percentile(xs, 20))
            first_band = [l for l in biomarker_lines if abs(l["x0"] - anchor_x) <= first_col_tolerance] or biomarker_lines[:1]
            y_top = max(0, min(l["y0"] for l in first_band) - top_margin)
            if debug:
                print(f"[table_smart_crop]    y_top={y_top}, anchor_x={anchor_x}")

        # ğŸ†• í•˜ë‹¨ y ê²°ì • (ê°œì„ ëœ ë¡œì§)
        if debug:
            print("[table_smart_crop] ğŸ“ í•˜ë‹¨ ê²½ê³„ ê³„ì‚° ì¤‘...")
        
        # ë‹¤ìŒ í—¤ë” í•„í„°ë§: ì¶©ë¶„íˆ ë©€ë¦¬ ë–¨ì–´ì§„ í—¤ë”ë§Œ ê³ ë ¤
        below_headers = [l for l in header_lines if l["y0"] > y_top + min_table_height]
        
        if debug:
            print(f"[table_smart_crop]    ì¶©ë¶„íˆ ë©€ë¦¬ ë–¨ì–´ì§„ í—¤ë”: {len(below_headers)}ê°œ (ìµœì†Œ ê±°ë¦¬: {min_table_height}px)")
        
        if below_headers:
            # ë‹¤ìŒ í…Œì´ë¸”ì˜ í—¤ë”ë¥¼ ì°¾ì•˜ë‹¤ë©´ ê·¸ ì§ì „ê¹Œì§€
            y_bottom = max(y_top + min_table_height, below_headers[0]["y0"] - 10)
            if debug:
                print(f"[table_smart_crop] âœ… ë‹¤ìŒ í…Œì´ë¸” í—¤ë”ë¡œ í•˜ë‹¨ ê²°ì •: y_bottom={y_bottom}")
        else:
            # ë‹¤ìŒ í—¤ë”ê°€ ì—†ìœ¼ë©´ ê³µë°± ë¶„ì„ìœ¼ë¡œ í•˜ë‹¨ ê²°ì •
            if debug:
                print("[table_smart_crop] ğŸ”„ ë‹¤ìŒ í—¤ë” ì—†ìŒ - ê³µë°± ë¶„ì„ìœ¼ë¡œ í•˜ë‹¨ ê²°ì •")
            candidate = [l for l in lines if l["y0"] >= y_top]
            band = [l for l in candidate if abs(l["x0"] - anchor_x) <= first_col_tolerance]
            band.sort(key=lambda l: l["y0"])
            
            if debug:
                print(f"[table_smart_crop]    í…Œì´ë¸” í›„ë³´ ë¼ì¸: {len(band)}ê°œ")
            
            if len(band) < min_rows:
                if debug:
                    print(f"[table_smart_crop] âš ï¸ ìµœì†Œ í–‰ ìˆ˜ ë¶€ì¡± ({len(band)} < {min_rows})")
                    print(f"[table_smart_crop] ğŸ”„ ì „ì²´ ë¼ì¸ì—ì„œ ê³µë°± ë¶„ì„ ì‹œë„...")
                # ğŸ†• ì²« ì—´ ì œì•½ ì™„í™”: ì „ì²´ ë¼ì¸ì—ì„œ y_top ì´í›„ ëª¨ë“  ë¼ì¸ ê³ ë ¤
                band = [l for l in lines if l["y0"] >= y_top]
                band.sort(key=lambda l: l["y0"])
                
                if len(band) < min_rows:
                    if debug:
                        print(f"[table_smart_crop] âŒ ì „ì²´ ë¼ì¸ë„ ë¶€ì¡± ({len(band)} < {min_rows}) - ì›ë³¸ ë°˜í™˜")
                    return img
            
            gaps = [band[i+1]["y0"] - band[i]["y1"] for i in range(len(band)-1)]
            med_gap = np.median([g for g in gaps if g >= 0]) if gaps else 20
            thresh = max(24, med_gap * gap_multiplier)
            
            if debug:
                print(f"[table_smart_crop]    í–‰ê°„ ì¤‘ì•™ê°’: {med_gap:.1f}px, ê³µë°± ì„ê³„ê°’: {thresh:.1f}px")

            y_bottom = band[0]["y1"]
            prev_y1 = band[0]["y1"]
            row_count = 1
            for l in band[1:]:
                if (l["y0"] - prev_y1) > thresh:
                    if debug:
                        print(f"[table_smart_crop]    í° ê³µë°± ê°ì§€: {l['y0'] - prev_y1:.1f}px > {thresh:.1f}px")
                    break
                y_bottom = max(y_bottom, l["y1"])
                prev_y1 = l["y1"]
                row_count += 1
            
            y_bottom = min(img.height, int(y_bottom + bottom_margin))
            if debug:
                print(f"[table_smart_crop] âœ… í•˜ë‹¨ ê²°ì •: y_bottom={y_bottom}, í…Œì´ë¸” í–‰ ìˆ˜={row_count}")

        # ìµœì¢… ê²€ì¦
        final_height = y_bottom - y_top
        if final_height < 64:
            if debug:
                print(f"[table_smart_crop] âŒ í…Œì´ë¸” ë†’ì´ ë¶€ì¡± ({final_height}px < 64px) - ì›ë³¸ ë°˜í™˜")
            return img

        # í¬ë¡­ ì‹¤í–‰
        cropped = img.crop((0, int(y_top), img.width, int(y_bottom)))
        if debug:
            print(f"[table_smart_crop] âœ‚ï¸ í¬ë¡­ ì™„ë£Œ")
            print(f"[table_smart_crop]    ì›ë³¸: {img.size} â†’ í¬ë¡­: {cropped.size}")
            print(f"[table_smart_crop]    ì˜ì—­: y_top={int(y_top)}, y_bottom={int(y_bottom)}")
            print(f"[table_smart_crop]    í¬ë¡­ ë†’ì´: {final_height}px")
        
        return cropped

    except Exception as e:
        if debug:
            print(f"[table_smart_crop] âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
        return img

# ---------- ì–‡ì€ í°ìƒ‰ í…Œë‘ë¦¬ ì¶”ê°€ ----------
def add_white_border(img: Image.Image, border: int = 4) -> Image.Image:
    """
    10) í…Œë‘ë¦¬ ì¶”ê°€: ê°€ì¥ìë¦¬ ë¬¸ìê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ ì–‡ì€ í°ìƒ‰ ì—¬ë°±
    """
    if border and border > 0:
        fill = 255 if img.mode == "L" else (255, 255, 255)
        return ImageOps.expand(img, border=border, fill=fill)
    return img

# ---------- ëª©í‘œ í•´ìƒë„ë¡œ ë‹¤ìš´ìŠ¤ì¼€ì¼ ----------
def downscale_target_long_edge(img: Image.Image, target_long_edge: int = 1920) -> Image.Image:
    """
    11) í•´ìƒë„ í‘œì¤€í™”(ë‹¤ìš´ìŠ¤ì¼€ì¼ í—ˆìš©): ê³¼ëŒ€ í¬ê¸°ëŠ” ì¶•ì†Œ
    """
    w, h = img.size
    long_edge = max(w, h)
    if long_edge > target_long_edge:
        scale = target_long_edge / float(long_edge)
        img = img.resize((int(round(w * scale)), int(round(h * scale))), Image.LANCZOS)
    return img

# ---------- OCR í’ˆì§ˆ ê²Œì´íŠ¸ ----------
def _tesseract_metrics(pil_img: Image.Image, lang: str = "eng+kor") -> dict:
    try:
        data = image_to_data(pil_img, lang=lang, config="--oem 3 --psm 6", output_type=Output.DICT)
        confs = []
        for c in data.get("conf", []):
            try:
                v = float(c)
                if v >= 0:
                    confs.append(v)
            except Exception:
                pass
        mean_conf = float(np.mean(confs)) if confs else 0.0
        n_tokens = int(len(confs))
        return {"mean_conf": mean_conf, "tokens": n_tokens}
    except Exception:
        return {"mean_conf": 0.0, "tokens": 0}

def ocr_quality_gate(
    img: Image.Image,
    baseline_img: Optional[Image.Image] = None,
    lang: str = "eng+kor",
    min_delta_conf: float = -1.0,
    min_delta_tokens: int = -9999,
    debug: bool = True,
) -> Image.Image:
    """
    new ocr_quality_gate(í† í° ìˆ˜/í‰ê·  conf ê¸°ë°˜ í’ˆì§ˆ ì ê²€Â·ì•…í™” ì‹œ ì´ì „ ë‹¨ê³„ ë¡¤ë°±)
    - baseline_imgê°€ ì£¼ì–´ì§€ë©´ í˜„ì¬ ì´ë¯¸ì§€ê°€ í’ˆì§ˆì´ ë” ë‚˜ì˜ë©´ baselineìœ¼ë¡œ ë¡¤ë°±
    - min_delta_*ëŠ” 'í˜„ì¬ - ê¸°ì¤€'ì˜ ìµœì†Œ í—ˆìš© ë³€í™”ëŸ‰(ìŒìˆ˜ í—ˆìš©). ë” ë‚®ìœ¼ë©´ ë¡¤ë°±.
    """
    cur = _tesseract_metrics(img, lang=lang)
    if baseline_img is None:
        # ë©”íŠ¸ë¦­ë§Œ ê¸°ë¡í•˜ê³  í†µê³¼
        try:
            img.info["ocr_quality"] = cur
        except Exception:
            pass
        if debug: print(f"[ocr_quality_gate] conf={cur['mean_conf']:.1f}, tokens={cur['tokens']}")
        return img

    base = _tesseract_metrics(baseline_img, lang=lang)
    d_conf = cur["mean_conf"] - base["mean_conf"]
    d_tok = cur["tokens"] - base["tokens"]
    if debug:
        print(f"[ocr_quality_gate] Î”conf={d_conf:.1f}, Î”tok={d_tok}")
    worse = (d_conf < min_delta_conf) or (d_tok < min_delta_tokens)
    return baseline_img if worse else img

# ---------- PNG ë¬´ì†ì‹¤ ì €ì¥ ----------
def save_png_bytes(img: Image.Image, compress_level: int = 6) -> bytes:
    """
    12) PNG ì €ì¥(ë¬´ì†ì‹¤): í…ìŠ¤íŠ¸/ê¸°í˜¸ ë³´ì¡´ì— ìœ ë¦¬
    """
    buf = io.BytesIO()
    img.save(buf, format="PNG", optimize=True, compress_level=compress_level)
    return buf.getvalue()

def apply_pipeline(img: Image.Image, steps: Sequence[tuple[Callable, dict]]) -> Image.Image:
    """
    ì²´ì´ë‹ ì‹¤í–‰ ìœ í‹¸. [(func, kwargs), ...] í˜•íƒœë¡œ ì „ë‹¬ëœ ìŠ¤í…ì„ ìˆœì„œëŒ€ë¡œ ì ìš©.
    """
    for func, kwargs in steps:
        img = func(img, **kwargs)
    return img