"""
Korean OCR using PaddleOCR

ì´ ëª¨ë“ˆì€ PaddleOCRì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

Author: yunwoong7 (modified for latest PaddleOCR compatibility)
License: Apache 2.0
"""

import cv2
import numpy as np
import re
from paddleocr import PaddleOCR
from app.services.analysis import line_preprocessor as lp
import jsonpickle
from typing import Optional
import json

class PaddleOCRService:
    """
    PaddleOCRì„ ì‚¬ìš©í•œ í•œêµ­ì–´ OCR í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” PaddleOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë˜í•‘í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    ìµœì‹  PaddleOCR APIì™€ í˜¸í™˜ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Attributes:
        lang (str): ì¸ì‹í•  ì–¸ì–´ ì„¤ì • (ê¸°ë³¸ê°’: "korean")
        _ocr (PaddleOCR): PaddleOCR ì¸ìŠ¤í„´ìŠ¤
    """
    
    def __init__(self, lang: str = "korean", **kwargs):
        """
        MyPaddleOCR í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            lang (str): ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "korean")
            **kwargs: PaddleOCRì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        """
        self.lang = lang
        self.init_kwargs = kwargs.copy()  # ì´ˆê¸°í™”ì— ì‚¬ìš©ëœ ì¶”ê°€ ì¸ì ì €ì¥
        
        # PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì „ë‹¬ë°›ì€ ëª¨ë“  íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        self._ocr_engine = PaddleOCR(
            lang=self.lang, 
            use_doc_orientation_classify=True, # ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜/êµì • ëª¨ë¸ ë¡œë“œ
            use_doc_unwarping=True,            # ë¬¸ì„œ íœ˜ì–´ì§ ë³´ì • 
            use_textline_orientation=True,     # ë°©í–¥ ë¶„ë¥˜ í™œì„±í™”

            # text_detection_model_name="PP-OCRv5_server_det",
            # text_recognition_model_name="korean_PP-OCRv5_server_rec",
            # text_det_limit_side_len=1920,      # ì´ë¯¸ì§€ í¬ê¸° 
            # text_det_thresh=0.25,               # ê°ì§€ ì„ê³„ê°’ 
            # text_rec_score_thresh=0.75,         # ì¸ì‹ ì„ê³„ê°’ 

            # text_recognition_batch_size=1,     # ë°°ì¹˜ í¬ê¸°         
            # return_word_box=True,              # ë‹¨ì–´ë³„ ë°•ìŠ¤ ë°˜í™˜       
            # text_det_unclip_ratio=2.5,         # í…ìŠ¤íŠ¸ ë°•ìŠ¤ í™•ì¥  
            **kwargs
        )

    def get_available_langs(self):
        """
        PaddleOCRì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Note:
            PaddleOCR 3.2.0ì—ì„œëŠ” ë™ì  ì–¸ì–´ ëª©ë¡ ì¡°íšŒ APIê°€ ì œê³µë˜ì§€ ì•Šì•„
            ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ì˜ ì „ì²´ ì§€ì› ì–¸ì–´ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        # PaddleOCR 3.2.0ì—ì„œ ê³µì‹ ì§€ì›í•˜ëŠ” ì „ì²´ ì–¸ì–´ ëª©ë¡
        langs_info = [
            'ch', 'en', 'korean', 'japan', 'chinese_cht',  # ì£¼ìš” ë™ì•„ì‹œì•„ ì–¸ì–´
            'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic',  # ë‹¤ì–‘í•œ ë¬¸ìì²´ê³„
            'devanagari', 'french', 'german', 'it', 'xi',  # ìœ ëŸ½ ì–¸ì–´
            'pu', 'ru', 'ar', 'hi', 'ug', 'fa', 'ur',  # ì¤‘ë™/ë‚¨ì•„ì‹œì•„ ì–¸ì–´
            'rs_latin', 'oc', 'rs_cyrillic', 'bg', 'uk', 'be',  # ë™ìœ ëŸ½ ì–¸ì–´
            'kn', 'ch_tra', 'mr', 'ne'  # ì¶”ê°€ ì§€ì› ì–¸ì–´
        ]
        
        print(f'Available Languages ({len(langs_info)} total):')
        print(langs_info)
        
        # ì£¼ìš” ì–¸ì–´ ì„¤ëª…
        major_langs = {
            'ch': 'ì¤‘êµ­ì–´ (ê°„ì²´)',
            'en': 'ì˜ì–´',
            'korean': 'í•œêµ­ì–´',
            'japan': 'ì¼ë³¸ì–´',
            'chinese_cht': 'ì¤‘êµ­ì–´ (ë²ˆì²´)',
            'french': 'í”„ë‘ìŠ¤ì–´',
            'german': 'ë…ì¼ì–´',
            'ru': 'ëŸ¬ì‹œì•„ì–´',
            'ar': 'ì•„ëì–´',
            'hi': 'íŒë””ì–´'
        }
        
        print(f'\nMajor supported languages:')
        for code, name in major_langs.items():
            print(f'  {code:12} - {name}')
            
        return langs_info
    
    def check_language_support(self, lang_code: str):
        """
        íŠ¹ì • ì–¸ì–´ê°€ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            lang_code (str): í™•ì¸í•  ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'korean', 'en', 'ch')
        
        Returns:
            bool: ì§€ì› ì—¬ë¶€
        """
        supported_langs = [
            'ch', 'en', 'korean', 'japan', 'chinese_cht',
            'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic',
            'devanagari', 'french', 'german', 'it', 'xi',
            'pu', 'ru', 'ar', 'hi', 'ug', 'fa', 'ur',
            'rs_latin', 'oc', 'rs_cyrillic', 'bg', 'uk', 'be',
            'kn', 'ch_tra', 'mr', 'ne'
        ]
        
        is_supported = lang_code in supported_langs
        print(f"Language '{lang_code}': {'âœ… Supported' if is_supported else 'âŒ Not supported'}")
        
        if not is_supported:
            # ìœ ì‚¬í•œ ì–¸ì–´ ì œì•ˆ
            suggestions = [lang for lang in supported_langs if lang.startswith(lang_code[:2])]
            if suggestions:
                print(f"Did you mean: {suggestions}")
        
        return is_supported
        
    def get_available_models(self):
        """
        PaddleOCRì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ì§€ì› ì–¸ì–´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ê³¼ ì´ë¡ ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ëª¨ë¸ì„ ëª¨ë‘ ë³´ì—¬ì¤ë‹ˆë‹¤.
        """
        import os
        
        print("ğŸ¤– PaddleOCR ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´")
        print("=" * 60)
        
        # 1. ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸
        model_dir = os.path.expanduser("~/.paddlex/official_models")
        downloaded_models = []
        
        if os.path.exists(model_dir):
            try:
                downloaded_models = [item for item in os.listdir(model_dir) 
                                   if os.path.isdir(os.path.join(model_dir, item))]
                print(f"âœ… ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ({len(downloaded_models)}ê°œ):")
                
                # ëª¨ë¸ ë¶„ë¥˜
                detection_models = [m for m in downloaded_models if 'det' in m.lower()]
                recognition_models = [m for m in downloaded_models if 'rec' in m.lower()]
                orientation_models = [m for m in downloaded_models if 'ori' in m.lower() or 'doc' in m.lower()]
                other_models = [m for m in downloaded_models if m not in detection_models + recognition_models + orientation_models]
                
                if detection_models:
                    print("  ğŸ” í…ìŠ¤íŠ¸ ê°ì§€ ëª¨ë¸:")
                    for model in detection_models:
                        version = "PP-OCRv5" if "v5" in model else ("PP-OCRv4" if "v4" in model else "PP-OCR")
                        print(f"    ğŸ“¦ {model} ({version})")
                
                if recognition_models:
                    print("  ğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸:")
                    for model in recognition_models:
                        version = "PP-OCRv5" if "v5" in model else ("PP-OCRv4" if "v4" in model else "PP-OCR")
                        lang = "í•œêµ­ì–´" if "korean" in model else ("ì˜ì–´" if "en" in model else "ê¸°íƒ€")
                        size = "ëª¨ë°”ì¼" if "mobile" in model else "ì„œë²„"
                        print(f"    ğŸ“¦ {model} ({version}, {lang}, {size})")
                
                if orientation_models:
                    print("  ğŸ“ ë°©í–¥/êµ¬ì¡° ë³´ì • ëª¨ë¸:")
                    for model in orientation_models:
                        print(f"    ğŸ“¦ {model}")
                
                if other_models:
                    print("  ğŸ”§ ê¸°íƒ€ ëª¨ë¸:")
                    for model in other_models:
                        print(f"    ğŸ“¦ {model}")
                        
            except PermissionError:
                print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ")
        else:
            print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        print("\n" + "=" * 60)
        
        return downloaded_models
    
    def get_current_model_info(self):
        """
        í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ OCR ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì‹¤ì œ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë™ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Returns:
            dict: í˜„ì¬ ëª¨ë¸ ì •ë³´
        """
        print("ğŸ” í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´ (ì‹¤ì œ ì„¤ì •)")
        print("=" * 50)
        
        # ì‹¤ì œ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
        try:
            # _paramsì—ì„œ ì‹¤ì œ ì„¤ì •ëœ ëª¨ë¸ëª… ì¶”ì¶œ
            params = self._ocr_engine._params
            config = self._ocr_engine._merged_paddlex_config
            
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ë“¤
            detection_model = params.get('text_detection_model_name', 'Unknown')
            recognition_model = params.get('text_recognition_model_name', 'Unknown')
            
            # configì—ì„œ ì„¸ë¶€ ëª¨ë¸ë“¤ ì¶”ì¶œ
            sub_modules = config.get('SubModules', {})
            sub_pipelines = config.get('SubPipelines', {})
            
            # ë¬¸ì„œ ì „ì²˜ë¦¬ ëª¨ë¸ë“¤
            doc_models = []
            if 'DocPreprocessor' in sub_pipelines:
                doc_preprocessor = sub_pipelines['DocPreprocessor'].get('SubModules', {})
                if 'DocOrientationClassify' in doc_preprocessor:
                    doc_ori_model = doc_preprocessor['DocOrientationClassify'].get('model_name')
                    if doc_ori_model:
                        doc_models.append(doc_ori_model)
                if 'DocUnwarping' in doc_preprocessor:
                    doc_unwarp_model = doc_preprocessor['DocUnwarping'].get('model_name')
                    if doc_unwarp_model:
                        doc_models.append(doc_unwarp_model)
            
            # í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë³´ì • ëª¨ë¸
            textline_ori_model = None
            if 'TextLineOrientation' in sub_modules:
                textline_ori_model = sub_modules['TextLineOrientation'].get('model_name')
            
            # ëª¨ë¸ ì •ë³´ êµ¬ì„±
            model_info = {
                'language': self.lang,
                'version': 'PP-OCRv5',  # ëª¨ë“  ëª¨ë¸ì´ v5ì„ì„ í™•ì¸
                'detection_model': detection_model,
                'recognition_model': recognition_model,
                'doc_orientation_models': doc_models,
                'textline_orientation_model': textline_ori_model,
                'pipeline_config': {
                    'use_doc_preprocessor': config.get('use_doc_preprocessor', False),
                    'use_textline_orientation': config.get('use_textline_orientation', False),
                    'text_type': config.get('text_type', 'general')
                }
            }
            
            # ìƒì„¸ ì¶œë ¥
            print(f"ğŸ“Œ ì„¤ì • ì–¸ì–´: {model_info['language']}")
            print(f"ğŸ“Œ íŒŒì´í”„ë¼ì¸: {config.get('pipeline_name', 'OCR')}")
            print(f"ğŸ“Œ í…ìŠ¤íŠ¸ ìœ í˜•: {model_info['pipeline_config']['text_type']}")
            print(f"ğŸ“Œ ëª¨ë¸ ë²„ì „: {model_info['version']}")
            
            print(f"\nğŸ” í•µì‹¬ ëª¨ë¸:")
            print(f"   í…ìŠ¤íŠ¸ ê°ì§€: {model_info['detection_model']}")
            print(f"   í…ìŠ¤íŠ¸ ì¸ì‹: {model_info['recognition_model']}")
            
            if model_info['doc_orientation_models']:
                print(f"\nğŸ“ ë¬¸ì„œ ì „ì²˜ë¦¬ ëª¨ë¸:")
                for model in model_info['doc_orientation_models']:
                    model_type = "ë°©í–¥ ë³´ì •" if "ori" in model else "ë¬¸ì„œ êµì •"
                    print(f"   {model} ({model_type})")
            
            if model_info['textline_orientation_model']:
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë³´ì •:")
                print(f"   {model_info['textline_orientation_model']}")
            
            # ì„¤ì • ì •ë³´
            print(f"\nâš™ï¸  íŒŒì´í”„ë¼ì¸ ì„¤ì •:")
            print(f"   ë¬¸ì„œ ì „ì²˜ë¦¬: {'âœ…' if model_info['pipeline_config']['use_doc_preprocessor'] else 'âŒ'}")
            print(f"   í…ìŠ¤íŠ¸ë¼ì¸ ë³´ì •: {'âœ…' if model_info['pipeline_config']['use_textline_orientation'] else 'âŒ'}")
            
            # ì‹¤ì œ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´
            if 'TextDetection' in sub_modules:
                det_config = sub_modules['TextDetection']
                print(f"\nğŸ” ê°ì§€ ëª¨ë¸ ì„¤ì •:")
                print(f"   ì„ê³„ê°’: {det_config.get('thresh', 'N/A')}")
                print(f"   ë°•ìŠ¤ ì„ê³„ê°’: {det_config.get('box_thresh', 'N/A')}")
                print(f"   ì–¸í´ë¦½ ë¹„ìœ¨: {det_config.get('unclip_ratio', 'N/A')}")
            
            if 'TextRecognition' in sub_modules:
                rec_config = sub_modules['TextRecognition']
                print(f"\nğŸ“ ì¸ì‹ ëª¨ë¸ ì„¤ì •:")
                print(f"   ë°°ì¹˜ í¬ê¸°: {rec_config.get('batch_size', 'N/A')}")
                print(f"   ì ìˆ˜ ì„ê³„ê°’: {rec_config.get('score_thresh', 'N/A')}")
            
            # ì„±ëŠ¥ íŠ¹ì„± (ì‹¤ì œ ì„¤ì • ê¸°ë°˜)
            is_korean = self.lang == 'korean'
            is_mobile_rec = 'mobile' in recognition_model
            is_server_det = 'server' in detection_model
            
            print(f"\nğŸ“Š ì„±ëŠ¥ íŠ¹ì„± (ì‹¤ì œ ì„¤ì • ê¸°ë°˜):")
            print(f"   ëª¨ë¸ ì¡°í•©: {'ì„œë²„ê¸‰ ê°ì§€' if is_server_det else 'ëª¨ë°”ì¼ ê°ì§€'} + {'ëª¨ë°”ì¼ ì¸ì‹' if is_mobile_rec else 'ì„œë²„ê¸‰ ì¸ì‹'}")
            print(f"   í•œêµ­ì–´ ìµœì í™”: {'âœ…' if is_korean else 'âŒ'}")
            print(f"   ì‹¤ì‹œê°„ ì²˜ë¦¬: {'âœ…' if is_mobile_rec else 'âš¡ ê³ ì„±ëŠ¥'}")
            print(f"   ë¬¸ì„œ ì²˜ë¦¬: {'âœ… ê³ ê¸‰' if model_info['pipeline_config']['use_doc_preprocessor'] else 'âŒ ê¸°ë³¸'}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ fallback
            model_info = {
                'language': self.lang,
                'version': 'PP-OCRv5',
                'detection_model': 'PP-OCRv5_server_det',
                'recognition_model': f'{self.lang}_PP-OCRv5_mobile_rec',
                'error': str(e)
            }
            print(f"ğŸ“Œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í‘œì‹œ: {self.lang} ì–¸ì–´, PP-OCRv5 ëª¨ë¸")
        
        return model_info
        
    def get_current_preprocessing_settings(self):
        """
        í˜„ì¬ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì— ì‹¤ì œë¡œ ì ìš©ëœ ëª¨ë“  ì „ì²˜ë¦¬ ì„¤ì •ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Returns:
            dict: í˜„ì¬ ì „ì²˜ë¦¬ ì„¤ì • ì •ë³´
        """
        print("ğŸ”§ í˜„ì¬ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì˜ ì „ì²˜ë¦¬ ì„¤ì • (ì‹¤ì œ ì ìš©ë¨)")
        print("=" * 70)
        
        preprocessing_settings = {}
        
        try:
            # PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤ì œ ì„¤ì • ì¶”ì¶œ
            params = self._ocr_engine._params
            config = self._ocr_engine._merged_paddlex_config
            sub_modules = config.get('SubModules', {})
            sub_pipelines = config.get('SubPipelines', {})
            
            # 1. ê¸°ë³¸ ì‹œìŠ¤í…œ ì„¤ì •
            system_settings = {
                'language': self.lang,
                'pipeline_name': config.get('pipeline_name', 'OCR'),
                'text_type': config.get('text_type', 'general'),
                'use_gpu': params.get('use_gpu', True),
                'gpu_id': params.get('gpu_id', 0),
                'cpu_threads': params.get('cpu_threads', 10),
                'enable_mkldnn': params.get('enable_mkldnn', True),
                'warmup': params.get('warmup', True),
                'show_log': params.get('show_log', False)
            }
            preprocessing_settings['system'] = system_settings
            
            print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ ì„¤ì •:")
            print(f"   ì–¸ì–´: {system_settings['language']}")
            print(f"   íŒŒì´í”„ë¼ì¸: {system_settings['pipeline_name']}")
            print(f"   í…ìŠ¤íŠ¸ ìœ í˜•: {system_settings['text_type']}")
            print(f"   GPU ì‚¬ìš©: {'âœ…' if system_settings['use_gpu'] else 'âŒ'}")
            print(f"   GPU ID: {system_settings['gpu_id']}")
            print(f"   CPU ìŠ¤ë ˆë“œ: {system_settings['cpu_threads']}")
            print(f"   MKLDNN ìµœì í™”: {'âœ…' if system_settings['enable_mkldnn'] else 'âŒ'}")
            print(f"   ëª¨ë¸ ì›Œë°ì—…: {'âœ…' if system_settings['warmup'] else 'âŒ'}")
            print(f"   ë¡œê·¸ ì¶œë ¥: {'âœ…' if system_settings['show_log'] else 'âŒ'}")
            
            # 2. í…ìŠ¤íŠ¸ ê°ì§€ ì „ì²˜ë¦¬ ì„¤ì •
            detection_settings = {}
            if 'TextDetection' in sub_modules:
                det_config = sub_modules['TextDetection']
                detection_settings = {
                    'model_name': det_config.get('model_name', 'Unknown'),
                    'thresh': det_config.get('thresh', 0.3),
                    'box_thresh': det_config.get('box_thresh', 0.6),
                    'unclip_ratio': det_config.get('unclip_ratio', 1.5),
                    'max_side_len': det_config.get('max_side_len', 960),
                    'limit_type': det_config.get('limit_type', 'max'),
                    'use_dilation': det_config.get('use_dilation', True),
                    'score_mode': det_config.get('score_mode', 'fast'),
                    'polygon': det_config.get('polygon', False),
                    'visualize': det_config.get('visualize', False)
                }
                preprocessing_settings['detection'] = detection_settings
                
                print(f"\nğŸ” í…ìŠ¤íŠ¸ ê°ì§€ ì „ì²˜ë¦¬:")
                print(f"   ëª¨ë¸: {detection_settings['model_name']}")
                print(f"   ê°ì§€ ì„ê³„ê°’: {detection_settings['thresh']}")
                print(f"   ë°•ìŠ¤ ì„ê³„ê°’: {detection_settings['box_thresh']}")
                print(f"   ì–¸í´ë¦½ ë¹„ìœ¨: {detection_settings['unclip_ratio']}")
                print(f"   ìµœëŒ€ ë³€ ê¸¸ì´: {detection_settings['max_side_len']}px")
                print(f"   í¬ê¸° ì œí•œ ë°©ì‹: {detection_settings['limit_type']}")
                print(f"   íŒ½ì°½ ì—°ì‚°: {'âœ…' if detection_settings['use_dilation'] else 'âŒ'}")
                print(f"   ì ìˆ˜ ê³„ì‚° ëª¨ë“œ: {detection_settings['score_mode']}")
                print(f"   ë‹¤ê°í˜• ê°ì§€: {'âœ…' if detection_settings['polygon'] else 'âŒ'}")
                print(f"   ì‹œê°í™”: {'âœ…' if detection_settings['visualize'] else 'âŒ'}")
            
            # 3. í…ìŠ¤íŠ¸ ì¸ì‹ ì „ì²˜ë¦¬ ì„¤ì •
            recognition_settings = {}
            if 'TextRecognition' in sub_modules:
                rec_config = sub_modules['TextRecognition']
                recognition_settings = {
                    'model_name': rec_config.get('model_name', 'Unknown'),
                    'batch_size': rec_config.get('batch_size', 6),
                    'score_thresh': rec_config.get('score_thresh', 0.5),
                    'max_text_length': rec_config.get('max_text_length', 25),
                    'image_shape': rec_config.get('image_shape', [3, 48, 320]),
                    'use_space_char': rec_config.get('use_space_char', True),
                    'limited_max_width': rec_config.get('limited_max_width', 1280),
                    'limited_min_width': rec_config.get('limited_min_width', 16),
                    'char_dict_path': rec_config.get('char_dict_path', None),
                    'visualize': rec_config.get('visualize', False)
                }
                preprocessing_settings['recognition'] = recognition_settings
                
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ ì „ì²˜ë¦¬:")
                print(f"   ëª¨ë¸: {recognition_settings['model_name']}")
                print(f"   ë°°ì¹˜ í¬ê¸°: {recognition_settings['batch_size']}")
                print(f"   ì ìˆ˜ ì„ê³„ê°’: {recognition_settings['score_thresh']}")
                print(f"   ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´: {recognition_settings['max_text_length']}")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {recognition_settings['image_shape']}")
                print(f"   ê³µë°± ë¬¸ì ì‚¬ìš©: {'âœ…' if recognition_settings['use_space_char'] else 'âŒ'}")
                print(f"   ìµœëŒ€ ë„ˆë¹„ ì œí•œ: {recognition_settings['limited_max_width']}px")
                print(f"   ìµœì†Œ ë„ˆë¹„ ì œí•œ: {recognition_settings['limited_min_width']}px")
                print(f"   ë¬¸ì ì‚¬ì „: {recognition_settings['char_dict_path'] or 'ê¸°ë³¸ê°’'}")
                print(f"   ì‹œê°í™”: {'âœ…' if recognition_settings['visualize'] else 'âŒ'}")
            
            # 4. í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜ ì „ì²˜ë¦¬ ì„¤ì •
            orientation_settings = {}
            if 'TextLineOrientation' in sub_modules:
                ori_config = sub_modules['TextLineOrientation']
                orientation_settings = {
                    'model_name': ori_config.get('model_name', 'Unknown'),
                    'score_thresh': ori_config.get('score_thresh', 0.9),
                    'batch_size': ori_config.get('batch_size', 6),
                    'image_shape': ori_config.get('image_shape', [3, 48, 192]),
                    'label_list': ori_config.get('label_list', ['0', '180']),
                    'visualize': ori_config.get('visualize', False)
                }
                preprocessing_settings['orientation'] = orientation_settings
                
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜ ì „ì²˜ë¦¬:")
                print(f"   ëª¨ë¸: {orientation_settings['model_name']}")
                print(f"   ë¶„ë¥˜ ì„ê³„ê°’: {orientation_settings['score_thresh']}")
                print(f"   ë°°ì¹˜ í¬ê¸°: {orientation_settings['batch_size']}")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {orientation_settings['image_shape']}")
                print(f"   ì§€ì› ê°ë„: {orientation_settings['label_list']}")
                print(f"   ì‹œê°í™”: {'âœ…' if orientation_settings['visualize'] else 'âŒ'}")
            else:
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜ ì „ì²˜ë¦¬: âŒ ë¹„í™œì„±í™”")
            
            # 5. ë¬¸ì„œ ì „ì²˜ë¦¬ ì„¤ì • (ê³ ê¸‰)
            doc_preprocessing_settings = {}
            if 'DocPreprocessor' in sub_pipelines:
                doc_preprocessor = sub_pipelines['DocPreprocessor']
                doc_sub_modules = doc_preprocessor.get('SubModules', {})
                
                doc_preprocessing_settings['enabled'] = True
                doc_preprocessing_settings['modules'] = {}
                
                print(f"\nğŸ“„ ë¬¸ì„œ ì „ì²˜ë¦¬ (ê³ ê¸‰ ê¸°ëŠ¥):")
                
                # ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜
                if 'DocOrientationClassify' in doc_sub_modules:
                    doc_ori_config = doc_sub_modules['DocOrientationClassify']
                    doc_ori_settings = {
                        'model_name': doc_ori_config.get('model_name', 'Unknown'),
                        'score_thresh': doc_ori_config.get('score_thresh', 0.9),
                        'batch_size': doc_ori_config.get('batch_size', 1)
                    }
                    doc_preprocessing_settings['modules']['orientation'] = doc_ori_settings
                    
                    print(f"   ğŸ”„ ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜:")
                    print(f"      ëª¨ë¸: {doc_ori_settings['model_name']}")
                    print(f"      ì„ê³„ê°’: {doc_ori_settings['score_thresh']}")
                    print(f"      ë°°ì¹˜ í¬ê¸°: {doc_ori_settings['batch_size']}")
                
                # ë¬¸ì„œ êµì • (ì–¸ì›Œí•‘)
                if 'DocUnwarping' in doc_sub_modules:
                    doc_unwarp_config = doc_sub_modules['DocUnwarping']
                    doc_unwarp_settings = {
                        'model_name': doc_unwarp_config.get('model_name', 'Unknown'),
                        'batch_size': doc_unwarp_config.get('batch_size', 1)
                    }
                    doc_preprocessing_settings['modules']['unwarping'] = doc_unwarp_settings
                    
                    print(f"   ğŸ“ ë¬¸ì„œ êµì • (ì–¸ì›Œí•‘):")
                    print(f"      ëª¨ë¸: {doc_unwarp_settings['model_name']}")
                    print(f"      ë°°ì¹˜ í¬ê¸°: {doc_unwarp_settings['batch_size']}")
                
                preprocessing_settings['document'] = doc_preprocessing_settings
            else:
                print(f"\nğŸ“„ ë¬¸ì„œ ì „ì²˜ë¦¬: âŒ ë¹„í™œì„±í™” (ì¼ë°˜ ëª¨ë“œ)")
                preprocessing_settings['document'] = {'enabled': False}
            
            # 6. ì´ë¯¸ì§€ ì…ë ¥ ì „ì²˜ë¦¬ ì„¤ì • (ì¶”ë¡ )
            image_preprocessing = {
                'auto_resize': True,
                'max_side_len': detection_settings.get('max_side_len', 960),
                'normalize': True,
                'channel_order': 'BGR',
                'data_type': 'float32',
                'interpolation': 'LANCZOS',
                'padding': False
            }
            preprocessing_settings['image'] = image_preprocessing
            
            print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ ì…ë ¥ ì „ì²˜ë¦¬ (ì¶”ë¡ ë¨):")
            print(f"   ìë™ í¬ê¸° ì¡°ì •: {'âœ…' if image_preprocessing['auto_resize'] else 'âŒ'}")
            print(f"   ìµœëŒ€ ë³€ ê¸¸ì´: {image_preprocessing['max_side_len']}px")
            print(f"   ì •ê·œí™”: {'âœ…' if image_preprocessing['normalize'] else 'âŒ'}")
            print(f"   ì±„ë„ ìˆœì„œ: {image_preprocessing['channel_order']}")
            print(f"   ë°ì´í„° íƒ€ì…: {image_preprocessing['data_type']}")
            print(f"   ë³´ê°„ë²•: {image_preprocessing['interpolation']}")
            print(f"   íŒ¨ë”©: {'âœ…' if image_preprocessing['padding'] else 'âŒ'}")
            
            # 7. ì´ˆê¸°í™” ì‹œ ì‚¬ìš©ëœ ì»¤ìŠ¤í…€ ì˜µì…˜ë“¤
            custom_settings = {}
            if self.init_kwargs:
                custom_settings = self.init_kwargs.copy()
                preprocessing_settings['custom'] = custom_settings
                
                print(f"\nâš™ï¸  ì´ˆê¸°í™” ì‹œ ì»¤ìŠ¤í…€ ì„¤ì •:")
                for key, value in custom_settings.items():
                    print(f"   {key}: {value}")
            else:
                print(f"\nâš™ï¸  ì´ˆê¸°í™” ì‹œ ì»¤ìŠ¤í…€ ì„¤ì •: âŒ ëª¨ë“  ê¸°ë³¸ê°’ ì‚¬ìš©")
            
            # 8. íŒŒì´í”„ë¼ì¸ í”Œë¡œìš° ìš”ì•½
            print(f"\nğŸ”„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°:")
            
            flow_steps = []
            flow_steps.append("1. ì´ë¯¸ì§€ ë¡œë“œ ë° í¬ê¸° ì¡°ì •")
            
            if preprocessing_settings['document']['enabled']:
                doc_section = preprocessing_settings.get('document') if isinstance(preprocessing_settings, dict) else None
                doc_modules = doc_section.get('modules', {}) if isinstance(doc_section, dict) else {}
                if isinstance(doc_modules, dict) and 'orientation' in doc_modules:
                    flow_steps.append("2. ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜")
                if isinstance(doc_modules, dict) and 'unwarping' in doc_modules:
                    flow_steps.append("3. ë¬¸ì„œ êµì • (ì–¸ì›Œí•‘)")
            
            flow_steps.append(f"{len(flow_steps)+1}. í…ìŠ¤íŠ¸ ê°ì§€ ({detection_settings.get('model_name', 'Unknown')})")
            
            if 'orientation' in preprocessing_settings:
                flow_steps.append(f"{len(flow_steps)+1}. í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜")
            
            flow_steps.append(f"{len(flow_steps)+1}. í…ìŠ¤íŠ¸ ì¸ì‹ ({recognition_settings.get('model_name', 'Unknown')})")
            flow_steps.append(f"{len(flow_steps)+1}. ê²°ê³¼ í›„ì²˜ë¦¬ ë° í•„í„°ë§")
            
            for step in flow_steps:
                print(f"   {step}")
            
            # 9. ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„
            print(f"\nğŸ“Š ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„:")
            
            # ëª¨ë¸ ì¡°í•© ë¶„ì„
            det_model = detection_settings.get('model_name', '')
            rec_model = recognition_settings.get('model_name', '')
            
            is_server_det = 'server' in det_model.lower()
            is_mobile_rec = 'mobile' in rec_model.lower()
            has_doc_processing = preprocessing_settings['document']['enabled']
            has_orientation = 'orientation' in preprocessing_settings
            
            print(f"   ëª¨ë¸ ì¡°í•©: {'ì„œë²„ê¸‰' if is_server_det else 'ëª¨ë°”ì¼'} ê°ì§€ + {'ëª¨ë°”ì¼' if is_mobile_rec else 'ì„œë²„ê¸‰'} ì¸ì‹")
            print(f"   ì²˜ë¦¬ ì†ë„: {'âš¡ ê³ ì†' if is_mobile_rec else 'ğŸ¯ ê³ ì •í™•ë„'}")
            print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {'ğŸ’¾ ì ìŒ' if is_mobile_rec else 'ğŸ’¿ ë§ìŒ'}")
            print(f"   ë¬¸ì„œ ì§€ì›: {'âœ… ê³ ê¸‰' if has_doc_processing else 'âŒ ê¸°ë³¸'}")
            print(f"   ë°©í–¥ ë³´ì •: {'âœ… ì§€ì›' if has_orientation else 'âŒ ë¯¸ì§€ì›'}")
            print(f"   ë°°ì¹˜ ì²˜ë¦¬: ê°ì§€({detection_settings.get('batch_size', 'N/A')}), ì¸ì‹({recognition_settings.get('batch_size', 'N/A')})")
            
            # ì‹ ë¢°ë„ ì„¤ì • ë¶„ì„
            det_thresh = detection_settings.get('thresh', 0.3)
            rec_thresh = recognition_settings.get('score_thresh', 0.5)
            
            print(f"\nğŸ¯ ì‹ ë¢°ë„ ì„¤ì • ë¶„ì„:")
            print(f"   ê°ì§€ ë¯¼ê°ë„: {'ë†’ìŒ' if det_thresh <= 0.3 else 'ë³´í†µ' if det_thresh <= 0.5 else 'ë‚®ìŒ'} (ì„ê³„ê°’: {det_thresh})")
            print(f"   ì¸ì‹ í•„í„°ë§: {'ì—„ê²©' if rec_thresh >= 0.7 else 'ë³´í†µ' if rec_thresh >= 0.5 else 'ê´€ëŒ€'} (ì„ê³„ê°’: {rec_thresh})")
            
            overall_quality = "ê· í˜•" if (det_thresh <= 0.4 and rec_thresh >= 0.5) else \
                            "ê³ í’ˆì§ˆ" if (det_thresh <= 0.3 and rec_thresh >= 0.7) else \
                            "ê³ ì†ë„" if (det_thresh >= 0.4 and rec_thresh <= 0.4) else "ì»¤ìŠ¤í…€"
            print(f"   ì „ì²´ ì„¤ì •: {overall_quality}")
            
        except Exception as e:
            print(f"âŒ ì „ì²˜ë¦¬ ì„¤ì • ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            preprocessing_settings = {
                'error': str(e),
                'fallback': {
                    'language': self.lang,
                    'custom_options': self.init_kwargs
                }
            }
            print(f"ğŸ“Œ ê¸°ë³¸ ì •ë³´ë§Œ í‘œì‹œ: ì–¸ì–´={self.lang}, ì»¤ìŠ¤í…€ ì˜µì…˜={len(self.init_kwargs)}ê°œ")
        
        return preprocessing_settings



    def run_ocr_from_path(self, file_path: str) -> list[dict] | None:
        """
        íŒŒì¼ ê²½ë¡œì—ì„œ OCRì„ ì‹¤í–‰í•˜ê³  ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            file_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            list[dict] | None: PaddleOCR ì›ë³¸ ê²°ê³¼ (ì„±ê³µì‹œ OCRResult ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # PaddleOCR ì›ë³¸ ê²°ê³¼ ë°˜í™˜
            result = self._ocr_engine.predict(file_path)
            # print(f"result: {result}")

            return result
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ OCR ì‹¤íŒ¨: {e}")
            return None
    
    def run_ocr_from_nparray(self, image_array: np.ndarray) -> list[dict] | None:
        """
        numpy ë°°ì—´ì—ì„œ OCRì„ ì‹¤í–‰í•˜ê³  ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            image_array (np.ndarray): OpenCV ì´ë¯¸ì§€ ë°°ì—´ (BGR í˜•ì‹)
            
        Returns:
            list[dict] | None: PaddleOCR ì›ë³¸ ê²°ê³¼ (ì„±ê³µì‹œ OCRResult ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # PaddleOCR ì›ë³¸ ê²°ê³¼ ë°˜í™˜
            result = self._ocr_engine.predict(image_array)
            return result
            
        except Exception as e:
            print(f"âŒ ë°°ì—´ OCR ì‹¤íŒ¨: {e}")
            return None
    
    def run_ocr_from_bytes(self, image_bytes: bytes) -> list[dict] | None:
        """
        ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ OCRì„ ì‹¤í–‰í•˜ê³  ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            image_bytes (bytes): ì´ë¯¸ì§€ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
            
        Returns:
            list[dict] | None: PaddleOCR ì›ë³¸ ê²°ê³¼ (ì„±ê³µì‹œ OCRResult ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            nparr = np.frombuffer(image_bytes, np.uint8)
            cv_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            if cv_image is None:
                print("âŒ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì´ê±°ë‚˜ ì†ìƒëœ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")
                return None
            
            # numpy ë°°ì—´ë¡œ OCR ì‹¤í–‰ (ì¬ê·€ í˜¸ì¶œ)
            return self.run_ocr_from_nparray(cv_image)
            
        except Exception as e:
            print(f"âŒ ë°”ì´íŠ¸ ë°ì´í„° OCR ì‹¤íŒ¨: {e}")
            return None





