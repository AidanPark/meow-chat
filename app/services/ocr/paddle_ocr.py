"""
Korean OCR using PaddleOCR

ì´ ëª¨ë“ˆì€ PaddleOCRì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

Author: yunwoong7 (modified for latest PaddleOCR compatibility)
License: Apache 2.0
"""

import cv2
import numpy as np
from typing import Union
from paddleocr import PaddleOCR
from app.utils.image_util import plt_imshow, put_text

class MyPaddleOCR:
    """
    PaddleOCRì„ ì‚¬ìš©í•œ í•œêµ­ì–´ OCR í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” PaddleOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë˜í•‘í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    ìµœì‹  PaddleOCR APIì™€ í˜¸í™˜ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Attributes:
        lang (str): ì¸ì‹í•  ì–¸ì–´ ì„¤ì • (ê¸°ë³¸ê°’: "korean")
        _ocr (PaddleOCR): PaddleOCR ì¸ìŠ¤í„´ìŠ¤
        img_path (str): ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê²½ë¡œ
        ocr_result (dict): OCR ê²°ê³¼ ìƒì„¸ ì •ë³´
    """
    
    def __init__(self, lang: str = "korean", **kwargs):
        """
        MyPaddleOCR í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            lang (str): ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "korean")
            **kwargs: PaddleOCRì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        """
        self.lang = lang
        self.init_kwargs = kwargs.copy()  # ì´ˆê¸°í™”ì— ì‚¬ìš©ëœ ì¶”ê°€ ì¸ì ì €ì¥
        
        # PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì „ë‹¬ë°›ì€ ëª¨ë“  íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        self._ocr = PaddleOCR(lang=lang, **kwargs)
        self.img_path = None  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì´ë¯¸ì§€ ê²½ë¡œ
        self.ocr_result = {}  # OCR ê²°ê³¼ ìƒì„¸ ì •ë³´ ì €ì¥
    
    def get_available_langs(self):
        """
        PaddleOCRì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Note:
            PaddleOCR 3.2.0ì—ì„œëŠ” ë™ì  ì–¸ì–´ ëª©ë¡ ì¡°íšŒ APIê°€ ì œê³µë˜ì§€ ì•Šì•„
            ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ì˜ ì „ì²´ ì§€ì› ì–¸ì–´ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        # PaddleOCR 3.2.0ì—ì„œ ê³µì‹ ì§€ì›í•˜ëŠ” ì „ì²´ ì–¸ì–´ ëª©ë¡
        langs_info = [
            'ch', 'en', 'korean', 'japan', 'chinese_cht',  # ì£¼ìš” ë™ì•„ì‹œì•„ ì–¸ì–´
            'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic',  # ë‹¤ì–‘í•œ ë¬¸ìì²´ê³„
            'devanagari', 'french', 'german', 'it', 'xi',  # ìœ ëŸ½ ì–¸ì–´
            'pu', 'ru', 'ar', 'hi', 'ug', 'fa', 'ur',  # ì¤‘ë™/ë‚¨ì•„ì‹œì•„ ì–¸ì–´
            'rs_latin', 'oc', 'rs_cyrillic', 'bg', 'uk', 'be',  # ë™ìœ ëŸ½ ì–¸ì–´
            'kn', 'ch_tra', 'mr', 'ne'  # ì¶”ê°€ ì§€ì› ì–¸ì–´
        ]
        
        print(f'Available Languages ({len(langs_info)} total):')
        print(langs_info)
        
        # ì£¼ìš” ì–¸ì–´ ì„¤ëª…
        major_langs = {
            'ch': 'ì¤‘êµ­ì–´ (ê°„ì²´)',
            'en': 'ì˜ì–´',
            'korean': 'í•œêµ­ì–´',
            'japan': 'ì¼ë³¸ì–´',
            'chinese_cht': 'ì¤‘êµ­ì–´ (ë²ˆì²´)',
            'french': 'í”„ë‘ìŠ¤ì–´',
            'german': 'ë…ì¼ì–´',
            'ru': 'ëŸ¬ì‹œì•„ì–´',
            'ar': 'ì•„ëì–´',
            'hi': 'íŒë””ì–´'
        }
        
        print(f'\nMajor supported languages:')
        for code, name in major_langs.items():
            print(f'  {code:12} - {name}')
            
        return langs_info
    
    def check_language_support(self, lang_code: str):
        """
        íŠ¹ì • ì–¸ì–´ê°€ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            lang_code (str): í™•ì¸í•  ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'korean', 'en', 'ch')
        
        Returns:
            bool: ì§€ì› ì—¬ë¶€
        """
        supported_langs = [
            'ch', 'en', 'korean', 'japan', 'chinese_cht',
            'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic',
            'devanagari', 'french', 'german', 'it', 'xi',
            'pu', 'ru', 'ar', 'hi', 'ug', 'fa', 'ur',
            'rs_latin', 'oc', 'rs_cyrillic', 'bg', 'uk', 'be',
            'kn', 'ch_tra', 'mr', 'ne'
        ]
        
        is_supported = lang_code in supported_langs
        print(f"Language '{lang_code}': {'âœ… Supported' if is_supported else 'âŒ Not supported'}")
        
        if not is_supported:
            # ìœ ì‚¬í•œ ì–¸ì–´ ì œì•ˆ
            suggestions = [lang for lang in supported_langs if lang.startswith(lang_code[:2])]
            if suggestions:
                print(f"Did you mean: {suggestions}")
        
        return is_supported
        
    def get_available_models(self):
        """
        PaddleOCRì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ì§€ì› ì–¸ì–´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ê³¼ ì´ë¡ ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ëª¨ë¸ì„ ëª¨ë‘ ë³´ì—¬ì¤ë‹ˆë‹¤.
        """
        import os
        
        print("ğŸ¤– PaddleOCR ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´")
        print("=" * 60)
        
        # 1. ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸
        model_dir = os.path.expanduser("~/.paddlex/official_models")
        downloaded_models = []
        
        if os.path.exists(model_dir):
            try:
                downloaded_models = [item for item in os.listdir(model_dir) 
                                   if os.path.isdir(os.path.join(model_dir, item))]
                print(f"âœ… ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ({len(downloaded_models)}ê°œ):")
                
                # ëª¨ë¸ ë¶„ë¥˜
                detection_models = [m for m in downloaded_models if 'det' in m.lower()]
                recognition_models = [m for m in downloaded_models if 'rec' in m.lower()]
                orientation_models = [m for m in downloaded_models if 'ori' in m.lower() or 'doc' in m.lower()]
                other_models = [m for m in downloaded_models if m not in detection_models + recognition_models + orientation_models]
                
                if detection_models:
                    print("  ğŸ” í…ìŠ¤íŠ¸ ê°ì§€ ëª¨ë¸:")
                    for model in detection_models:
                        version = "PP-OCRv5" if "v5" in model else ("PP-OCRv4" if "v4" in model else "PP-OCR")
                        print(f"    ğŸ“¦ {model} ({version})")
                
                if recognition_models:
                    print("  ğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸:")
                    for model in recognition_models:
                        version = "PP-OCRv5" if "v5" in model else ("PP-OCRv4" if "v4" in model else "PP-OCR")
                        lang = "í•œêµ­ì–´" if "korean" in model else ("ì˜ì–´" if "en" in model else "ê¸°íƒ€")
                        size = "ëª¨ë°”ì¼" if "mobile" in model else "ì„œë²„"
                        print(f"    ğŸ“¦ {model} ({version}, {lang}, {size})")
                
                if orientation_models:
                    print("  ğŸ“ ë°©í–¥/êµ¬ì¡° ë³´ì • ëª¨ë¸:")
                    for model in orientation_models:
                        print(f"    ğŸ“¦ {model}")
                
                if other_models:
                    print("  ğŸ”§ ê¸°íƒ€ ëª¨ë¸:")
                    for model in other_models:
                        print(f"    ğŸ“¦ {model}")
                        
            except PermissionError:
                print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ")
        else:
            print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        print("\n" + "=" * 60)
        
        # 2. PaddleOCRì—ì„œ ì´ë¡ ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ëª¨ë¸ ë²„ì „
        print("ğŸ“š PaddleOCR ì§€ì› ëª¨ë¸ ë²„ì „:")
        model_info = {
            'PP-OCRv5': {
                'languages': ['ch', 'en', 'korean', 'japan', 'chinese_cht', 'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic', 'devanagari'],
                'status': 'âœ… í˜„ì¬ ì‚¬ìš© ì¤‘',
                'features': ['ìµœê³  ì •í™•ë„', 'í•œêµ­ì–´ ìµœì í™”', 'ëª¨ë°”ì¼/ì„œë²„ ì§€ì›']
            },
            'PP-OCRv4': {
                'languages': ['ch', 'en', 'korean', 'japan', 'chinese_cht'],
                'status': 'ğŸ”¶ ì´ì „ ë²„ì „',
                'features': ['ì•ˆì •ì  ì„±ëŠ¥', 'ë¹ ë¥¸ ì²˜ë¦¬']
            },
            'PP-OCRv3': {
                'languages': ['ch', 'en', 'korean', 'japan', 'chinese_cht', 'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic', 'devanagari'],
                'status': 'ğŸ”¶ ì´ì „ ë²„ì „',
                'features': ['ê´‘ë²”ìœ„í•œ ì–¸ì–´ ì§€ì›']
            },
            'PP-OCRv2': {
                'languages': ['ch'],
                'status': 'ğŸ”¸ ë ˆê±°ì‹œ',
                'features': ['ì¤‘êµ­ì–´ ì „ìš©']
            }
        }
        
        for idx, (model_name, info) in enumerate(model_info.items(), 1):
            print(f"\n#{idx} {model_name} {info['status']}")
            print(f"   ğŸŒ ì§€ì› ì–¸ì–´ ({len(info['languages'])}ê°œ): {info['languages'][:5]}{'...' if len(info['languages']) > 5 else ''}")
            print(f"   â­ íŠ¹ì§•: {', '.join(info['features'])}")
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ í˜„ì¬ ì„¤ì •:")
        print(f"   ğŸ“Œ ì‚¬ìš© ì¤‘ì¸ ë²„ì „: PP-OCRv5")
        print(f"   ğŸ“Œ ì£¼ ì‚¬ìš© ì–¸ì–´: {self.lang}")
        print(f"   ğŸ“Œ ëª¨ë¸ êµ¬ì„±: ì„œë²„ê¸‰ ê°ì§€ + ëª¨ë°”ì¼ ìµœì í™” ì¸ì‹")
        
        return downloaded_models
    
    def get_current_model_info(self):
        """
        í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ OCR ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì‹¤ì œ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë™ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Returns:
            dict: í˜„ì¬ ëª¨ë¸ ì •ë³´
        """
        print("ğŸ” í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´ (ì‹¤ì œ ì„¤ì •)")
        print("=" * 50)
        
        # ì‹¤ì œ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
        try:
            # _paramsì—ì„œ ì‹¤ì œ ì„¤ì •ëœ ëª¨ë¸ëª… ì¶”ì¶œ
            params = self._ocr._params
            config = self._ocr._merged_paddlex_config
            
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ë“¤
            detection_model = params.get('text_detection_model_name', 'Unknown')
            recognition_model = params.get('text_recognition_model_name', 'Unknown')
            
            # configì—ì„œ ì„¸ë¶€ ëª¨ë¸ë“¤ ì¶”ì¶œ
            sub_modules = config.get('SubModules', {})
            sub_pipelines = config.get('SubPipelines', {})
            
            # ë¬¸ì„œ ì „ì²˜ë¦¬ ëª¨ë¸ë“¤
            doc_models = []
            if 'DocPreprocessor' in sub_pipelines:
                doc_preprocessor = sub_pipelines['DocPreprocessor'].get('SubModules', {})
                if 'DocOrientationClassify' in doc_preprocessor:
                    doc_ori_model = doc_preprocessor['DocOrientationClassify'].get('model_name')
                    if doc_ori_model:
                        doc_models.append(doc_ori_model)
                if 'DocUnwarping' in doc_preprocessor:
                    doc_unwarp_model = doc_preprocessor['DocUnwarping'].get('model_name')
                    if doc_unwarp_model:
                        doc_models.append(doc_unwarp_model)
            
            # í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë³´ì • ëª¨ë¸
            textline_ori_model = None
            if 'TextLineOrientation' in sub_modules:
                textline_ori_model = sub_modules['TextLineOrientation'].get('model_name')
            
            # ëª¨ë¸ ì •ë³´ êµ¬ì„±
            model_info = {
                'language': self.lang,
                'version': 'PP-OCRv5',  # ëª¨ë“  ëª¨ë¸ì´ v5ì„ì„ í™•ì¸
                'detection_model': detection_model,
                'recognition_model': recognition_model,
                'doc_orientation_models': doc_models,
                'textline_orientation_model': textline_ori_model,
                'pipeline_config': {
                    'use_doc_preprocessor': config.get('use_doc_preprocessor', False),
                    'use_textline_orientation': config.get('use_textline_orientation', False),
                    'text_type': config.get('text_type', 'general')
                }
            }
            
            # ìƒì„¸ ì¶œë ¥
            print(f"ğŸ“Œ ì„¤ì • ì–¸ì–´: {model_info['language']}")
            print(f"ğŸ“Œ íŒŒì´í”„ë¼ì¸: {config.get('pipeline_name', 'OCR')}")
            print(f"ğŸ“Œ í…ìŠ¤íŠ¸ ìœ í˜•: {model_info['pipeline_config']['text_type']}")
            print(f"ğŸ“Œ ëª¨ë¸ ë²„ì „: {model_info['version']}")
            
            print(f"\nğŸ” í•µì‹¬ ëª¨ë¸:")
            print(f"   í…ìŠ¤íŠ¸ ê°ì§€: {model_info['detection_model']}")
            print(f"   í…ìŠ¤íŠ¸ ì¸ì‹: {model_info['recognition_model']}")
            
            if model_info['doc_orientation_models']:
                print(f"\nğŸ“ ë¬¸ì„œ ì „ì²˜ë¦¬ ëª¨ë¸:")
                for model in model_info['doc_orientation_models']:
                    model_type = "ë°©í–¥ ë³´ì •" if "ori" in model else "ë¬¸ì„œ êµì •"
                    print(f"   {model} ({model_type})")
            
            if model_info['textline_orientation_model']:
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë³´ì •:")
                print(f"   {model_info['textline_orientation_model']}")
            
            # ì„¤ì • ì •ë³´
            print(f"\nâš™ï¸  íŒŒì´í”„ë¼ì¸ ì„¤ì •:")
            print(f"   ë¬¸ì„œ ì „ì²˜ë¦¬: {'âœ…' if model_info['pipeline_config']['use_doc_preprocessor'] else 'âŒ'}")
            print(f"   í…ìŠ¤íŠ¸ë¼ì¸ ë³´ì •: {'âœ…' if model_info['pipeline_config']['use_textline_orientation'] else 'âŒ'}")
            
            # ì‹¤ì œ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´
            if 'TextDetection' in sub_modules:
                det_config = sub_modules['TextDetection']
                print(f"\nğŸ” ê°ì§€ ëª¨ë¸ ì„¤ì •:")
                print(f"   ì„ê³„ê°’: {det_config.get('thresh', 'N/A')}")
                print(f"   ë°•ìŠ¤ ì„ê³„ê°’: {det_config.get('box_thresh', 'N/A')}")
                print(f"   ì–¸í´ë¦½ ë¹„ìœ¨: {det_config.get('unclip_ratio', 'N/A')}")
            
            if 'TextRecognition' in sub_modules:
                rec_config = sub_modules['TextRecognition']
                print(f"\nğŸ“ ì¸ì‹ ëª¨ë¸ ì„¤ì •:")
                print(f"   ë°°ì¹˜ í¬ê¸°: {rec_config.get('batch_size', 'N/A')}")
                print(f"   ì ìˆ˜ ì„ê³„ê°’: {rec_config.get('score_thresh', 'N/A')}")
            
            # ì„±ëŠ¥ íŠ¹ì„± (ì‹¤ì œ ì„¤ì • ê¸°ë°˜)
            is_korean = self.lang == 'korean'
            is_mobile_rec = 'mobile' in recognition_model
            is_server_det = 'server' in detection_model
            
            print(f"\nğŸ“Š ì„±ëŠ¥ íŠ¹ì„± (ì‹¤ì œ ì„¤ì • ê¸°ë°˜):")
            print(f"   ëª¨ë¸ ì¡°í•©: {'ì„œë²„ê¸‰ ê°ì§€' if is_server_det else 'ëª¨ë°”ì¼ ê°ì§€'} + {'ëª¨ë°”ì¼ ì¸ì‹' if is_mobile_rec else 'ì„œë²„ê¸‰ ì¸ì‹'}")
            print(f"   í•œêµ­ì–´ ìµœì í™”: {'âœ…' if is_korean else 'âŒ'}")
            print(f"   ì‹¤ì‹œê°„ ì²˜ë¦¬: {'âœ…' if is_mobile_rec else 'âš¡ ê³ ì„±ëŠ¥'}")
            print(f"   ë¬¸ì„œ ì²˜ë¦¬: {'âœ… ê³ ê¸‰' if model_info['pipeline_config']['use_doc_preprocessor'] else 'âŒ ê¸°ë³¸'}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ fallback
            model_info = {
                'language': self.lang,
                'version': 'PP-OCRv5',
                'detection_model': 'PP-OCRv5_server_det',
                'recognition_model': f'{self.lang}_PP-OCRv5_mobile_rec',
                'error': str(e)
            }
            print(f"ğŸ“Œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í‘œì‹œ: {self.lang} ì–¸ì–´, PP-OCRv5 ëª¨ë¸")
        
        return model_info
        
    def get_ocr_result(self):
        """
        ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹¤í–‰ëœ OCRì˜ ìƒì„¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            dict: OCR ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
                - rec_texts: ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
                - rec_scores: ê° í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ ì ìˆ˜
                - rec_polys: ê° í…ìŠ¤íŠ¸ì˜ ì¢Œí‘œ ì •ë³´
                - ê¸°íƒ€ ë©”íƒ€ë°ì´í„°
        """
        return self.ocr_result

    def get_img_path(self):
        """
        í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        """
        return self.img_path

    def show_img(self):
        """
        í˜„ì¬ ì´ë¯¸ì§€ë¥¼ matplotlibì„ ì‚¬ìš©í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        
        Note:
            utils.image_util.plt_imshow í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        plt_imshow(img=self.img_path)
    
    def run_ocr(self, img_input: Union[str, np.ndarray], debug: bool = False):
        """
        ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” OCRì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            img_input (Union[str, np.ndarray]): 
                - str: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                - np.ndarray: OpenCV ì´ë¯¸ì§€ ë°°ì—´ (BGR í˜•ì‹)
            debug (bool): ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
                         Trueì¼ ê²½ìš° ì¸ì‹ëœ í…ìŠ¤íŠ¸ì™€ ì‹ ë¢°ë„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Returns:
            list: ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
                 ì˜ˆ: ['ì•„ë˜í•œê¸€ í•œê¸€ë¬¸ì„œ', 'ë””ìì¸', '2022.04']
        
        Note:
            - ê²°ê³¼ëŠ” self.ocr_resultì—ë„ ì €ì¥ë©ë‹ˆë‹¤ (ìƒì„¸ ì •ë³´ í¬í•¨)
            - PaddleOCRì˜ ìµœì‹  predict() APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤
            - numpy ë°°ì—´ê³¼ íŒŒì¼ ê²½ë¡œ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤
        """
        # ì…ë ¥ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(img_input, str):
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            self.img_path = img_input
            input_source = img_input
            if debug:
                print(f"ğŸ“ íŒŒì¼ì—ì„œ OCR ì‹¤í–‰: {img_input}")
        elif isinstance(img_input, np.ndarray):
            # numpy ë°°ì—´ì¸ ê²½ìš°
            self.img_path = "memory_image"  # ë©”ëª¨ë¦¬ ì´ë¯¸ì§€ í‘œì‹œ
            input_source = img_input
            if debug:
                print(f"ğŸ’¾ ë©”ëª¨ë¦¬ì—ì„œ OCR ì‹¤í–‰: shape={img_input.shape}, dtype={img_input.dtype}")
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {type(img_input)}. str ë˜ëŠ” np.ndarrayë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
        
        ocr_text = []  # ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        
        # PaddleOCR ìµœì‹  ë²„ì „ API ì‚¬ìš©
        try:
            # PaddleOCR predict ë©”ì„œë“œ í˜¸ì¶œ (íŒŒì¼ ê²½ë¡œì™€ numpy ë°°ì—´ ëª¨ë‘ ì§€ì›)
            result = self._ocr.predict(input_source)
            
            # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ì´ê³  ì²« ë²ˆì§¸ ìš”ì†Œì— ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
            if result and isinstance(result, list) and len(result) > 0:
                page_result = result[0]  # ì²« ë²ˆì§¸ í˜ì´ì§€ ê²°ê³¼ ì¶”ì¶œ
                
                # ê²°ê³¼ì— í…ìŠ¤íŠ¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
                if isinstance(page_result, dict) and 'rec_texts' in page_result:
                    # ìƒì„¸ ê²°ê³¼ë¥¼ ê°ì²´ì— ì €ì¥
                    self.ocr_result = page_result
                    # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    ocr_text = page_result['rec_texts']
                    
                    # ë””ë²„ê·¸ ëª¨ë“œì¼ ê²½ìš° ê²°ê³¼ ì¶œë ¥
                    if debug:
                        input_type = "íŒŒì¼" if isinstance(img_input, str) else "ë©”ëª¨ë¦¬"
                        print(f"âœ… {input_type} OCR ì™„ë£Œ:")
                        print(f"   ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ({len(ocr_text)}ê°œ): {ocr_text}")
                        if 'rec_scores' in page_result:
                            scores = page_result['rec_scores']
                            print(f"   ğŸ“Š ì‹ ë¢°ë„: {[f'{score:.4f}' for score in scores]}")
                        if 'rec_polys' in page_result:
                            polys = page_result['rec_polys']
                            print(f"   ğŸ“ ì¢Œí‘œ ì •ë³´: {len(polys)}ê°œ ì˜ì—­")
                else:
                    # í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
                    self.ocr_result = {}
                    ocr_text = ["í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
                    if debug:
                        print("âš ï¸ OCR ê²°ê³¼ì— í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
                self.ocr_result = {}
                ocr_text = ["OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."]
                if debug:
                    print("âš ï¸ OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            # OCR ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ
            print(f"âŒ OCR ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.ocr_result = {}
            ocr_text = ["OCR ì‹¤í–‰ ì‹¤íŒ¨"]

        return ocr_text
    
    def run_ocr_from_bytes(self, image_bytes: bytes, debug: bool = False):
        """
        ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ ì§ì ‘ OCRì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            image_bytes (bytes): ì´ë¯¸ì§€ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
            debug (bool): ë””ë²„ê·¸ ëª¨ë“œ
            
        Returns:
            list: ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            nparr = np.frombuffer(image_bytes, np.uint8)
            cv_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if cv_image is None:
                raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
            
            if debug:
                print(f"ğŸ”„ ë°”ì´íŠ¸ ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {cv_image.shape}")
            
            # numpy ë°°ì—´ë¡œ OCR ì‹¤í–‰
            return self.run_ocr(cv_image, debug=debug)
            
        except Exception as e:
            print(f"âŒ ë°”ì´íŠ¸ ë°ì´í„° OCR ì‹¤íŒ¨: {e}")
            return ["ë°”ì´íŠ¸ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨"]
        
    def show_img_with_ocr(self):
        """
        OCR ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ ìœ„ì— ì‹œê°í™”í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
        
        ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ë…¹ìƒ‰ ì‚¬ê°í˜•ìœ¼ë¡œ í‘œì‹œí•˜ê³ ,
        ê° ì˜ì—­ ìœ„ì— ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
        
        Note:
            - OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì²˜ë¦¬
            - matplotlibì„ í†µí•´ ì›ë³¸ê³¼ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
            - í˜„ì¬ ë²„ì „ì—ì„œëŠ” draw_ocr ì˜ì¡´ì„± ë¬¸ì œë¡œ ë¹„í™œì„±í™”ë¨
        """
        # ì´ë¯¸ì§€ ì½ê¸°
        img = cv2.imread(self.img_path)
        roi_img = img.copy()  # ê²°ê³¼ í‘œì‹œìš© ì´ë¯¸ì§€ ë³µì‚¬

        # OCR ê²°ê³¼ì˜ ê° í…ìŠ¤íŠ¸ ì˜ì—­ì— ëŒ€í•´ ì²˜ë¦¬
        for text_result in self.ocr_result:
            text = text_result[1][0]  # ì¸ì‹ëœ í…ìŠ¤íŠ¸
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ì˜ 4ê°œ ê¼­ì§€ì  ì¢Œí‘œ ì¶”ì¶œ
            tlX = int(text_result[0][0][0])  # Top-Left X
            tlY = int(text_result[0][0][1])  # Top-Left Y
            trX = int(text_result[0][1][0])  # Top-Right X
            trY = int(text_result[0][1][1])  # Top-Right Y
            brX = int(text_result[0][2][0])  # Bottom-Right X
            brY = int(text_result[0][2][1])  # Bottom-Right Y
            blX = int(text_result[0][3][0])  # Bottom-Left X
            blY = int(text_result[0][3][1])  # Bottom-Left Y

            # 4ê°œ ê¼­ì§€ì  ì¢Œí‘œ íŠœí”Œë¡œ ì •ë¦¬
            pts = ((tlX, tlY), (trX, trY), (brX, brY), (blX, blY))
            topLeft = pts[0]
            topRight = pts[1]
            bottomRight = pts[2]
            bottomLeft = pts[3]

            # í…ìŠ¤íŠ¸ ì˜ì—­ì„ ë…¹ìƒ‰ ì‚¬ê°í˜•ìœ¼ë¡œ í‘œì‹œ
            cv2.line(roi_img, topLeft, topRight, (0, 255, 0), 2)
            cv2.line(roi_img, topRight, bottomRight, (0, 255, 0), 2)
            cv2.line(roi_img, bottomRight, bottomLeft, (0, 255, 0), 2)
            cv2.line(roi_img, bottomLeft, topLeft, (0, 255, 0), 2)
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ìœ„ì— ì¸ì‹ëœ í…ìŠ¤íŠ¸ í‘œì‹œ
            roi_img = put_text(roi_img, text, topLeft[0], topLeft[1] - 20, font_size=15)

        # ì›ë³¸ ì´ë¯¸ì§€ì™€ OCR ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
        plt_imshow(["Original", "ROI"], [img, roi_img], figsize=(16, 10))

    def show_img(self):
        """
        í˜„ì¬ ì´ë¯¸ì§€ë¥¼ matplotlibì„ ì‚¬ìš©í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        
        Note:
            ë©”ëª¨ë¦¬ ì´ë¯¸ì§€ì¸ ê²½ìš° í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
        """
        if self.img_path == "memory_image":
            print("âš ï¸ ë©”ëª¨ë¦¬ ì´ë¯¸ì§€ëŠ” show_img()ë¡œ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ëŒ€ì‹  run_ocr ì‹¤í–‰ ì‹œ numpy ë°°ì—´ì„ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.")
        else:
            plt_imshow(img=self.img_path)

    def save_memory_image(self, output_path: str, image_array: np.ndarray = None):
        """
        ë©”ëª¨ë¦¬ì— ìˆëŠ” ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            image_array (np.ndarray, optional): ì €ì¥í•  ì´ë¯¸ì§€ ë°°ì—´
                                                Noneì¸ ê²½ìš° ë§ˆì§€ë§‰ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©
        """
        if image_array is not None:
            cv2.imwrite(output_path, image_array)
            print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")
        else:
            print("âŒ ì €ì¥í•  ì´ë¯¸ì§€ ë°°ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
