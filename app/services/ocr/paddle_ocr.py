"""
Korean OCR using PaddleOCR

ì´ ëª¨ë“ˆì€ PaddleOCRì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

Author: yunwoong7 (modified for latest PaddleOCR compatibility)
License: Apache 2.0
"""

import cv2
import numpy as np
from paddleocr import PaddleOCR
import jsonpickle
import numpy as np

class PaddleOCRService:
    """
    PaddleOCRì„ ì‚¬ìš©í•œ í•œêµ­ì–´ OCR í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” PaddleOCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë˜í•‘í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    ìµœì‹  PaddleOCR APIì™€ í˜¸í™˜ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Attributes:
        lang (str): ì¸ì‹í•  ì–¸ì–´ ì„¤ì • (ê¸°ë³¸ê°’: "korean")
        _ocr (PaddleOCR): PaddleOCR ì¸ìŠ¤í„´ìŠ¤
    """
    
    def __init__(self, lang: str = "korean", **kwargs):
        """
        MyPaddleOCR í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            lang (str): ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "korean")
            **kwargs: PaddleOCRì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        """
        self.lang = lang
        self.init_kwargs = kwargs.copy()  # ì´ˆê¸°í™”ì— ì‚¬ìš©ëœ ì¶”ê°€ ì¸ì ì €ì¥
        
        # PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì „ë‹¬ë°›ì€ ëª¨ë“  íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        self._ocr_engine = PaddleOCR(
            lang=self.lang, 
            use_doc_orientation_classify=True, # ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜/êµì • ëª¨ë¸ ë¡œë“œ
            use_doc_unwarping=True,            # ë¬¸ì„œ íœ˜ì–´ì§ ë³´ì • 
            use_textline_orientation=True,     # ë°©í–¥ ë¶„ë¥˜ í™œì„±í™”
            # text_det_thresh=0.2,               # ê°ì§€ ì„ê³„ê°’ 
            # text_rec_score_thresh=0.7,         # ì¸ì‹ ì„ê³„ê°’ 
            # text_recognition_batch_size=1,     # ë°°ì¹˜ í¬ê¸° 
            # text_det_limit_side_len=1600,      # ì´ë¯¸ì§€ í¬ê¸° 
            # return_word_box=True,              # ë‹¨ì–´ë³„ ë°•ìŠ¤ ë°˜í™˜       

            # text_det_unclip_ratio=2.5,         # í…ìŠ¤íŠ¸ ë°•ìŠ¤ í™•ì¥  
            **kwargs
        )

        
    
    def get_available_langs(self):
        """
        PaddleOCRì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Note:
            PaddleOCR 3.2.0ì—ì„œëŠ” ë™ì  ì–¸ì–´ ëª©ë¡ ì¡°íšŒ APIê°€ ì œê³µë˜ì§€ ì•Šì•„
            ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ì˜ ì „ì²´ ì§€ì› ì–¸ì–´ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        # PaddleOCR 3.2.0ì—ì„œ ê³µì‹ ì§€ì›í•˜ëŠ” ì „ì²´ ì–¸ì–´ ëª©ë¡
        langs_info = [
            'ch', 'en', 'korean', 'japan', 'chinese_cht',  # ì£¼ìš” ë™ì•„ì‹œì•„ ì–¸ì–´
            'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic',  # ë‹¤ì–‘í•œ ë¬¸ìì²´ê³„
            'devanagari', 'french', 'german', 'it', 'xi',  # ìœ ëŸ½ ì–¸ì–´
            'pu', 'ru', 'ar', 'hi', 'ug', 'fa', 'ur',  # ì¤‘ë™/ë‚¨ì•„ì‹œì•„ ì–¸ì–´
            'rs_latin', 'oc', 'rs_cyrillic', 'bg', 'uk', 'be',  # ë™ìœ ëŸ½ ì–¸ì–´
            'kn', 'ch_tra', 'mr', 'ne'  # ì¶”ê°€ ì§€ì› ì–¸ì–´
        ]
        
        print(f'Available Languages ({len(langs_info)} total):')
        print(langs_info)
        
        # ì£¼ìš” ì–¸ì–´ ì„¤ëª…
        major_langs = {
            'ch': 'ì¤‘êµ­ì–´ (ê°„ì²´)',
            'en': 'ì˜ì–´',
            'korean': 'í•œêµ­ì–´',
            'japan': 'ì¼ë³¸ì–´',
            'chinese_cht': 'ì¤‘êµ­ì–´ (ë²ˆì²´)',
            'french': 'í”„ë‘ìŠ¤ì–´',
            'german': 'ë…ì¼ì–´',
            'ru': 'ëŸ¬ì‹œì•„ì–´',
            'ar': 'ì•„ëì–´',
            'hi': 'íŒë””ì–´'
        }
        
        print(f'\nMajor supported languages:')
        for code, name in major_langs.items():
            print(f'  {code:12} - {name}')
            
        return langs_info
    
    def check_language_support(self, lang_code: str):
        """
        íŠ¹ì • ì–¸ì–´ê°€ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            lang_code (str): í™•ì¸í•  ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'korean', 'en', 'ch')
        
        Returns:
            bool: ì§€ì› ì—¬ë¶€
        """
        supported_langs = [
            'ch', 'en', 'korean', 'japan', 'chinese_cht',
            'ta', 'te', 'ka', 'latin', 'arabic', 'cyrillic',
            'devanagari', 'french', 'german', 'it', 'xi',
            'pu', 'ru', 'ar', 'hi', 'ug', 'fa', 'ur',
            'rs_latin', 'oc', 'rs_cyrillic', 'bg', 'uk', 'be',
            'kn', 'ch_tra', 'mr', 'ne'
        ]
        
        is_supported = lang_code in supported_langs
        print(f"Language '{lang_code}': {'âœ… Supported' if is_supported else 'âŒ Not supported'}")
        
        if not is_supported:
            # ìœ ì‚¬í•œ ì–¸ì–´ ì œì•ˆ
            suggestions = [lang for lang in supported_langs if lang.startswith(lang_code[:2])]
            if suggestions:
                print(f"Did you mean: {suggestions}")
        
        return is_supported
        
    def get_available_models(self):
        """
        PaddleOCRì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ì§€ì› ì–¸ì–´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ê³¼ ì´ë¡ ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ëª¨ë¸ì„ ëª¨ë‘ ë³´ì—¬ì¤ë‹ˆë‹¤.
        """
        import os
        
        print("ğŸ¤– PaddleOCR ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´")
        print("=" * 60)
        
        # 1. ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸
        model_dir = os.path.expanduser("~/.paddlex/official_models")
        downloaded_models = []
        
        if os.path.exists(model_dir):
            try:
                downloaded_models = [item for item in os.listdir(model_dir) 
                                   if os.path.isdir(os.path.join(model_dir, item))]
                print(f"âœ… ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ({len(downloaded_models)}ê°œ):")
                
                # ëª¨ë¸ ë¶„ë¥˜
                detection_models = [m for m in downloaded_models if 'det' in m.lower()]
                recognition_models = [m for m in downloaded_models if 'rec' in m.lower()]
                orientation_models = [m for m in downloaded_models if 'ori' in m.lower() or 'doc' in m.lower()]
                other_models = [m for m in downloaded_models if m not in detection_models + recognition_models + orientation_models]
                
                if detection_models:
                    print("  ğŸ” í…ìŠ¤íŠ¸ ê°ì§€ ëª¨ë¸:")
                    for model in detection_models:
                        version = "PP-OCRv5" if "v5" in model else ("PP-OCRv4" if "v4" in model else "PP-OCR")
                        print(f"    ğŸ“¦ {model} ({version})")
                
                if recognition_models:
                    print("  ğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸:")
                    for model in recognition_models:
                        version = "PP-OCRv5" if "v5" in model else ("PP-OCRv4" if "v4" in model else "PP-OCR")
                        lang = "í•œêµ­ì–´" if "korean" in model else ("ì˜ì–´" if "en" in model else "ê¸°íƒ€")
                        size = "ëª¨ë°”ì¼" if "mobile" in model else "ì„œë²„"
                        print(f"    ğŸ“¦ {model} ({version}, {lang}, {size})")
                
                if orientation_models:
                    print("  ğŸ“ ë°©í–¥/êµ¬ì¡° ë³´ì • ëª¨ë¸:")
                    for model in orientation_models:
                        print(f"    ğŸ“¦ {model}")
                
                if other_models:
                    print("  ğŸ”§ ê¸°íƒ€ ëª¨ë¸:")
                    for model in other_models:
                        print(f"    ğŸ“¦ {model}")
                        
            except PermissionError:
                print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ")
        else:
            print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        print("\n" + "=" * 60)
        
        return downloaded_models
    
    def get_current_model_info(self):
        """
        í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ OCR ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì‹¤ì œ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë™ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Returns:
            dict: í˜„ì¬ ëª¨ë¸ ì •ë³´
        """
        print("ğŸ” í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´ (ì‹¤ì œ ì„¤ì •)")
        print("=" * 50)
        
        # ì‹¤ì œ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
        try:
            # _paramsì—ì„œ ì‹¤ì œ ì„¤ì •ëœ ëª¨ë¸ëª… ì¶”ì¶œ
            params = self._ocr_engine._params
            config = self._ocr_engine._merged_paddlex_config
            
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ë“¤
            detection_model = params.get('text_detection_model_name', 'Unknown')
            recognition_model = params.get('text_recognition_model_name', 'Unknown')
            
            # configì—ì„œ ì„¸ë¶€ ëª¨ë¸ë“¤ ì¶”ì¶œ
            sub_modules = config.get('SubModules', {})
            sub_pipelines = config.get('SubPipelines', {})
            
            # ë¬¸ì„œ ì „ì²˜ë¦¬ ëª¨ë¸ë“¤
            doc_models = []
            if 'DocPreprocessor' in sub_pipelines:
                doc_preprocessor = sub_pipelines['DocPreprocessor'].get('SubModules', {})
                if 'DocOrientationClassify' in doc_preprocessor:
                    doc_ori_model = doc_preprocessor['DocOrientationClassify'].get('model_name')
                    if doc_ori_model:
                        doc_models.append(doc_ori_model)
                if 'DocUnwarping' in doc_preprocessor:
                    doc_unwarp_model = doc_preprocessor['DocUnwarping'].get('model_name')
                    if doc_unwarp_model:
                        doc_models.append(doc_unwarp_model)
            
            # í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë³´ì • ëª¨ë¸
            textline_ori_model = None
            if 'TextLineOrientation' in sub_modules:
                textline_ori_model = sub_modules['TextLineOrientation'].get('model_name')
            
            # ëª¨ë¸ ì •ë³´ êµ¬ì„±
            model_info = {
                'language': self.lang,
                'version': 'PP-OCRv5',  # ëª¨ë“  ëª¨ë¸ì´ v5ì„ì„ í™•ì¸
                'detection_model': detection_model,
                'recognition_model': recognition_model,
                'doc_orientation_models': doc_models,
                'textline_orientation_model': textline_ori_model,
                'pipeline_config': {
                    'use_doc_preprocessor': config.get('use_doc_preprocessor', False),
                    'use_textline_orientation': config.get('use_textline_orientation', False),
                    'text_type': config.get('text_type', 'general')
                }
            }
            
            # ìƒì„¸ ì¶œë ¥
            print(f"ğŸ“Œ ì„¤ì • ì–¸ì–´: {model_info['language']}")
            print(f"ğŸ“Œ íŒŒì´í”„ë¼ì¸: {config.get('pipeline_name', 'OCR')}")
            print(f"ğŸ“Œ í…ìŠ¤íŠ¸ ìœ í˜•: {model_info['pipeline_config']['text_type']}")
            print(f"ğŸ“Œ ëª¨ë¸ ë²„ì „: {model_info['version']}")
            
            print(f"\nğŸ” í•µì‹¬ ëª¨ë¸:")
            print(f"   í…ìŠ¤íŠ¸ ê°ì§€: {model_info['detection_model']}")
            print(f"   í…ìŠ¤íŠ¸ ì¸ì‹: {model_info['recognition_model']}")
            
            if model_info['doc_orientation_models']:
                print(f"\nğŸ“ ë¬¸ì„œ ì „ì²˜ë¦¬ ëª¨ë¸:")
                for model in model_info['doc_orientation_models']:
                    model_type = "ë°©í–¥ ë³´ì •" if "ori" in model else "ë¬¸ì„œ êµì •"
                    print(f"   {model} ({model_type})")
            
            if model_info['textline_orientation_model']:
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë³´ì •:")
                print(f"   {model_info['textline_orientation_model']}")
            
            # ì„¤ì • ì •ë³´
            print(f"\nâš™ï¸  íŒŒì´í”„ë¼ì¸ ì„¤ì •:")
            print(f"   ë¬¸ì„œ ì „ì²˜ë¦¬: {'âœ…' if model_info['pipeline_config']['use_doc_preprocessor'] else 'âŒ'}")
            print(f"   í…ìŠ¤íŠ¸ë¼ì¸ ë³´ì •: {'âœ…' if model_info['pipeline_config']['use_textline_orientation'] else 'âŒ'}")
            
            # ì‹¤ì œ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´
            if 'TextDetection' in sub_modules:
                det_config = sub_modules['TextDetection']
                print(f"\nğŸ” ê°ì§€ ëª¨ë¸ ì„¤ì •:")
                print(f"   ì„ê³„ê°’: {det_config.get('thresh', 'N/A')}")
                print(f"   ë°•ìŠ¤ ì„ê³„ê°’: {det_config.get('box_thresh', 'N/A')}")
                print(f"   ì–¸í´ë¦½ ë¹„ìœ¨: {det_config.get('unclip_ratio', 'N/A')}")
            
            if 'TextRecognition' in sub_modules:
                rec_config = sub_modules['TextRecognition']
                print(f"\nğŸ“ ì¸ì‹ ëª¨ë¸ ì„¤ì •:")
                print(f"   ë°°ì¹˜ í¬ê¸°: {rec_config.get('batch_size', 'N/A')}")
                print(f"   ì ìˆ˜ ì„ê³„ê°’: {rec_config.get('score_thresh', 'N/A')}")
            
            # ì„±ëŠ¥ íŠ¹ì„± (ì‹¤ì œ ì„¤ì • ê¸°ë°˜)
            is_korean = self.lang == 'korean'
            is_mobile_rec = 'mobile' in recognition_model
            is_server_det = 'server' in detection_model
            
            print(f"\nğŸ“Š ì„±ëŠ¥ íŠ¹ì„± (ì‹¤ì œ ì„¤ì • ê¸°ë°˜):")
            print(f"   ëª¨ë¸ ì¡°í•©: {'ì„œë²„ê¸‰ ê°ì§€' if is_server_det else 'ëª¨ë°”ì¼ ê°ì§€'} + {'ëª¨ë°”ì¼ ì¸ì‹' if is_mobile_rec else 'ì„œë²„ê¸‰ ì¸ì‹'}")
            print(f"   í•œêµ­ì–´ ìµœì í™”: {'âœ…' if is_korean else 'âŒ'}")
            print(f"   ì‹¤ì‹œê°„ ì²˜ë¦¬: {'âœ…' if is_mobile_rec else 'âš¡ ê³ ì„±ëŠ¥'}")
            print(f"   ë¬¸ì„œ ì²˜ë¦¬: {'âœ… ê³ ê¸‰' if model_info['pipeline_config']['use_doc_preprocessor'] else 'âŒ ê¸°ë³¸'}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ fallback
            model_info = {
                'language': self.lang,
                'version': 'PP-OCRv5',
                'detection_model': 'PP-OCRv5_server_det',
                'recognition_model': f'{self.lang}_PP-OCRv5_mobile_rec',
                'error': str(e)
            }
            print(f"ğŸ“Œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í‘œì‹œ: {self.lang} ì–¸ì–´, PP-OCRv5 ëª¨ë¸")
        
        return model_info
        
    def get_current_preprocessing_settings(self):
        """
        í˜„ì¬ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì— ì‹¤ì œë¡œ ì ìš©ëœ ëª¨ë“  ì „ì²˜ë¦¬ ì„¤ì •ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Returns:
            dict: í˜„ì¬ ì „ì²˜ë¦¬ ì„¤ì • ì •ë³´
        """
        print("ğŸ”§ í˜„ì¬ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì˜ ì „ì²˜ë¦¬ ì„¤ì • (ì‹¤ì œ ì ìš©ë¨)")
        print("=" * 70)
        
        preprocessing_settings = {}
        
        try:
            # PaddleOCR ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤ì œ ì„¤ì • ì¶”ì¶œ
            params = self._ocr_engine._params
            config = self._ocr_engine._merged_paddlex_config
            sub_modules = config.get('SubModules', {})
            sub_pipelines = config.get('SubPipelines', {})
            
            # 1. ê¸°ë³¸ ì‹œìŠ¤í…œ ì„¤ì •
            system_settings = {
                'language': self.lang,
                'pipeline_name': config.get('pipeline_name', 'OCR'),
                'text_type': config.get('text_type', 'general'),
                'use_gpu': params.get('use_gpu', True),
                'gpu_id': params.get('gpu_id', 0),
                'cpu_threads': params.get('cpu_threads', 10),
                'enable_mkldnn': params.get('enable_mkldnn', True),
                'warmup': params.get('warmup', True),
                'show_log': params.get('show_log', False)
            }
            preprocessing_settings['system'] = system_settings
            
            print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ ì„¤ì •:")
            print(f"   ì–¸ì–´: {system_settings['language']}")
            print(f"   íŒŒì´í”„ë¼ì¸: {system_settings['pipeline_name']}")
            print(f"   í…ìŠ¤íŠ¸ ìœ í˜•: {system_settings['text_type']}")
            print(f"   GPU ì‚¬ìš©: {'âœ…' if system_settings['use_gpu'] else 'âŒ'}")
            print(f"   GPU ID: {system_settings['gpu_id']}")
            print(f"   CPU ìŠ¤ë ˆë“œ: {system_settings['cpu_threads']}")
            print(f"   MKLDNN ìµœì í™”: {'âœ…' if system_settings['enable_mkldnn'] else 'âŒ'}")
            print(f"   ëª¨ë¸ ì›Œë°ì—…: {'âœ…' if system_settings['warmup'] else 'âŒ'}")
            print(f"   ë¡œê·¸ ì¶œë ¥: {'âœ…' if system_settings['show_log'] else 'âŒ'}")
            
            # 2. í…ìŠ¤íŠ¸ ê°ì§€ ì „ì²˜ë¦¬ ì„¤ì •
            detection_settings = {}
            if 'TextDetection' in sub_modules:
                det_config = sub_modules['TextDetection']
                detection_settings = {
                    'model_name': det_config.get('model_name', 'Unknown'),
                    'thresh': det_config.get('thresh', 0.3),
                    'box_thresh': det_config.get('box_thresh', 0.6),
                    'unclip_ratio': det_config.get('unclip_ratio', 1.5),
                    'max_side_len': det_config.get('max_side_len', 960),
                    'limit_type': det_config.get('limit_type', 'max'),
                    'use_dilation': det_config.get('use_dilation', True),
                    'score_mode': det_config.get('score_mode', 'fast'),
                    'polygon': det_config.get('polygon', False),
                    'visualize': det_config.get('visualize', False)
                }
                preprocessing_settings['detection'] = detection_settings
                
                print(f"\nğŸ” í…ìŠ¤íŠ¸ ê°ì§€ ì „ì²˜ë¦¬:")
                print(f"   ëª¨ë¸: {detection_settings['model_name']}")
                print(f"   ê°ì§€ ì„ê³„ê°’: {detection_settings['thresh']}")
                print(f"   ë°•ìŠ¤ ì„ê³„ê°’: {detection_settings['box_thresh']}")
                print(f"   ì–¸í´ë¦½ ë¹„ìœ¨: {detection_settings['unclip_ratio']}")
                print(f"   ìµœëŒ€ ë³€ ê¸¸ì´: {detection_settings['max_side_len']}px")
                print(f"   í¬ê¸° ì œí•œ ë°©ì‹: {detection_settings['limit_type']}")
                print(f"   íŒ½ì°½ ì—°ì‚°: {'âœ…' if detection_settings['use_dilation'] else 'âŒ'}")
                print(f"   ì ìˆ˜ ê³„ì‚° ëª¨ë“œ: {detection_settings['score_mode']}")
                print(f"   ë‹¤ê°í˜• ê°ì§€: {'âœ…' if detection_settings['polygon'] else 'âŒ'}")
                print(f"   ì‹œê°í™”: {'âœ…' if detection_settings['visualize'] else 'âŒ'}")
            
            # 3. í…ìŠ¤íŠ¸ ì¸ì‹ ì „ì²˜ë¦¬ ì„¤ì •
            recognition_settings = {}
            if 'TextRecognition' in sub_modules:
                rec_config = sub_modules['TextRecognition']
                recognition_settings = {
                    'model_name': rec_config.get('model_name', 'Unknown'),
                    'batch_size': rec_config.get('batch_size', 6),
                    'score_thresh': rec_config.get('score_thresh', 0.5),
                    'max_text_length': rec_config.get('max_text_length', 25),
                    'image_shape': rec_config.get('image_shape', [3, 48, 320]),
                    'use_space_char': rec_config.get('use_space_char', True),
                    'limited_max_width': rec_config.get('limited_max_width', 1280),
                    'limited_min_width': rec_config.get('limited_min_width', 16),
                    'char_dict_path': rec_config.get('char_dict_path', None),
                    'visualize': rec_config.get('visualize', False)
                }
                preprocessing_settings['recognition'] = recognition_settings
                
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ ì „ì²˜ë¦¬:")
                print(f"   ëª¨ë¸: {recognition_settings['model_name']}")
                print(f"   ë°°ì¹˜ í¬ê¸°: {recognition_settings['batch_size']}")
                print(f"   ì ìˆ˜ ì„ê³„ê°’: {recognition_settings['score_thresh']}")
                print(f"   ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´: {recognition_settings['max_text_length']}")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {recognition_settings['image_shape']}")
                print(f"   ê³µë°± ë¬¸ì ì‚¬ìš©: {'âœ…' if recognition_settings['use_space_char'] else 'âŒ'}")
                print(f"   ìµœëŒ€ ë„ˆë¹„ ì œí•œ: {recognition_settings['limited_max_width']}px")
                print(f"   ìµœì†Œ ë„ˆë¹„ ì œí•œ: {recognition_settings['limited_min_width']}px")
                print(f"   ë¬¸ì ì‚¬ì „: {recognition_settings['char_dict_path'] or 'ê¸°ë³¸ê°’'}")
                print(f"   ì‹œê°í™”: {'âœ…' if recognition_settings['visualize'] else 'âŒ'}")
            
            # 4. í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜ ì „ì²˜ë¦¬ ì„¤ì •
            orientation_settings = {}
            if 'TextLineOrientation' in sub_modules:
                ori_config = sub_modules['TextLineOrientation']
                orientation_settings = {
                    'model_name': ori_config.get('model_name', 'Unknown'),
                    'score_thresh': ori_config.get('score_thresh', 0.9),
                    'batch_size': ori_config.get('batch_size', 6),
                    'image_shape': ori_config.get('image_shape', [3, 48, 192]),
                    'label_list': ori_config.get('label_list', ['0', '180']),
                    'visualize': ori_config.get('visualize', False)
                }
                preprocessing_settings['orientation'] = orientation_settings
                
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜ ì „ì²˜ë¦¬:")
                print(f"   ëª¨ë¸: {orientation_settings['model_name']}")
                print(f"   ë¶„ë¥˜ ì„ê³„ê°’: {orientation_settings['score_thresh']}")
                print(f"   ë°°ì¹˜ í¬ê¸°: {orientation_settings['batch_size']}")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {orientation_settings['image_shape']}")
                print(f"   ì§€ì› ê°ë„: {orientation_settings['label_list']}")
                print(f"   ì‹œê°í™”: {'âœ…' if orientation_settings['visualize'] else 'âŒ'}")
            else:
                print(f"\nğŸ“ í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜ ì „ì²˜ë¦¬: âŒ ë¹„í™œì„±í™”")
            
            # 5. ë¬¸ì„œ ì „ì²˜ë¦¬ ì„¤ì • (ê³ ê¸‰)
            doc_preprocessing_settings = {}
            if 'DocPreprocessor' in sub_pipelines:
                doc_preprocessor = sub_pipelines['DocPreprocessor']
                doc_sub_modules = doc_preprocessor.get('SubModules', {})
                
                doc_preprocessing_settings['enabled'] = True
                doc_preprocessing_settings['modules'] = {}
                
                print(f"\nğŸ“„ ë¬¸ì„œ ì „ì²˜ë¦¬ (ê³ ê¸‰ ê¸°ëŠ¥):")
                
                # ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜
                if 'DocOrientationClassify' in doc_sub_modules:
                    doc_ori_config = doc_sub_modules['DocOrientationClassify']
                    doc_ori_settings = {
                        'model_name': doc_ori_config.get('model_name', 'Unknown'),
                        'score_thresh': doc_ori_config.get('score_thresh', 0.9),
                        'batch_size': doc_ori_config.get('batch_size', 1)
                    }
                    doc_preprocessing_settings['modules']['orientation'] = doc_ori_settings
                    
                    print(f"   ğŸ”„ ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜:")
                    print(f"      ëª¨ë¸: {doc_ori_settings['model_name']}")
                    print(f"      ì„ê³„ê°’: {doc_ori_settings['score_thresh']}")
                    print(f"      ë°°ì¹˜ í¬ê¸°: {doc_ori_settings['batch_size']}")
                
                # ë¬¸ì„œ êµì • (ì–¸ì›Œí•‘)
                if 'DocUnwarping' in doc_sub_modules:
                    doc_unwarp_config = doc_sub_modules['DocUnwarping']
                    doc_unwarp_settings = {
                        'model_name': doc_unwarp_config.get('model_name', 'Unknown'),
                        'batch_size': doc_unwarp_config.get('batch_size', 1)
                    }
                    doc_preprocessing_settings['modules']['unwarping'] = doc_unwarp_settings
                    
                    print(f"   ğŸ“ ë¬¸ì„œ êµì • (ì–¸ì›Œí•‘):")
                    print(f"      ëª¨ë¸: {doc_unwarp_settings['model_name']}")
                    print(f"      ë°°ì¹˜ í¬ê¸°: {doc_unwarp_settings['batch_size']}")
                
                preprocessing_settings['document'] = doc_preprocessing_settings
            else:
                print(f"\nğŸ“„ ë¬¸ì„œ ì „ì²˜ë¦¬: âŒ ë¹„í™œì„±í™” (ì¼ë°˜ ëª¨ë“œ)")
                preprocessing_settings['document'] = {'enabled': False}
            
            # 6. ì´ë¯¸ì§€ ì…ë ¥ ì „ì²˜ë¦¬ ì„¤ì • (ì¶”ë¡ )
            image_preprocessing = {
                'auto_resize': True,
                'max_side_len': detection_settings.get('max_side_len', 960),
                'normalize': True,
                'channel_order': 'BGR',
                'data_type': 'float32',
                'interpolation': 'LANCZOS',
                'padding': False
            }
            preprocessing_settings['image'] = image_preprocessing
            
            print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ ì…ë ¥ ì „ì²˜ë¦¬ (ì¶”ë¡ ë¨):")
            print(f"   ìë™ í¬ê¸° ì¡°ì •: {'âœ…' if image_preprocessing['auto_resize'] else 'âŒ'}")
            print(f"   ìµœëŒ€ ë³€ ê¸¸ì´: {image_preprocessing['max_side_len']}px")
            print(f"   ì •ê·œí™”: {'âœ…' if image_preprocessing['normalize'] else 'âŒ'}")
            print(f"   ì±„ë„ ìˆœì„œ: {image_preprocessing['channel_order']}")
            print(f"   ë°ì´í„° íƒ€ì…: {image_preprocessing['data_type']}")
            print(f"   ë³´ê°„ë²•: {image_preprocessing['interpolation']}")
            print(f"   íŒ¨ë”©: {'âœ…' if image_preprocessing['padding'] else 'âŒ'}")
            
            # 7. ì´ˆê¸°í™” ì‹œ ì‚¬ìš©ëœ ì»¤ìŠ¤í…€ ì˜µì…˜ë“¤
            custom_settings = {}
            if self.init_kwargs:
                custom_settings = self.init_kwargs.copy()
                preprocessing_settings['custom'] = custom_settings
                
                print(f"\nâš™ï¸  ì´ˆê¸°í™” ì‹œ ì»¤ìŠ¤í…€ ì„¤ì •:")
                for key, value in custom_settings.items():
                    print(f"   {key}: {value}")
            else:
                print(f"\nâš™ï¸  ì´ˆê¸°í™” ì‹œ ì»¤ìŠ¤í…€ ì„¤ì •: âŒ ëª¨ë“  ê¸°ë³¸ê°’ ì‚¬ìš©")
            
            # 8. íŒŒì´í”„ë¼ì¸ í”Œë¡œìš° ìš”ì•½
            print(f"\nğŸ”„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°:")
            
            flow_steps = []
            flow_steps.append("1. ì´ë¯¸ì§€ ë¡œë“œ ë° í¬ê¸° ì¡°ì •")
            
            if preprocessing_settings['document']['enabled']:
                if 'orientation' in preprocessing_settings['document']['modules']:
                    flow_steps.append("2. ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜")
                if 'unwarping' in preprocessing_settings['document']['modules']:
                    flow_steps.append("3. ë¬¸ì„œ êµì • (ì–¸ì›Œí•‘)")
            
            flow_steps.append(f"{len(flow_steps)+1}. í…ìŠ¤íŠ¸ ê°ì§€ ({detection_settings.get('model_name', 'Unknown')})")
            
            if 'orientation' in preprocessing_settings:
                flow_steps.append(f"{len(flow_steps)+1}. í…ìŠ¤íŠ¸ ë°©í–¥ ë¶„ë¥˜")
            
            flow_steps.append(f"{len(flow_steps)+1}. í…ìŠ¤íŠ¸ ì¸ì‹ ({recognition_settings.get('model_name', 'Unknown')})")
            flow_steps.append(f"{len(flow_steps)+1}. ê²°ê³¼ í›„ì²˜ë¦¬ ë° í•„í„°ë§")
            
            for step in flow_steps:
                print(f"   {step}")
            
            # 9. ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„
            print(f"\nğŸ“Š ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„:")
            
            # ëª¨ë¸ ì¡°í•© ë¶„ì„
            det_model = detection_settings.get('model_name', '')
            rec_model = recognition_settings.get('model_name', '')
            
            is_server_det = 'server' in det_model.lower()
            is_mobile_rec = 'mobile' in rec_model.lower()
            has_doc_processing = preprocessing_settings['document']['enabled']
            has_orientation = 'orientation' in preprocessing_settings
            
            print(f"   ëª¨ë¸ ì¡°í•©: {'ì„œë²„ê¸‰' if is_server_det else 'ëª¨ë°”ì¼'} ê°ì§€ + {'ëª¨ë°”ì¼' if is_mobile_rec else 'ì„œë²„ê¸‰'} ì¸ì‹")
            print(f"   ì²˜ë¦¬ ì†ë„: {'âš¡ ê³ ì†' if is_mobile_rec else 'ğŸ¯ ê³ ì •í™•ë„'}")
            print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {'ğŸ’¾ ì ìŒ' if is_mobile_rec else 'ğŸ’¿ ë§ìŒ'}")
            print(f"   ë¬¸ì„œ ì§€ì›: {'âœ… ê³ ê¸‰' if has_doc_processing else 'âŒ ê¸°ë³¸'}")
            print(f"   ë°©í–¥ ë³´ì •: {'âœ… ì§€ì›' if has_orientation else 'âŒ ë¯¸ì§€ì›'}")
            print(f"   ë°°ì¹˜ ì²˜ë¦¬: ê°ì§€({detection_settings.get('batch_size', 'N/A')}), ì¸ì‹({recognition_settings.get('batch_size', 'N/A')})")
            
            # ì‹ ë¢°ë„ ì„¤ì • ë¶„ì„
            det_thresh = detection_settings.get('thresh', 0.3)
            rec_thresh = recognition_settings.get('score_thresh', 0.5)
            
            print(f"\nğŸ¯ ì‹ ë¢°ë„ ì„¤ì • ë¶„ì„:")
            print(f"   ê°ì§€ ë¯¼ê°ë„: {'ë†’ìŒ' if det_thresh <= 0.3 else 'ë³´í†µ' if det_thresh <= 0.5 else 'ë‚®ìŒ'} (ì„ê³„ê°’: {det_thresh})")
            print(f"   ì¸ì‹ í•„í„°ë§: {'ì—„ê²©' if rec_thresh >= 0.7 else 'ë³´í†µ' if rec_thresh >= 0.5 else 'ê´€ëŒ€'} (ì„ê³„ê°’: {rec_thresh})")
            
            overall_quality = "ê· í˜•" if (det_thresh <= 0.4 and rec_thresh >= 0.5) else \
                            "ê³ í’ˆì§ˆ" if (det_thresh <= 0.3 and rec_thresh >= 0.7) else \
                            "ê³ ì†ë„" if (det_thresh >= 0.4 and rec_thresh <= 0.4) else "ì»¤ìŠ¤í…€"
            print(f"   ì „ì²´ ì„¤ì •: {overall_quality}")
            
        except Exception as e:
            print(f"âŒ ì „ì²˜ë¦¬ ì„¤ì • ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            preprocessing_settings = {
                'error': str(e),
                'fallback': {
                    'language': self.lang,
                    'custom_options': self.init_kwargs
                }
            }
            print(f"ğŸ“Œ ê¸°ë³¸ ì •ë³´ë§Œ í‘œì‹œ: ì–¸ì–´={self.lang}, ì»¤ìŠ¤í…€ ì˜µì…˜={len(self.init_kwargs)}ê°œ")
        
        return preprocessing_settings



    def run_ocr_from_path(self, file_path: str) -> list[dict] | None:
        """
        íŒŒì¼ ê²½ë¡œì—ì„œ OCRì„ ì‹¤í–‰í•˜ê³  ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            file_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            list[dict] | None: PaddleOCR ì›ë³¸ ê²°ê³¼ (ì„±ê³µì‹œ OCRResult ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # PaddleOCR ì›ë³¸ ê²°ê³¼ ë°˜í™˜
            result = self._ocr_engine.predict(file_path)
            # print(f"result: {result}")

            return result
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ OCR ì‹¤íŒ¨: {e}")
            return None
    
    def run_ocr_from_nparray(self, image_array: np.ndarray) -> list[dict] | None:
        """
        numpy ë°°ì—´ì—ì„œ OCRì„ ì‹¤í–‰í•˜ê³  ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            image_array (np.ndarray): OpenCV ì´ë¯¸ì§€ ë°°ì—´ (BGR í˜•ì‹)
            
        Returns:
            list[dict] | None: PaddleOCR ì›ë³¸ ê²°ê³¼ (ì„±ê³µì‹œ OCRResult ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # PaddleOCR ì›ë³¸ ê²°ê³¼ ë°˜í™˜
            result = self._ocr_engine.predict(image_array)
            return result
            
        except Exception as e:
            print(f"âŒ ë°°ì—´ OCR ì‹¤íŒ¨: {e}")
            return None
    
    def run_ocr_from_bytes(self, image_bytes: bytes) -> list[dict] | None:
        """
        ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ OCRì„ ì‹¤í–‰í•˜ê³  ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            image_bytes (bytes): ì´ë¯¸ì§€ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
            
        Returns:
            list[dict] | None: PaddleOCR ì›ë³¸ ê²°ê³¼ (ì„±ê³µì‹œ OCRResult ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            nparr = np.frombuffer(image_bytes, np.uint8)
            cv_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            # numpy ë°°ì—´ë¡œ OCR ì‹¤í–‰ (ì¬ê·€ í˜¸ì¶œ)
            return self.run_ocr_from_nparray(cv_image)
            
        except Exception as e:
            print(f"âŒ ë°”ì´íŠ¸ ë°ì´í„° OCR ì‹¤íŒ¨: {e}")
            return None




    def extract_text_with_confidence(self, ocr_result) -> list[dict[str, str | float | None]]:
        """
        OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ì™€ ì‹ ë¢°ë„ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        
        Args:
            ocr_result: OCR ê²°ê³¼ ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬
            
        Returns:
            list[dict[str, str | float | None]]: [{"text": str, "confidence": float | None}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
            ë°ì´í„° ë¬´ê²°ì„± ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        """
        # rec_texts ì†ì„± í™•ì¸
        if hasattr(ocr_result, 'rec_texts'):
            rec_texts = ocr_result.rec_texts
        elif isinstance(ocr_result, dict) and 'rec_texts' in ocr_result:
            rec_texts = ocr_result['rec_texts']
        else:
            print("âŒ rec_textsë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # rec_scores ì†ì„± í™•ì¸ (í•œ ë²ˆë§Œ)
        rec_scores = None
        if hasattr(ocr_result, 'rec_scores'):
            rec_scores = ocr_result.rec_scores
        elif isinstance(ocr_result, dict) and 'rec_scores' in ocr_result:
            rec_scores = ocr_result['rec_scores']
        else:
            print("âŒ rec_scoresë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # rec_textsì™€ rec_scores ê¸¸ì´ê°€ ê°™ë‹¤ë©´ zipìœ¼ë¡œ í•¨ê»˜ ì²˜ë¦¬
        if rec_scores and len(rec_texts) == len(rec_scores):
            # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            result_list = []
            for text, confidence in zip(rec_texts, rec_scores):
                result_list.append({
                    "text": text,
                    "confidence": round(float(confidence), 2)
                })
            return result_list    
        else:
            # ê¸¸ì´ê°€ ë‹¤ë¥´ê±°ë‚˜ rec_scoresê°€ ì—†ìœ¼ë©´ [] ë°˜í™˜
            return []

    def convert_to_json(self, result, pretty: bool = True):
        """jsonpickleì„ ì‚¬ìš©í•œ JSON ë³€í™˜"""
        try:
            # jsonpickleì€ numpy ë°°ì—´, ë³µì¡í•œ ê°ì²´ ëª¨ë‘ ì²˜ë¦¬
            json_string = jsonpickle.encode(
                result, 
                unpicklable=False,  # ìˆœìˆ˜ JSONë§Œ ìƒì„±
                make_refs=False     # ì°¸ì¡° ì œê±°
            )
            
            if pretty:
                import json
                parsed = json.loads(json_string)
                return json.dumps(parsed, indent=2, ensure_ascii=False)
            
            return json_string
            
        except Exception as e:
            print(f"âŒ jsonpickle ë³€í™˜ ì‹¤íŒ¨: {e}")
            return json.dumps({"error": str(e)})

    def convert_to_structured_json(self, result, pretty: bool = True):
        """
        OCR ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë³„ë¡œ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜
        
        Args:
            result: run_ocr_from_* ë©”ì„œë“œì˜ ë°˜í™˜ê°’
            pretty (bool): ë“¤ì—¬ì“°ê¸° ì ìš© ì—¬ë¶€
            
        Returns:
            str: êµ¬ì¡°í™”ëœ JSON ë¬¸ìì—´
            
        Example:
            [
                {
                    "rec_text": "ì•ˆë…•í•˜ì„¸ìš”",
                    "rec_score": 0.9876,
                    "rec_poly": [[100, 50], [200, 50], [200, 80], [100, 80]],
                    "dt_poly": [[99.5, 49.8], [201.2, 50.1], [200.9, 80.3], [99.7, 79.9]],
                    "dt_score": 0.9543,
                    "ori_poly": [[100, 50], [200, 50], [200, 80], [100, 80]],
                    "ori_scores": 0.9234
                },
                ...
            ]
        """
        try:
            if not result or len(result) == 0:
                return "[]"
            
            page_result = result[0]
            
            # PaddleOCR 3.2.0 ê²°ê³¼ êµ¬ì¡° ì²˜ë¦¬
            if isinstance(page_result, dict):
                texts = page_result.get('rec_texts', [])
                rec_scores = page_result.get('rec_scores', [])
                rec_polys = page_result.get('rec_polys', [])
                dt_polys = page_result.get('dt_polys', [])
                dt_scores = page_result.get('dt_scores', [])
                ori_polys = page_result.get('ori_polys', [])
                ori_scores = page_result.get('ori_scores', [])
            else:
                # êµ¬ë²„ì „ í˜¸í™˜ì„±: [[ì¢Œí‘œ, (í…ìŠ¤íŠ¸, ì‹ ë¢°ë„)], ...]
                texts = []
                rec_scores = []
                rec_polys = []
                dt_polys = []
                dt_scores = []
                ori_polys = []
                ori_scores = []
                
                for item in page_result:
                    if len(item) >= 2:
                        dt_polys.append(item[0])
                        rec_polys.append(item[0])  # êµ¬ë²„ì „ì—ì„œëŠ” ë™ì¼
                        if isinstance(item[1], tuple):
                            texts.append(item[1][0])
                            rec_scores.append(item[1][1])
                        else:
                            texts.append(str(item[1]))
                            rec_scores.append(0.0)
                        
                        # êµ¬ë²„ì „ì—ì„œëŠ” ì¶”ê°€ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’
                        dt_scores.append(0.0)
                        ori_polys.append(item[0])
                        ori_scores.append(0.0)
            
            # í…ìŠ¤íŠ¸ë³„ êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±
            structured_data = []
            
            # ëª¨ë“  ë°°ì—´ì˜ ìµœëŒ€ ê¸¸ì´ ê³„ì‚°
            max_length = max(
                len(texts), len(rec_scores), len(rec_polys),
                len(dt_polys), len(dt_scores), len(ori_polys), len(ori_scores)
            )
            
            for i in range(max_length):
                # ê° í•„ë“œì—ì„œ ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ (ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
                text_item = {
                    "rec_text": texts[i] if i < len(texts) else "",
                    "rec_score": float(rec_scores[i]) if i < len(rec_scores) else 0.0,
                    "rec_poly": self._convert_poly_to_list(rec_polys[i]) if i < len(rec_polys) else [],
                    "dt_poly": self._convert_poly_to_list(dt_polys[i]) if i < len(dt_polys) else [],
                    "dt_score": float(dt_scores[i]) if i < len(dt_scores) else 0.0,
                    "ori_poly": self._convert_poly_to_list(ori_polys[i]) if i < len(ori_polys) else [],
                    "ori_scores": float(ori_scores[i]) if i < len(ori_scores) else 0.0
                }
                
                structured_data.append(text_item)
            
            # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            import json
            if pretty:
                return json.dumps(structured_data, indent=2, ensure_ascii=False)
            else:
                return json.dumps(structured_data, ensure_ascii=False)
                
        except Exception as e:
            print(f"âŒ êµ¬ì¡°í™”ëœ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return json.dumps({"error": str(e)}, ensure_ascii=False)
    
    def _convert_poly_to_list(self, poly):
        """
        ë‹¤ì–‘í•œ í˜•íƒœì˜ ì¢Œí‘œ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            poly: numpy ë°°ì—´, ë¦¬ìŠ¤íŠ¸, ë˜ëŠ” ê¸°íƒ€ ì¢Œí‘œ ë°ì´í„°
            
        Returns:
            list: [[x1, y1], [x2, y2], [x3, y3], [x4, y4]] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if poly is None:
                return []
            
            # numpy ë°°ì—´ì¸ ê²½ìš°
            if isinstance(poly, np.ndarray):
                # 1ì°¨ì› ë°°ì—´ì„ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜ (8ê°œ ê°’ â†’ 4x2)
                if poly.ndim == 1 and len(poly) == 8:
                    poly = poly.reshape(4, 2)
                
                # 2ì°¨ì› ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if poly.ndim == 2:
                    return [[float(x), float(y)] for x, y in poly]
                else:
                    return poly.tolist()
            
            # ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            elif isinstance(poly, list):
                # í‰ë©´ ë¦¬ìŠ¤íŠ¸ [x1, y1, x2, y2, ...] â†’ [[x1, y1], [x2, y2], ...]
                if len(poly) == 8 and all(isinstance(x, (int, float)) for x in poly):
                    return [[float(poly[i]), float(poly[i+1])] for i in range(0, 8, 2)]
                # ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœì¸ ê²½ìš°
                elif len(poly) > 0 and isinstance(poly[0], (list, tuple)):
                    return [[float(x), float(y)] for x, y in poly]
                else:
                    return poly
            
            # ê¸°íƒ€ í˜•íƒœì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ íŒŒì‹± ì‹œë„
            else:
                return str(poly)
                
        except Exception as e:
            print(f"âš ï¸ ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return []


    def _x_extract_reference_words_simple(self, result, left_region_ratio=0.10, confidence_threshold=0.3, min_word_length=2):
        """
        ê°„ë‹¨í•œ ì™¼ìª½ ì˜ì—­ í•„í„°ë§ì„ í†µí•œ ê¸°ì¤€ë‹¨ì–´ ì¶”ì¶œ
        
        rec_polysì˜ left ê°’ì´ ë¬¸ì„œ ë„ˆë¹„ì˜ 10% ì´ë‚´ì— ìˆëŠ” í…ìŠ¤íŠ¸ë“¤ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
        """
        if not result or len(result) == 0:
            print("âŒ OCR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            page_result = result[0]
            
            # PaddleOCR 3.2.0 ê²°ê³¼ êµ¬ì¡° ì²˜ë¦¬ - rec_polys ì‚¬ìš©
            if isinstance(page_result, dict):
                texts = page_result.get('rec_texts', [])
                scores = page_result.get('rec_scores', [])
                polys = page_result.get('rec_polys', [])
                print("ğŸ” ì‚¬ìš© ì¢Œí‘œ: rec_polys (ì •ê·œí™”ëœ ìœ„ì¹˜)")
            else:
                # êµ¬ë²„ì „ í˜¸í™˜ì„±
                texts = []
                scores = []
                polys = []
                for item in page_result:
                    if len(item) >= 2:
                        polys.append(item[0])
                        if isinstance(item[1], tuple):
                            texts.append(item[1][0])
                            scores.append(item[1][1])
                        else:
                            texts.append(str(item[1]))
                            scores.append(0.0)
            
            if not texts or not polys:
                print("âŒ ì¸ì‹ëœ í…ìŠ¤íŠ¸ë‚˜ ì¢Œí‘œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ë¬¸ì„œ ë„ˆë¹„ ê³„ì‚°
            all_x_coords = []
            for poly in polys:
                all_x_coords.extend([point[0] for point in poly])
            
            min_x = min(all_x_coords)
            max_x = max(all_x_coords)
            document_width = max_x - min_x
            left_boundary = min_x + document_width * left_region_ratio
            
            print(f"ğŸ“ ë¬¸ì„œ ë„ˆë¹„: {document_width:.1f}, ì™¼ìª½ ê²½ê³„: {left_boundary:.1f}")
            
            # ì™¼ìª½ ì˜ì—­ í•„í„°ë§
            left_items = []
            for i in range(min(len(texts), len(polys), len(scores))):
                text = texts[i].strip()
                poly = polys[i]
                confidence = scores[i] if i < len(scores) else 0.0
                
                # ì‹ ë¢°ë„ ë° ê¸¸ì´ í•„í„°ë§
                if confidence < confidence_threshold or len(text) < min_word_length:
                    continue
                
                # left ê°’ ê³„ì‚°
                left = min([point[0] for point in poly])
                top = min([point[1] for point in poly])
                bottom = max([point[1] for point in poly])
                center_y = (top + bottom) / 2
                
                # ì™¼ìª½ ì˜ì—­ í•„í„°ë§
                if left <= left_boundary:
                    left_items.append({
                        'text': text,
                        'confidence': confidence,
                        'left': left,
                        'center_y': center_y
                    })
            
            # Y ì¢Œí‘œ ê¸°ì¤€ ì •ë ¬
            left_items.sort(key=lambda x: x['center_y'])
            
            return left_items
            
        except Exception as e:
            print(f"âŒ ê°„ë‹¨ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _setup_korean_font(self):
        """í•œê¸€ í°íŠ¸ ì„¤ì • (NanumGothic ì‚¬ìš©)"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.font_manager as fm
            import os
            
            # NanumGothic í°íŠ¸ ì§ì ‘ ë“±ë¡
            nanum_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
            
            if os.path.exists(nanum_path):
                # í°íŠ¸ ë“±ë¡
                fm.fontManager.addfont(nanum_path)
                font_prop = fm.FontProperties(fname=nanum_path)
                
                # matplotlib ì„¤ì •
                plt.rcParams['font.family'] = font_prop.get_name()
                plt.rcParams['axes.unicode_minus'] = False
                
                print(f"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {font_prop.get_name()}")
                
            else:
                # ëŒ€ì²´ í°íŠ¸ ì‚¬ìš©
                plt.rcParams['font.family'] = 'DejaVu Sans'
                plt.rcParams['axes.unicode_minus'] = False
                print("âš ï¸ NanumGothicì„ ì°¾ì„ ìˆ˜ ì—†ì–´ DejaVu Sans ì‚¬ìš©")
                
        except Exception as e:
            print(f"âŒ í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}")
            import matplotlib.pyplot as plt
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
    
    def debug_ocr_result(self, result, image_path: str = None):
        """
        PaddleOCR 3.2.0 ì‹œê°í™” 
        
        Args:
            result: PaddleOCR.predict() ë°˜í™˜ê°’
            image_path (str, optional): ì‹œê°í™”í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ. Noneì´ë©´ í…ìŠ¤íŠ¸ ë¶„ì„ë§Œ ìˆ˜í–‰
        """
        try:
            print(f"ğŸ¨ PaddleOCR 3.2.0 ì‹œê°í™” ì‹œì‘...")
            
            if not result or len(result) == 0:
                print("âŒ í‘œì‹œí•  OCR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            page_result = result[0]
            if not isinstance(page_result, dict):
                print("âŒ OCR ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return
            
            # OCR ê²°ê³¼ ì¶”ì¶œ
            texts = page_result.get('rec_texts', [])
            polys = page_result.get('dt_polys', page_result.get('rec_polys', []))
            scores = page_result.get('rec_scores', [])
            
            if not texts or not polys:
                print("âŒ í…ìŠ¤íŠ¸ë‚˜ ì¢Œí‘œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # OCR ê²°ê³¼ í…ìŠ¤íŠ¸ ë¶„ì„ (í•­ìƒ ì‹¤í–‰)
            print("ğŸ” OCR ê²°ê³¼ ë¶„ì„:")
            
            if isinstance(result, list) and len(result) > 0:
                page_result = result[0]
                if isinstance(page_result, dict):
                    texts = page_result.get('rec_texts', [])
                    scores = page_result.get('rec_scores', [])
                    polys = page_result.get('rec_polys', [])
                    
                    print(f"   ğŸ“ í…ìŠ¤íŠ¸: {len(texts)}ê°œ")
                    print(f"   ğŸ“Š ì‹ ë¢°ë„: {len(scores)}ê°œ")
                    print(f"   ğŸ“ ì¢Œí‘œ: {len(polys)}ê°œ")
                    print(f"   ğŸ”‘ ì „ì²´ í‚¤: {list(page_result.keys())}")
                    
                    if texts:
                        print(f"   ğŸ“„ ì¸ì‹ëœ í…ìŠ¤íŠ¸ë“¤:")
                        for i, text in enumerate(texts, 1):
                            confidence = f" (ì‹ ë¢°ë„: {scores[i-1]:.4f})" if i-1 < len(scores) else ""
                            print(f"      {i}. '{text}'{confidence}")
                    
                    # ì‹ ë¢°ë„ í†µê³„
                    if scores:
                        avg_confidence = sum(scores) / len(scores)
                        print(f"   ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.4f}")
                        print(f"   ğŸ“Š ì‹ ë¢°ë„ ë²”ìœ„: {min(scores):.4f} ~ {max(scores):.4f}")
                        
                else:
                    print(f"   âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ êµ¬ì¡°: {type(page_result)}")
            else:
                print(f"   âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìµœìƒìœ„ êµ¬ì¡°: {type(result)}")

            # image_pathê°€ ì œê³µëœ ê²½ìš°ì—ë§Œ ì´ë¯¸ì§€ ì‹œê°í™” ì‹¤í–‰
            if image_path is None:
                print("ğŸ’¡ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ ë¶„ì„ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.")
                print("   ì‹œê°í™”ë¥¼ ì›í•œë‹¤ë©´ image_pathë¥¼ ì§€ì •í•˜ì„¸ìš”.")
                return

            # ìƒˆë¡œìš´ PaddleX ê¸°ë°˜ ì‹œê°í™” êµ¬í˜„
            from PIL import Image, ImageDraw, ImageFont
            import matplotlib.pyplot as plt
            import numpy as np
            import os
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
            pil_image = Image.open(image_path).convert('RGB')
            draw = ImageDraw.Draw(pil_image)
            
            print(f"ğŸ“Š ì‹œê°í™” ì •ë³´:")
            print(f"   - ì´ë¯¸ì§€ í¬ê¸°: {pil_image.size}")
            print(f"   - í…ìŠ¤íŠ¸ ìˆ˜: {len(texts)}")
            print(f"   - ì¢Œí‘œ ìˆ˜: {len(polys)}")
            
            # í°íŠ¸ ì„¤ì •
            try:
                font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
                if os.path.exists(font_path):
                    font = ImageFont.truetype(font_path, 24)
                    label_font = ImageFont.truetype(font_path, 16)
                else:
                    font = ImageFont.load_default()
                    label_font = ImageFont.load_default()
            except:
                font = ImageFont.load_default()
                label_font = ImageFont.load_default()
            
            # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            colors = [
                (255, 0, 0),     # ë¹¨ê°•
                (0, 255, 0),     # ì´ˆë¡
                (0, 0, 255),     # íŒŒë‘
                (255, 165, 0),   # ì£¼í™©
                (128, 0, 128),   # ë³´ë¼
                (255, 20, 147),  # ë¶„í™
                (0, 191, 255),   # í•˜ëŠ˜ìƒ‰
                (255, 215, 0),   # ê¸ˆìƒ‰
            ]
            
            # ë°”ìš´ë”© ë°•ìŠ¤ì™€ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            for i, (text, poly) in enumerate(zip(texts, polys)):
                try:
                    # ì¢Œí‘œ ì •ê·œí™”
                    if isinstance(poly, (list, np.ndarray)):
                        poly_array = np.array(poly, dtype=np.float32)
                        
                        if poly_array.ndim == 1 and len(poly_array) == 8:
                            poly_array = poly_array.reshape(4, 2)
                        
                        if poly_array.ndim == 2 and poly_array.shape[0] >= 4:
                            # ë‹¤ê°í˜• ì¢Œí‘œ
                            polygon_points = [(int(p[0]), int(p[1])) for p in poly_array]
                            
                            # ìƒ‰ìƒ ì„ íƒ (ìˆœí™˜)
                            color = colors[i % len(colors)]
                            
                            # ë‹¤ê°í˜• í…Œë‘ë¦¬ ê·¸ë¦¬ê¸°
                            draw.polygon(polygon_points, outline=color, width=3)
                            
                            # ë²ˆí˜¸ ë ˆì´ë¸” ìœ„ì¹˜ (ì™¼ìª½ ìƒë‹¨)
                            label_x = int(poly_array[0][0])
                            label_y = max(0, int(poly_array[0][1]) - 25)
                            
                            # ë²ˆí˜¸ ë°°ê²½ (ê°€ë…ì„±ì„ ìœ„í•´)
                            label_text = str(i + 1)
                            try:
                                bbox = draw.textbbox((label_x, label_y), label_text, font=label_font)
                                draw.rectangle(bbox, fill=color)
                            except:
                                # textbboxê°€ ì—†ëŠ” êµ¬ë²„ì „ PIL ëŒ€ì‘
                                draw.rectangle((label_x-2, label_y-2, label_x+20, label_y+18), fill=color)
                            
                            # ë²ˆí˜¸ í…ìŠ¤íŠ¸
                            draw.text((label_x, label_y), label_text, fill=(255, 255, 255), font=label_font)
                            
                            # ì‹ ë¢°ë„ í‘œì‹œ (ì„ íƒì )
                            if i < len(scores):
                                confidence_text = "{:.3f}".format(scores[i])
                                conf_y = label_y + 20
                                draw.text((label_x, conf_y), confidence_text, fill=color, font=label_font)
                            
                            # ë¡œê·¸ ì¶œë ¥
                            score_text = "{:.3f}".format(scores[i]) if i < len(scores) else 'N/A'
                            print("   âœ… {}. '{}' - ì‹ ë¢°ë„: {}".format(i+1, text, score_text))
                            
                except Exception as e:
                    print("   âŒ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨ ({}): {}".format(i+1, str(e)))
                    continue
            
            # matplotlibìœ¼ë¡œ í‘œì‹œ
            self._setup_korean_font()
            
            plt.figure(figsize=(20, 14))
            plt.imshow(pil_image)
            # íƒ€ì´í‹€ ì œê±° (ìš”ì²­ì‚¬í•­ 3)
            plt.axis('off')
            
            # ì¢Œì¸¡ í•˜ë‹¨: ì¸ì‹ëœ í…ìŠ¤íŠ¸ ëª©ë¡ (ì‹ ë¢°ë„ ë§‰ëŒ€ ì œê±°, í•œê¸€ ê¹¨ì§ ë°©ì§€)
            text_info_lines = []
            for i, (text, score) in enumerate(zip(texts, scores)):
                # ì‹ ë¢°ë„ ë§‰ëŒ€ ê·¸ë˜í”„ ì œê±° (ìš”ì²­ì‚¬í•­ 1)
                line = "{}. {} ({:.3f})".format(i+1, text, score)
                text_info_lines.append(line)
            
            text_info = "\n".join(text_info_lines)
            
            # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ fontfamily ì œê±° (ìš”ì²­ì‚¬í•­ 1)
            plt.figtext(0.02, 0.02, "ì¸ì‹ëœ í…ìŠ¤íŠ¸:\n{}".format(text_info), 
                    fontsize=11, verticalalignment='bottom',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.95))
            
            # ì¢Œì¸¡ ìƒë‹¨: í†µê³„ ì •ë³´ (ìš”ì²­ì‚¬í•­ 2)
            if scores:
                avg_confidence = sum(scores) / len(scores)
                min_score = min(scores)
                max_score = max(scores)
                stats_text = "ì´ {}ê°œ í…ìŠ¤íŠ¸\ní‰ê·  ì‹ ë¢°ë„: {:.3f}\në²”ìœ„: {:.3f} ~ {:.3f}".format(
                    len(texts), avg_confidence, min_score, max_score
                )
            else:
                stats_text = "ì´ {}ê°œ í…ìŠ¤íŠ¸\nì‹ ë¢°ë„ ì •ë³´ ì—†ìŒ".format(len(texts))
            
            # ìœ„ì¹˜ë¥¼ ì¢Œì¸¡ ìƒë‹¨ìœ¼ë¡œ ë³€ê²½ (0.02, 0.98)
            plt.figtext(0.02, 0.98, stats_text, 
                    fontsize=12, horizontalalignment='left', verticalalignment='top',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.9))
            
            plt.tight_layout()
            plt.show()
            
            print("âœ… PaddleOCR 3.2.0 ì‹œê°í™” ì™„ë£Œ!")
            if scores:
                avg_confidence = sum(scores) / len(scores)
                print("ğŸ“Š í†µê³„: í‰ê·  ì‹ ë¢°ë„ {:.4f}, ë²”ìœ„ {:.3f}~{:.3f}".format(
                    avg_confidence, min(scores), max(scores)
                ))
            
        except Exception as e:
            print("âŒ PaddleOCR 3.2.0 ì‹œê°í™” ì‹¤íŒ¨: {}".format(str(e)))
            import traceback
            traceback.print_exc()

   





