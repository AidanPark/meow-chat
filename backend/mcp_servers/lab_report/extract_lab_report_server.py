"""
ê±´ê°•ê²€ì§„(í˜ˆì•¡ê²€ì‚¬) ë¦¬í¬íŠ¸ ì „ìš© OCR í›„ì²˜ë¦¬ ì„œë²„ (í¬íŠ¸ 8004)
- ê³µí†µ OCR ê²°ê³¼(JSON)ë¥¼ ë°›ì•„ ì¶”ì¶œ/ë³‘í•©ì„ ê±°ì³ ìµœì¢… MergeEnvelope JSONì„ ë°˜í™˜í•œë‹¤.
"""

import os
import sys
import json
import logging
from logging.handlers import RotatingFileHandler
from typing import Any, List, Sequence

from mcp.server.fastmcp import FastMCP
from starlette.applications import Starlette
from starlette.responses import JSONResponse
from starlette.routing import Route
import uvicorn

_project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)

from mcp_servers.common.runtime import (
    setup_logging,
    load_mcp_server_settings,
    get_project_root,
)


setup_logging()
logger = logging.getLogger(__name__)

LOG_DIR = os.path.join(get_project_root(), "logs")
os.makedirs(LOG_DIR, exist_ok=True)
LOG_PATH = os.path.join(LOG_DIR, "lab_report.log")
if not any(getattr(h, "baseFilename", None) == LOG_PATH for h in logger.handlers):
    file_handler = RotatingFileHandler(LOG_PATH, maxBytes=5 * 1024 * 1024, backupCount=3, encoding="utf-8")
    file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(name)s - %(message)s"))
    logger.addHandler(file_handler)
    logger.setLevel(logging.INFO)

from app.core.deps import get_lab_report_extractor, get_image_preprocessor, get_ocr_service  # noqa: E402
from app.models.envelopes import OCRResultEnvelope, OCRData, OCRMeta, MergeEnvelope


mcp = FastMCP("LabReportServer")

_host, _port = load_mcp_server_settings("extract_lab_report", default_port=8004)
mcp.settings.host = _host
mcp.settings.port = _port


_IMAGE_PREPROCESSOR = None
_OCR_SVC = None


def _get_preprocessor():
    global _IMAGE_PREPROCESSOR
    if _IMAGE_PREPROCESSOR is None:
        _IMAGE_PREPROCESSOR = get_image_preprocessor()
    return _IMAGE_PREPROCESSOR


def _get_ocr_service():
    global _OCR_SVC
    if _OCR_SVC is None:
        _OCR_SVC = get_ocr_service()
    return _OCR_SVC


def _run_ocr_pipeline(image_bytes: bytes, do_preprocess: bool, debug: bool) -> OCRResultEnvelope:
    data = image_bytes
    if do_preprocess:
        try:
            data = _get_preprocessor().process_bytes(data, debug=bool(debug))
        except Exception as exc:
            logger.exception("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: do_preprocess=%s, debug=%s", do_preprocess, debug)
            raise RuntimeError(f"image preprocessing failed: {exc}") from exc

    ocr_service = _get_ocr_service()
    try:
        ocr_result_raw = ocr_service.run_ocr_from_bytes(data)
    except Exception as exc:
        logger.exception("PaddleOCR ì‹¤í–‰ ì‹¤íŒ¨")
        raise RuntimeError(f"paddleocr execution failed: {exc}") from exc

    if ocr_result_raw is None:
        logger.error("PaddleOCRê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
        raise RuntimeError("paddleocr returned no result")

    if hasattr(ocr_result_raw, "data") and hasattr(ocr_result_raw, "meta"):
        return ocr_result_raw  # type: ignore[return-value]

    logger.warning("ì˜ˆìƒì¹˜ ëª»í•œ OCR ë°˜í™˜ í˜•íƒœ: %r", type(ocr_result_raw))
    return OCRResultEnvelope(stage="ocr", data=OCRData(items=[]), meta=OCRMeta(items=0))


@mcp.tool()
async def extract_lab_report(paths: Sequence[str], do_preprocess: bool = True, debug: bool = False) -> str:
    """ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ë‚´ë¶€ì—ì„œ OCRâ†’ì¶”ì¶œâ†’ë³‘í•©ê¹Œì§€ ìˆ˜í–‰í•˜ê³  MergeEnvelope(JSON)ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    ì…ë ¥:
    - paths: ì´ë¯¸ì§€ ê²½ë¡œë“¤ì˜ ì‹œí€€ìŠ¤(str). í•œ ì¥ ì´ìƒ í—ˆìš©í•©ë‹ˆë‹¤.
    - do_preprocess: ì „ì²˜ë¦¬ ì‚¬ìš© ì—¬ë¶€(ê¸°ë³¸ê°’ True)
    - debug: ë””ë²„ê·¸ ëª¨ë“œ(ê¸°ë³¸ê°’ False)

    ì¶œë ¥:
    - MergeEnvelope(JSON ë¬¸ìì—´). RBC/HCT/HGB/WBC ë“± í•µì‹¬ ìˆ˜ì¹˜ ë° ë©”íƒ€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """
    if isinstance(paths, str):  # type: ignore[arg-type]
        paths = [paths]
    if not isinstance(paths, Sequence) or not paths:
        return json.dumps({"error": "paths must be a non-empty list"}, ensure_ascii=False)

    lab_report_extractor = get_lab_report_extractor(progress_cb=None)
    extractions: List[dict] = []
    failures: List[dict] = []

    loop = None
    try:
        import asyncio as _asyncio
        loop = _asyncio.get_running_loop()
    except Exception:
        loop = None

    for idx, path in enumerate(paths):
        logger.info("ğŸ–¼ï¸ EXTRACT_LAB_REPORT í˜¸ì¶œ: path=%s, do_preprocess=%s, debug=%s", path, do_preprocess, debug)
        if not path or not os.path.exists(path):
            msg = f"File not found: {path}"
            logger.error(msg)
            failures.append({"index": idx, "path": path, "error": msg})
            continue

        try:
            with open(path, "rb") as f:
                b = f.read()
        except Exception as e:
            msg = f"Failed to read file: {e}"
            logger.error(msg)
            failures.append({"index": idx, "path": path, "error": msg})
            continue

        try:
            if loop:
                ocr_env = await loop.run_in_executor(
                    None,
                    lambda b=b: _run_ocr_pipeline(
                        b,
                        do_preprocess=do_preprocess,
                        debug=debug,
                    ),
                )
            else:
                ocr_env = _run_ocr_pipeline(b, do_preprocess=do_preprocess, debug=debug)
        except Exception as exc:
            logger.exception("OCR íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: path=%s", path)
            failures.append({"index": idx, "path": path, "error": str(exc)})
            continue

        try:
            # ì €ìˆ˜ì¤€ ë””ë²„ê·¸ëŠ” ë¹„í™œì„±í™”í•˜ë˜, ê³ ìˆ˜ì¤€ ë””ë²„ê·¸(Step 12/13)ë¥¼ ëª…ì‹œ ì¶œë ¥
            # 1) ë¼ì¸ ê·¸ë£¹í•‘ â†’ 2) ì¸í„°ë¯¸ë””ì—‡ í¬í•¨ ì¶”ì¶œ â†’ 3) Step12/13 ìš”ì•½ ì¶œë ¥ â†’ 4) ìµœì¢… doc ìˆ˜ì§‘
            try:
                _data = getattr(ocr_env, 'data', None)
                _items = getattr(_data, 'items', None)
                items = _items if isinstance(_items, list) else None
                lined = lab_report_extractor.line_preproc.extract_and_group_lines(items[0] if items and len(items) > 0 else None)
            except Exception as le:
                raise RuntimeError(f"line grouping failed: {le}")

            # ì¶”ì¶œ + ì¸í„°ë¯¸ë””ì—‡
            try:
                result = lab_report_extractor.extractor.extract_from_lines(lined, return_intermediates=True)
                if isinstance(result, tuple) and len(result) == 2:
                    final_doc, intermediates = result
                else:
                    final_doc, intermediates = (result if isinstance(result, dict) else {}), {}
            except Exception as ee:
                raise RuntimeError(f"extraction failed: {ee}")

            # ë””ë²„ê·¸ ì¶œë ¥: Step 12 / Step 13 (ì´ë¯¸ì§€ë³„)
            try:
                step12_txt = lab_report_extractor.extractor.debug_step12(intermediates)
                if step12_txt:
                    logger.info("\n===== [Image %d] Step 12 =====\n%s\n", idx + 1, step12_txt)
            except Exception:
                pass
            try:
                step13_txt = lab_report_extractor.extractor.debug_step13(intermediates)
                if step13_txt:
                    logger.info("\n===== [Image %d] Step 13 =====\n%s\n", idx + 1, step13_txt)
            except Exception:
                pass

            # ìµœì¢… ë¬¸ì„œ ìˆ˜ì§‘ (ì´ì „ ocr_to_extractionê³¼ ë™ì¼í•œ í˜•ì‹ ë³´ì¥)
            extractions.append(final_doc if isinstance(final_doc, dict) else {})
        except Exception as exc:
            logger.exception("extraction ì‹¤íŒ¨: path=%s", path)
            failures.append({"index": idx, "path": path, "error": f"extraction_failed: {exc}"})
            continue

    if not extractions:
        return json.dumps(
            {
                "error": "no_valid_images",
                "message": "ìœ íš¨í•œ ì´ë¯¸ì§€ì—ì„œ OCR/ì¶”ì¶œì„ ìˆ˜í–‰í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "failures": failures,
            },
            ensure_ascii=False,
        )

    try:
        merged_env: MergeEnvelope = lab_report_extractor.merge_extractions(extractions)
        # ìµœì¢… ë³‘í•© JSONì„ ì„œë²„ ì½˜ì†”ì— ì¶œë ¥
        try:
            logger.info("\n===== Final Merged JSON =====\n%s\n", merged_env.model_dump_json(indent=2, ensure_ascii=False))
        except Exception:
            pass
        return merged_env.model_dump_json(indent=2, ensure_ascii=False)
    except Exception as exc:  # pragma: no cover
        logger.error("merge_extractions ì‹¤íŒ¨: %s", exc)
        return json.dumps({"error": str(exc), "failures": failures}, ensure_ascii=False)


if __name__ == "__main__":
    logger.info("ğŸš€ ê±´ê°•ê²€ì§„ OCR í›„ì²˜ë¦¬ MCP ì„œë²„ ì‹œì‘ ì¤‘...")
    logger.info("ğŸ“‹ ë“±ë¡ëœ ë„êµ¬ë“¤: extract_lab_report")
    logger.info(f"ğŸŒ ì„œë²„ ì£¼ì†Œ: http://{mcp.settings.host or '127.0.0.1'}:{mcp.settings.port or 8004} (SSE: /sse, Health: /health)")

    async def health(_request):
        return JSONResponse({"status": "ok", "server": "LabReportServer"})

    sse_app = mcp.sse_app()
    routes = [
        Route("/health", endpoint=health),
        *sse_app.routes,
    ]

    app = Starlette(routes=routes, middleware=sse_app.user_middleware)

    uvicorn.run(app, host=mcp.settings.host or "127.0.0.1", port=mcp.settings.port or 8004)
