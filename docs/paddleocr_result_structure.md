# PaddleOCR ê²°ê³¼ êµ¬ì¡° ì™„ì „ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

PaddleOCRì˜ `predict()` ë©”ì„œë“œëŠ” ë³µì¡í•œ êµ¬ì¡°ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” ê²°ê³¼ êµ¬ì¡°ë¥¼ ì™„ì „íˆ ë¶„ì„í•˜ê³  ê° í•„ë“œì˜ ì˜ë¯¸ì™€ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ” ì „ì²´ ê²°ê³¼ êµ¬ì¡°

```python
result = [
    {  # ì²« ë²ˆì§¸ í˜ì´ì§€ ê²°ê³¼
        # === í•µì‹¬ OCR ê²°ê³¼ ===
        'rec_texts': [...],         # ì¸ì‹ëœ í…ìŠ¤íŠ¸ë“¤
        'rec_scores': [...],        # í…ìŠ¤íŠ¸ ì¸ì‹ ì‹ ë¢°ë„
        'rec_polys': [...],         # í…ìŠ¤íŠ¸ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (ì •ê·œí™”ë¨)
        'dt_polys': [...],          # í…ìŠ¤íŠ¸ ê°ì§€ ì›ë³¸ ì¢Œí‘œ (ì‹¤ì œ ìœ„ì¹˜)
        'dt_scores': [...],         # í…ìŠ¤íŠ¸ ê°ì§€ ì‹ ë¢°ë„
        
        # === ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ===
        'input_path': 'path/to/image.jpg',  # ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
        'layout_result': {...},             # ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ (ë¬¸ì„œìš©)
        
        # === í…ìŠ¤íŠ¸ ë°©í–¥ ë° êµ¬ì¡° ì •ë³´ ===
        'ori_polys': [...],                 # ì›ë³¸ ë°©í–¥ ë‹¤ê°í˜•
        'ori_scores': [...],                # ë°©í–¥ ë¶„ì„ ì‹ ë¢°ë„
        'textline_orientation': [...],      # í…ìŠ¤íŠ¸ ë¼ì¸ ë°©í–¥ ì •ë³´
        'reading_order': [...],             # í…ìŠ¤íŠ¸ ì½ê¸° ìˆœì„œ
        
        # === ë¬¸ì„œ ì „ì²˜ë¦¬ ë©”íƒ€ë°ì´í„° ===
        'doc_orientation': 0,               # ë¬¸ì„œ ë°©í–¥ (0, 90, 180, 270ë„)
        'doc_orientation_score': 0.9876,    # ë¬¸ì„œ ë°©í–¥ ë¶„ì„ ì‹ ë¢°ë„
        'doc_unwarp_result': {...},         # ë¬¸ì„œ ì™œê³¡ ë³´ì • ê²°ê³¼
        'cropped_image': np.array([...]),   # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (ì˜µì…˜)
        
        # === ì²˜ë¦¬ ì‹œê°„ ì •ë³´ ===
        'det_time': 0.123,                  # í…ìŠ¤íŠ¸ ê°ì§€ ì†Œìš”ì‹œê°„ (ì´ˆ)
        'rec_time': 0.456,                  # í…ìŠ¤íŠ¸ ì¸ì‹ ì†Œìš”ì‹œê°„ (ì´ˆ)
        'total_time': 0.789,                # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
        'preprocess_time': 0.045,           # ì „ì²˜ë¦¬ ì‹œê°„
        'postprocess_time': 0.021,          # í›„ì²˜ë¦¬ ì‹œê°„
        
        # === ëª¨ë¸ ì •ë³´ ===
        'det_model_name': 'PP-OCRv5_server_det',        # ì‚¬ìš©ëœ ê°ì§€ ëª¨ë¸
        'rec_model_name': 'korean_PP-OCRv5_mobile_rec', # ì‚¬ìš©ëœ ì¸ì‹ ëª¨ë¸
        'cls_model_name': 'ch_ppocr_mobile_v2.0_cls',   # ë¶„ë¥˜ ëª¨ë¸ (ë°©í–¥)
        
        # === ì´ë¯¸ì§€ ì •ë³´ ===
        'image_shape': (1080, 1920, 3),     # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (H, W, C)
        'processed_shape': (960, 1280, 3),  # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í¬ê¸°
        'scale_factor': 0.888,              # ë¦¬ì‚¬ì´ì¦ˆ ë°°ìœ¨
        'pad_info': {'top': 0, 'bottom': 60, 'left': 0, 'right': 0}, # íŒ¨ë”© ì •ë³´
        
        # === í…ìŠ¤íŠ¸ ë¼ì¸ ì •ë³´ ===
        'line_count': 6,                    # ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜
        'char_count': 45,                   # ì´ ë¬¸ì ìˆ˜ (ì¶”ì •)
        'avg_confidence': 0.9524,           # í‰ê·  ì‹ ë¢°ë„
        'min_confidence': 0.8234,           # ìµœì†Œ ì‹ ë¢°ë„
        'max_confidence': 0.9999,           # ìµœëŒ€ ì‹ ë¢°ë„
        
        # === ì–¸ì–´/ìŠ¤í¬ë¦½íŠ¸ ì •ë³´ ===
        'detected_language': 'korean',      # ê°ì§€ëœ ì£¼ ì–¸ì–´
        'language_confidence': 0.9345,      # ì–¸ì–´ ê°ì§€ ì‹ ë¢°ë„
        'script_type': 'hangul',            # ë¬¸ì ì²´ê³„
        'mixed_script': False,              # í˜¼í•© ë¬¸ì ì—¬ë¶€
        
        # === í’ˆì§ˆ ì •ë³´ ===
        'image_quality': 'good',            # ì´ë¯¸ì§€ í’ˆì§ˆ ('excellent', 'good', 'fair', 'poor')
        'blur_score': 0.123,                # ë¸”ëŸ¬ ì •ë„ (ë‚®ì„ìˆ˜ë¡ ì„ ëª…)
        'brightness': 128.5,                # í‰ê·  ë°ê¸° (0-255)
        'contrast': 0.234,                  # ëŒ€ë¹„ë„
        'noise_level': 'low',               # ë…¸ì´ì¦ˆ ìˆ˜ì¤€
        
        # === í…ìŠ¤íŠ¸ ë ˆì´ì•„ì›ƒ ë¶„ì„ ===
        'text_regions': [...],              # í…ìŠ¤íŠ¸ ì˜ì—­ ë¶„ë¥˜
        'paragraph_info': [...],            # ë¬¸ë‹¨ ì •ë³´
        'column_layout': 'single',          # ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ ('single', 'multi')
        'text_density': 0.156,              # í…ìŠ¤íŠ¸ ë°€ë„
        
        # === ì²˜ë¦¬ ì˜µì…˜ ì •ë³´ ===
        'use_angle_cls': True,              # ê°ë„ ë¶„ë¥˜ ì‚¬ìš© ì—¬ë¶€
        'use_space_char': True,             # ê³µë°± ë¬¸ì ì‚¬ìš© ì—¬ë¶€
        'drop_score': 0.5,                  # ë‚®ì€ ì‹ ë¢°ë„ ì œê±° ì„ê³„ê°’
        'max_text_length': 25,              # ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´
        
        # === ì—ëŸ¬/ê²½ê³  ì •ë³´ ===
        'warnings': [],                     # ì²˜ë¦¬ ì¤‘ ê²½ê³ ì‚¬í•­
        'errors': [],                       # ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜
        'recovery_attempts': 0,             # ë³µêµ¬ ì‹œë„ íšŸìˆ˜
        
        # === ë””ë²„ê¹… ì •ë³´ ===
        'debug_info': {
            'memory_usage': '245MB',        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            'gpu_usage': '1.2GB',           # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (GPU ì‚¬ìš©ì‹œ)
            'batch_size': 1,                # ë°°ì¹˜ í¬ê¸°
            'thread_count': 4,              # ì‚¬ìš©ëœ ìŠ¤ë ˆë“œ ìˆ˜
        },
        
        # === ë²„ì „ ì •ë³´ ===
        'paddleocr_version': '3.2.0',       # PaddleOCR ë²„ì „
        'paddle_version': '2.6.0',          # Paddle í”„ë ˆì„ì›Œí¬ ë²„ì „
        'opencv_version': '4.8.1',          # OpenCV ë²„ì „
        
        # === ì¶”ê°€ ë¶„ì„ ê²°ê³¼ (ì„ íƒì ) ===
        'table_result': None,               # í…Œì´ë¸” ì¸ì‹ ê²°ê³¼ (í…Œì´ë¸” ëª¨ë“œì‹œ)
        'formula_result': None,             # ìˆ˜ì‹ ì¸ì‹ ê²°ê³¼ (ìˆ˜ì‹ ëª¨ë“œì‹œ)
        'structure_result': None,           # ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ê²°ê³¼
        'seal_result': None,                # ì¸ì¥/ë„ì¥ ì¸ì‹ ê²°ê³¼
    }
]
```

---

## ğŸ¯ í•µì‹¬ OCR ê²°ê³¼ í•„ë“œ

### 1. `rec_texts` (ì¸ì‹ëœ í…ìŠ¤íŠ¸)
```python
rec_texts = [
    "ë©”ì´í¬ì—…ì¡´",
    "MAKEUP ZONE",
    "ë“œë ˆìŠ¤ í”¼íŒ…ë£¸",
    "DRESS FITTING ROOM",
    "í¬í† ì¡´",
    "PHOTO ZONE"
]
```
- **íƒ€ì…**: `list[str]`
- **ì„¤ëª…**: ì‹¤ì œë¡œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´ë“¤
- **ìš©ë„**: ìµœì¢… OCR ê²°ê³¼, API ì‘ë‹µì— ì£¼ë¡œ ì‚¬ìš©

### 2. `rec_scores` (í…ìŠ¤íŠ¸ ì¸ì‹ ì‹ ë¢°ë„)
```python
rec_scores = [
    0.9995,   # "ë©”ì´í¬ì—…ì¡´"ì˜ ì‹ ë¢°ë„
    0.9999,   # "MAKEUP ZONE"ì˜ ì‹ ë¢°ë„
    0.9984,   # "ë“œë ˆìŠ¤ í”¼íŒ…ë£¸"ì˜ ì‹ ë¢°ë„
    0.9841,   # "DRESS FITTING ROOM"ì˜ ì‹ ë¢°ë„
    0.9998,   # "í¬í† ì¡´"ì˜ ì‹ ë¢°ë„
    0.9554    # "PHOTO ZONE"ì˜ ì‹ ë¢°ë„
]
```
- **íƒ€ì…**: `list[float]`
- **ë²”ìœ„**: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ)
- **ìš©ë„**: í’ˆì§ˆ ê²€ì¦, ë‚®ì€ ì‹ ë¢°ë„ ê²°ê³¼ í•„í„°ë§

### 3. `rec_polys` vs `dt_polys` (ì¢Œí‘œ ì •ë³´)

#### `rec_polys` (ì¸ì‹ìš© ì •ê·œí™”ëœ ì¢Œí‘œ)
```python
rec_polys = [
    np.array([[318, 238], [484, 238], [484, 268], [318, 268]]),  # ì •ì‚¬ê°í˜•ì— ê°€ê¹Œì›€
    np.array([[318, 297], [484, 297], [484, 327], [318, 327]]),
    # ...
]
```
- **íŠ¹ì§•**: í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìœ„í•´ ì •ê·œí™”ëœ ì¢Œí‘œ
- **í˜•íƒœ**: ì¼ë°˜ì ìœ¼ë¡œ ì •ì‚¬ê°í˜•ì— ê°€ê¹Œì›€
- **ìš©ë„**: ì¼ë°˜ì ì¸ ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ

#### `dt_polys` (ê°ì§€ ë‹¨ê³„ ì›ë³¸ ì¢Œí‘œ)
```python
dt_polys = [
    np.array([[318.2, 237.8], [484.1, 238.2], [483.9, 268.1], [317.8, 267.7]]),  # ì‹¤ì œ ê¸°ìš¸ì–´ì§„ í˜•íƒœ
    # ë” ì •í™•í•œ ì‹¤ì œ ìœ„ì¹˜ ë°˜ì˜
]
```
- **íŠ¹ì§•**: í…ìŠ¤íŠ¸ ê°ì§€ ë‹¨ê³„ì—ì„œ ì°¾ì€ ì‹¤ì œ ì¢Œí‘œ
- **í˜•íƒœ**: íšŒì „, ê¸°ìš¸ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ì‹¤ì œ í˜•íƒœ ë°˜ì˜
- **ìš©ë„**: ì •í™•í•œ ì‹œê°í™”, ë ˆì´ì•„ì›ƒ ë¶„ì„

### 4. ì¢Œí‘œ í˜•ì‹ ì„¤ëª…

```python
# ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ìˆœì„œ (ì‹œê³„ë°©í–¥)
poly = [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]

# ì‹œê°ì  í‘œí˜„:
# [0] ì¢Œìƒë‹¨ â”€â”€â”€â”€â”€â”€ [1] ìš°ìƒë‹¨
#  â”‚                    â”‚
#  â”‚       í…ìŠ¤íŠ¸        â”‚
#  â”‚                    â”‚
# [3] ì¢Œí•˜ë‹¨ â”€â”€â”€â”€â”€â”€ [2] ìš°í•˜ë‹¨
```

---

## â±ï¸ ì„±ëŠ¥ ë©”íƒ€ë°ì´í„°

### ì²˜ë¦¬ ì‹œê°„ ì •ë³´
```python
{
    'det_time': 0.123,          # í…ìŠ¤íŠ¸ ê°ì§€ ì‹œê°„
    'rec_time': 0.456,          # í…ìŠ¤íŠ¸ ì¸ì‹ ì‹œê°„
    'total_time': 0.789,        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
    'preprocess_time': 0.045,   # ì „ì²˜ë¦¬ ì‹œê°„
    'postprocess_time': 0.021   # í›„ì²˜ë¦¬ ì‹œê°„
}
```

### ëª¨ë¸ ì •ë³´
```python
{
    'det_model_name': 'PP-OCRv5_server_det',
    'rec_model_name': 'korean_PP-OCRv5_mobile_rec',
    'cls_model_name': 'ch_ppocr_mobile_v2.0_cls'
}
```

---

## ğŸ–¼ï¸ ì´ë¯¸ì§€ ê´€ë ¨ ë©”íƒ€ë°ì´í„°

### ì´ë¯¸ì§€ í¬ê¸° ë° ë³€í™˜ ì •ë³´
```python
{
    'image_shape': (1080, 1920, 3),     # ì›ë³¸ í¬ê¸° (H, W, C)
    'processed_shape': (960, 1280, 3),  # ì²˜ë¦¬ëœ í¬ê¸°
    'scale_factor': 0.888,              # ë¦¬ì‚¬ì´ì¦ˆ ë¹„ìœ¨
    'pad_info': {                       # íŒ¨ë”© ì •ë³´
        'top': 0, 'bottom': 60, 
        'left': 0, 'right': 0
    }
}
```

### í’ˆì§ˆ í‰ê°€ ì •ë³´
```python
{
    'image_quality': 'good',            # ì´ë¯¸ì§€ í’ˆì§ˆ ë“±ê¸‰
    'blur_score': 0.123,                # ë¸”ëŸ¬ ì •ë„ (ë‚®ì„ìˆ˜ë¡ ì„ ëª…)
    'brightness': 128.5,                # í‰ê·  ë°ê¸° (0-255)
    'contrast': 0.234,                  # ëŒ€ë¹„ë„
    'noise_level': 'low'                # ë…¸ì´ì¦ˆ ìˆ˜ì¤€
}
```

---

## ğŸ“Š í†µê³„ ì •ë³´

### í…ìŠ¤íŠ¸ í†µê³„
```python
{
    'line_count': 6,                    # ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜
    'char_count': 45,                   # ì´ ë¬¸ì ìˆ˜ (ì¶”ì •)
    'avg_confidence': 0.9524,           # í‰ê·  ì‹ ë¢°ë„
    'min_confidence': 0.8234,           # ìµœì†Œ ì‹ ë¢°ë„
    'max_confidence': 0.9999            # ìµœëŒ€ ì‹ ë¢°ë„
}
```

### ì–¸ì–´ ê°ì§€ ì •ë³´
```python
{
    'detected_language': 'korean',      # ê°ì§€ëœ ì£¼ ì–¸ì–´
    'language_confidence': 0.9345,     # ì–¸ì–´ ê°ì§€ ì‹ ë¢°ë„
    'script_type': 'hangul',            # ë¬¸ì ì²´ê³„
    'mixed_script': False               # í˜¼í•© ë¬¸ì ì—¬ë¶€
}
```

---

## ğŸ’» ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

### 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
```python
def extract_texts(result):
    """í…ìŠ¤íŠ¸ë§Œ ê°„ë‹¨íˆ ì¶”ì¶œ"""
    if result and len(result) > 0:
        page_result = result[0]
        return page_result.get('rec_texts', [])
    return []

# ì‚¬ìš©
result = ocr.run_ocr_from_path('image.jpg')
texts = extract_texts(result)
print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {texts}")
```

### 2. ì‹ ë¢°ë„ì™€ í•¨ê»˜ ì¶”ì¶œ
```python
def extract_text_with_confidence(result, min_confidence=0.8):
    """ì‹ ë¢°ë„ ì„ê³„ê°’ ì´ìƒì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
    if not result or len(result) == 0:
        return []
    
    page_result = result[0]
    texts = page_result.get('rec_texts', [])
    scores = page_result.get('rec_scores', [])
    
    filtered_texts = []
    for text, score in zip(texts, scores):
        if score >= min_confidence:
            filtered_texts.append((text, score))
    
    return filtered_texts

# ì‚¬ìš©
reliable_texts = extract_text_with_confidence(result, min_confidence=0.9)
for text, confidence in reliable_texts:
    print(f"'{text}' (ì‹ ë¢°ë„: {confidence:.4f})")
```

### 3. ì¢Œí‘œì™€ í•¨ê»˜ ì¶”ì¶œ
```python
def extract_text_with_positions(result, use_accurate_coords=True):
    """í…ìŠ¤íŠ¸ì™€ ìœ„ì¹˜ ì •ë³´ë¥¼ í•¨ê»˜ ì¶”ì¶œ"""
    if not result or len(result) == 0:
        return []
    
    page_result = result[0]
    texts = page_result.get('rec_texts', [])
    
    # ë” ì •í™•í•œ ì¢Œí‘œ ì‚¬ìš© ì—¬ë¶€ ì„ íƒ
    coord_key = 'dt_polys' if use_accurate_coords else 'rec_polys'
    polys = page_result.get(coord_key, [])
    scores = page_result.get('rec_scores', [])
    
    results = []
    for i in range(min(len(texts), len(polys), len(scores))):
        # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¢Œìƒë‹¨, ìš°í•˜ë‹¨ ì¢Œí‘œ ê³„ì‚°
        poly = polys[i]
        if isinstance(poly, np.ndarray) and poly.shape == (4, 2):
            x_coords = poly[:, 0]
            y_coords = poly[:, 1]
            bbox = {
                'left': int(min(x_coords)),
                'top': int(min(y_coords)),
                'right': int(max(x_coords)),
                'bottom': int(max(y_coords))
            }
        else:
            bbox = None
        
        results.append({
            'text': texts[i],
            'confidence': scores[i],
            'bbox': bbox,
            'polygon': poly.tolist() if isinstance(poly, np.ndarray) else poly
        })
    
    return results

# ì‚¬ìš©
text_positions = extract_text_with_positions(result)
for item in text_positions:
    print(f"í…ìŠ¤íŠ¸: '{item['text']}'")
    print(f"ìœ„ì¹˜: {item['bbox']}")
    print(f"ì‹ ë¢°ë„: {item['confidence']:.4f}")
    print("-" * 30)
```

### 4. ì„±ëŠ¥ ë¶„ì„
```python
def analyze_performance(result):
    """OCR ì„±ëŠ¥ ë¶„ì„"""
    if not result or len(result) == 0:
        return None
    
    page_result = result[0]
    
    # ì²˜ë¦¬ ì‹œê°„ ë¶„ì„
    times = {
        'total': page_result.get('total_time', 0),
        'detection': page_result.get('det_time', 0),
        'recognition': page_result.get('rec_time', 0),
        'preprocessing': page_result.get('preprocess_time', 0),
        'postprocessing': page_result.get('postprocess_time', 0)
    }
    
    # í’ˆì§ˆ ë¶„ì„
    scores = page_result.get('rec_scores', [])
    quality = {
        'text_count': len(page_result.get('rec_texts', [])),
        'avg_confidence': sum(scores) / len(scores) if scores else 0,
        'min_confidence': min(scores) if scores else 0,
        'max_confidence': max(scores) if scores else 0,
        'low_confidence_count': sum(1 for s in scores if s < 0.8)
    }
    
    # ëª¨ë¸ ì •ë³´
    models = {
        'detection': page_result.get('det_model_name', 'Unknown'),
        'recognition': page_result.get('rec_model_name', 'Unknown'),
        'version': page_result.get('paddleocr_version', 'Unknown')
    }
    
    return {
        'performance': times,
        'quality': quality,
        'models': models
    }

# ì‚¬ìš©
analysis = analyze_performance(result)
if analysis:
    print(f"â±ï¸  ì´ ì²˜ë¦¬ì‹œê°„: {analysis['performance']['total']:.3f}ì´ˆ")
    print(f"ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {analysis['quality']['avg_confidence']:.4f}")
    print(f"ğŸ“ ì¸ì‹ í…ìŠ¤íŠ¸ ìˆ˜: {analysis['quality']['text_count']}ê°œ")
    print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {analysis['models']['recognition']}")
```

---

