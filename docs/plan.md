# meow-chat 프로젝트 계획서: 냥닥터 - 고양이 건강검진 AI 상담 서비스

> **최종 업데이트**: 2025-12-30  
> **현재 Phase**: Phase 1 (MVP 기본 구조) 완료, Phase 2 준비 중  
> **개발 환경**: Python 3.12, Poetry 2.2.1, PyCharm 2025.3.1 (WSL Ubuntu 24.04)

---

## 0) 프로젝트 개요

### 비전
**고양이의 생애주기와 함께하는 AI 디지털 주치의** - 단순 QA가 아닌, 반려묘의 전 생애를 동행하며 건강을 관리하는 서비스

### 핵심 컨셉
- **주치의 페르소나**: 공감적이고 친근하되, 의학적 판단 시에는 전문적이고 침착한 톤
- **장기 기억**: 검사/진료/투약/행동 변화를 장기적으로 기억하고 추적
- **Peer Data 비교**: 동종 코호트 데이터와 비교하여 정밀한 건강 위치 분석

### 사용자 흐름 (MVP)
1. 사용자가 **카메라 촬영, 갤러리 선택, 또는 PDF 업로드**로 검진 결과 문서를 전송
2. **OCR 엔진** (PaddleOCR/Google Vision/EasyOCR)으로 텍스트 추출
3. **구조화 추출 파이프라인**으로 검사 항목/수치/단위를 정규화
4. 추출된 검진 데이터를 컨텍스트로 **LLM API** 호출하여 맞춤형 건강 상담 제공

### 핵심 가치
- 복잡한 검진 결과지를 **이해되는 언어**로 설명
- 수치 이상 여부 해석 및 **동종 코호트 대비 위치** 분석
- **생애주기 전체를 기억**하는 연속성 있는 케어
- 향후 상용 서비스로 확장 가능한 아키텍처

---

# meow-chat 단기 개발 로드맵

> **최종 업데이트**: 2025-12-30

## 진행 순서

1. **Step 1 — 스몰토크(기본)**
2. **Step 2 — 스몰토크 + 단기 메모리**
3. **Step 3 — 의도분석/분기(‘검사 분석 요청’ 감지 → 확인 메시지 출력)**
4. **Step 4 — OCR 화면(문서 업로드/촬영 → OCR → 결과 표시)**
5. **Step 5 — 검사 분석(문서 컨텍스트 기반 상담)**
6. **Step 6 — (게이트) 프레임워크 도입 여부 결정**

---

## Step 1 — 스몰토크(기본)

**목표:**
- 문서 없이도 간단한 대화(스몰톡)가 가능하다.

**완료 조건:**
- 문서 없이 3~5턴 대화가 안정적으로 동작
- LLM API 키 미설정/실패 시에도 앱이 죽지 않고(더미 모드 또는 명확한 오류 안내) UX가 유지됨
- 응답이 가능하면 **스트리밍 UI**로 표시된다(Provider 미지원 시 폴백)

### 상세 구현 계획

1) **UI: 채팅 화면**
- `st.chat_message()`로 유저/어시스턴트 메시지 렌더링
- 입력은 `st.chat_input()` 사용

2) **상태: 대화 히스토리(최소)**
- `st.session_state.messages = [{"role": "user"|"assistant", "content": str}]` 형태로 저장
- Step 1에서는 "대화 초기화" 버튼 없이도 되지만, 디버깅 편의를 위해 넣어도 OK

3) **호출: ChatService 재사용**
- UI(`app/`)는 로직(`src/`)을 직접 구현하지 않고, 기존 `ChatService`/LLM Provider를 호출
- (원칙) UI는 입력/출력/상태만 담당

4) **스트리밍 응답(중요)**
- OpenAI는 **최신 권장: Responses API 스트리밍**을 사용한다.
  - 목표: 응답이 생성되는 동안 사용자 화면에 점진적으로 텍스트가 표시되도록 한다.
- Streamlit UI 패턴
  - `placeholder = st.empty()`를 만들고, 스트리밍으로 수신한 텍스트 조각을 누적하면서 `placeholder.markdown()`으로 계속 갱신
- **중요: 스트리밍 중간에는 UI만 업데이트**
  - `st.session_state.messages`에는 스트리밍 중간 조각을 계속 저장하지 않는다(히스토리 오염/재실행 꼬임 방지)
- **중요: 스트리밍이 끝난 뒤에 최종 문자열을 저장**
  - 스트리밍이 완료되면 누적된 최종 문자열(assistant 답변 1개)을 `st.session_state.messages`에 저장한다.
- 폴백
  - Dummy/미지원 Provider에서는 논-스트리밍 응답을 한 번에 출력하되, 저장 방식(최종 1개 저장)은 동일하게 유지한다.

5) **에러 처리/UX**
- API 키 없음/타임아웃/레이트리밋 등 예외 발생 시:
  - 앱이 죽지 않게 try/except
  - 사용자에게 "연결 실패" 안내 문구 표시
  - 가능하면 더미 Provider로 유도(또는 더미 모드 안내)

6) **테스트/검증(빠른 스모크)**
- 더미 LLM Provider로 3~5턴 대화가 UI에서 끊기지 않는지 확인
- 스트리밍은 실제 Provider에서 확인(미지원이면 폴백 동작 확인)

---

## Step 2 — 스몰토크 + 단기 메모리

**목표:**
- 동일 세션에서 대화 맥락이 유지되어, 사용자가 대화가 끊기지 않는다고 느낀다.

**완료 조건:**
- 최근 N턴(예: 10~20) 대화 히스토리가 세션 단위로 유지됨
- "대화 초기화"(히스토리 리셋) 동작
- (선택) 토큰/컨텍스트가 과도해지지 않도록 N턴 제한이 적용됨

### 단기 메모리 구현 선택지(기록)

- **기본(권장, 최소 구현): Streamlit `st.session_state`**
  - 장점: 구현/디버깅이 가장 단순, Streamlit rerun 모델과 잘 맞음
  - 한계: 브라우저 세션을 벗어나면 유지되지 않음

- **LangChain Memory (학습/확장용)**
  - 예: `ConversationBufferMemory`, `ConversationBufferWindowMemory`
  - 장점: 향후 RAG/툴/워크플로우(LangChain/LangGraph)로 확장 시 연결이 자연스러움
  - 주의: Streamlit과 완전 자동 통합은 아니어서 상태 저장은 여전히 설계가 필요할 수 있음

- **LlamaIndex ChatStore / Memory (데이터 중심/RAG 지향)**
  - 장점: 문서/인덱싱 중심(RAG) 확장 시 대화 기록 구조화에 유리
  - 주의: Step 2 범위에선 오버스펙일 수 있음

- **Persistence/세션 저장(운영 지향): Redis/쿠키/서버 세션 스토어**
  - 장점: 새로고침/재접속에도 대화 유지 가능, 멀티 인스턴스 운영에 유리
  - 주의: 인프라/운영 복잡도 증가(초기 MVP에선 후순위)

---

## Step 3 — 의도분석/분기(‘검사 분석 요청’ 감지 → 확인 메시지 출력)

**목표:**
- 사용자의 입력(텍스트)에서 “건강검사 기록지 분석을 원한다”는 의도를 감지한다.
- 감지되면 실제 분석을 바로 돌리기 전에, 사용자에게 확인 메시지를 보여준다.

**구현 범위(단기 MVP):**
- 규칙 기반(키워드)으로 시작
  - 초기 키워드 최소 세트(예): `분석`, `해석`, `검사결과`, `건강검진`, `혈액검사`
- 분석 의도 감지 시 확인 메시지 출력
  - 예: `"분석의뢰 의도 확인!!!"`
  - (선택) `확인/취소`로 다음 행동을 명시적으로 선택
- (후속) 키워드 기반으로 누락/오탐이 커지면, **Step 5 이후 LLM 기반 의도분류로 확장**

**완료 조건:**
- 위 키워드 중 하나가 포함된 입력에서 확인 메시지가 뜬다.
- 키워드가 없는 입력에서는 기존 스몰토크가 유지된다.

---

## Step 4 — OCR 화면(문서 업로드/촬영 → OCR → 결과 표시)

**목표:**
- 사용자가 이미지 업로드/카메라 촬영을 하면 OCR 결과가 화면에 표시된다.

**완료 조건:**
- 업로드/촬영 → OCR → 결과 표시가 안정적으로 동작
- 실패 시 재시도/가이드가 제공됨(흐림/해상도/잘림 등)

---

## Step 5 — 검사 분석(문서 컨텍스트 기반 상담)

**목표:**
- 문서가 업로드된 상태에서 사용자가 "분석/해석"을 요청하면,
  OCR/구조화 결과를 컨텍스트로 상담 응답을 생성한다.

**완료 조건:**
- 최소 1~2개의 실제 결과지에서 분석 요청 시 문서 컨텍스트가 답변에 반영됨
- 안전장치 포함: 진단/처방 금지, 응급 시 병원 권고, 불확실성 명시

---

## Step 6 — (게이트) 프레임워크 도입 여부 결정

**선행 조건:**
- Step 1~5 완료 조건 충족

**결정 질문:**
- Streamlit ↔ API 분리 여부
- 비동기 처리(큐/백그라운드 작업) 필요 여부
- Phase 2에서 RAG(출처 제시 포함) 필요 여부

**참고 문서:**
- `docs/LLM_FRAMEWORK_GUIDE.md`
