## 개인화 컨텍스트 개요
- 정의: 사용자별 중요 안전/정책 정보를 매 대화 프롬프트에 항상 포함시키는 “핵심 사실” 블록입니다.
- 포함 범주: 프로필(이름/성별/중성화/품종/연령/몸무게·체중·킬로그램 등), 알레르기, 만성질환, 금기/주의, 복용 약, 식단 등 CORE_QUERIES에 포함된 키워드와 연결된 메모리.
- 주요 특징:
  - LLM 요약 없이 “검색 → 정제/중복 제거 → 토큰 제한”만 적용해 원문 충실도와 투명성을 유지
  - 중복 제거 강화: 불릿/공백/접두 라벨(예: “사실:”), 번호 매김(예: “1.”/“2)”), 표현 차이(예: “고양이 이름은 X이다/입니다/임” → “고양이 이름은 X”, “사용자의 집 ” 접두어) 등을 정규화해 의미 중복을 줄이고 첫 원문만 유지
  - 반영 타이밍: 저장 이벤트 발생 시 다음 프레임에 1회 자동 새로고침(이벤트+TTL 캐시). 쓰기 직후 즉시 읽기를 피함
- 결과물 전달: `build_pinned_core_facts_block`의 결과를 `frontend/app.py`에서 system 메시지에 포함해 모델 프롬프트로 전달합니다.

> 한 줄 요약(TL;DR): “항상 필요한 내 고양이 핵심 정보”가 매 질문마다 자동으로 붙습니다. 안전하고 일관된 답변을 보장합니다.

## 생성 파이프라인
1. **진입점**: `core_facts.build_pinned_core_facts_block(...)`  
   - 호출 위치: `frontend/app.py`에서 채팅 요청 직전에 개인화 슬롯을 구성할 때 사용합니다.
2. **키워드 시퀀스 선택**
  - `CORE_QUERIES` 상수(프로필/알레르기/만성/금기/약/식단 등)에서 앞쪽 `max_queries`개를 선택합니다.
   - `max_queries`는 UI 슬라이더 “개인화 컨텍스트 검색 강도(질의 수)”(`pinned_max_queries`) 값으로 주입됩니다.
3. **다중 검색 실행**  
   - 각 키워드마다 `retrieve_memories(...)`를 호출해 Top-K(현재 6개) 결과를 얻습니다.  
   - 내부 호출 순서:  
     `build_pinned_core_facts_block → memory_retriever.retrieve_memories → memory_store.get_memory_store().retrieve`
  - 필터가 비어 있으면 `None`으로 전달하여 백엔드 드라이버의 빈 필터 처리 예외를 방지합니다.
4. **벡터 검색 스택**
  - 구현: `frontend/services/memory/memory_store.py`의 `ChromaMemoryStore`
  - 저장소: `data/vectors` 디렉터리 하위, 컬렉션명 `meow_memory_{user_id}`
  - 검색 방식: Chroma `similarity_search` + `OpenAIEmbeddings`
  - 연결 방식: 프론트엔드에서 로컬 Chroma에 직접 연결(MCP 우회)
5. **정제 및 중복 제거**
  - `_normalize_for_compare`로 불릿/공백/접두 라벨(“사실:”, “프로필:”), 번호 매김(“1.”/“2)”), 표현 차이(“고양이 이름은 X이다/입니다/임” → “고양이 이름은 X”, “사용자의 집 ” 제거)를 정규화하여 의미가 같은 항목은 하나만 남깁니다.
  - 원문 표시는 그대로 유지(정규화는 비교에만 사용).
  - 최대 약 20개 항목을 bullet 텍스트로 묶은 뒤 토큰 규칙에서 추가 트리밍합니다.
  - 고정 블록 성격상 `todo(해야 할 일)` 유형은 제외합니다(안전/프로필 중심 유지).
6. **토큰 예산 적용**  
   - `trim_memory_block` 유틸을 통해 전체 토큰(`max_tokens`)과 항목별 토큰(`per_item_cap`) 제한을 동시에 적용합니다.  
   - 슬라이더에서 설정한 “개인화 컨텍스트 토큰”과 “항목당 토큰 상한”이 그대로 반영됩니다.
7. **최종 블록 반환 및 주입**
  - 반환값은 세션 상태에 저장하지 않고, 각 턴 실행 시 즉시 system 메시지에 포함됩니다.
  - 저장 직후 UI 자동 새로고침으로 미리보기가 곧바로 갱신됩니다.

## 추출·저장 정책(요약)
- 자동 추출: 대화 흐름마다 LLM이 후보 항목을 직접 추출합니다(휴리스틱/정규식 사용 안 함). 각 항목은 `source="llm"`으로 태깅됩니다.
- 저장 시 중복 방지: 의미 유사도(문장 유사도 ≥ 0.92 등)를 이용해 기존과 중복인 경우 저장을 건너뜁니다.
- 메타데이터: 항목에는 고유 id, 타입(type), 중요도(importance), 타임스탬프 등이 포함됩니다.
- 추출 시점: 실험적 플래그로 `pre`/`post`를 지원합니다. 기본값은 `pre`(권장)이며, 사용자 발화 직후 백그라운드로 추출/저장을 시작합니다. 같은 턴 프롬프트에는 주입하지 않고, 다음 프레임/다음 턴부터 반영됩니다.
- 반영 타이밍: 저장 이벤트 후 다음 프레임에 1회 자동 새로고침되며, 미리보기는 이벤트+TTL 캐시를 사용해 과도한 재계산을 피합니다.

## 검색 강도의 의미
- **슬라이더 이름**: “개인화 컨텍스트 검색 강도(질의 수)” (`pinned_max_queries`)
- **동작**: CORE_QUERIES에서 앞쪽 n개 키워드를 선택해 n회 검색을 반복합니다. 각 검색은 Top-6 문서를 가져옵니다.
- **효과**
  - n↑ → 더 다양한 범주의 메모리를 회수(Recall 상승)하지만 검색 호출 수만큼 지연·비용이 늘어납니다.
  - n↓ → 응답이 빨라지나 특정 범주가 빠질 수 있습니다.
- **튜닝 팁**
  - 미리보기에서 특정 카테고리가 비어 있으면 n을 1~2 올립니다.
  - 속도가 중요한 세션은 n을 줄이고, 장기 관리형 어시스턴트는 n을 6 이상 유지합니다.
- **Top-K 조정**: 현재 `retrieve_memories(..., k=6)`로 고정되어 있으며, 필요 시 별도 슬라이더로 분리해 노출할 수 있습니다.

## 프론트엔드 설정 버블 요약 (frontend/app.py)
- **항목당 토큰 상한 (`memory_item_token_cap`)**  
  - 개인화 컨텍스트 각 항목에 허용되는 최대 길이입니다.  
  - 낮음: 더 많은 항목을 담을 수 있으나 문장이 중간에 잘릴 수 있음.  
  - 높음: 각 항목이 자세하지만 전체 블록이 길어짐. 권장 범위 120~200.
- **개인화 컨텍스트 토큰 (`pinned_token_budget`)**  
  - 고정 블록 전체 길이 상한입니다. 초과 시 중요도/최근성을 기준으로 항목 일부가 생략됩니다.  
  - 높일수록 품질은 좋아지지만 모델 호출 비용과 지연이 증가합니다. 권장 300~600.
- **개인화 컨텍스트 검색 강도 (`pinned_max_queries`)**  
  - 키워드 기반 검색 횟수를 조절합니다. 값이 크면 Recall↑, 비용·지연↑. 권장 4~8.
- **미리보기 패널**  
  - 개인화 컨텍스트 미리보기는 저장 이벤트와 TTL을 함께 사용해 갱신됩니다. 쓰기 직후에는 최소 1프레임 지연 후 재계산합니다.
  - 출력창 이중 표시는 제거되어 단일 텍스트 영역만 유지됩니다.
  - 실험적 옵션으로 미리보기 모드(TTL/즉시/버튼)와 추출 시점(pre/post)을 조정할 수 있습니다.

> 참고: 중요도는 저장 단계 정책으로 관리되며, 개인화 블록은 “항상 필요한 정보 우선” 원칙에 맞게 트리밍됩니다.

## 운용 및 활용 가이드
- **무엇을 개인화 컨텍스트로 삼나?**  
  - 장기 메모리 중 안전·정책·건강과 직결되는 필수 정보. 저장 시 메타 정보(owner_id, cat_id 등)가 있는 경우 필터링 옵션을 통해 특정 개체만 추출할 수 있습니다.
- **언제 업데이트되나?**
  - 사용자가 새로운 정보를 제공하면 `write_memories`가 장기 저장소에 upsert하고, 다음 프레임에 미리보기가 자동 새로고침되어 반영됩니다(이벤트+TTL 캐시).
- **품질 점검 루틴**  
  - 미리보기 패널에서 누락된 항목을 확인하고, 검색 강도 및 토큰 한도를 조정합니다.  
  - `data/vectors/meow_memory_{user_id}`를 점검해 임베딩이 정상 저장됐는지 확인할 수 있습니다.
- **확장 포인트**  
  - CORE_QUERIES에 새 키워드를 추가해 신규 카테고리를 포함할 수 있습니다.  
  - 중요도 스코어를 메타로 저장해 토큰 트리밍 시 가중치를 적용하는 방향으로 확장 가능합니다.
- **주의 사항**  
  - 현재는 요약 압축 없이 원문을 사용하므로 민감 정보가 그대로 노출됩니다. 저장 단계에서 비식별 처리를 선행하세요.  
  - OpenAIEmbeddings 사용으로 외부 API 키가 필요하며, 네트워크 지연이 검색 속도에 영향을 줄 수 있습니다.

## 특징(Why it matters)
- 안전: 알레르기·금기 등 치명적 정보를 놓치지 않도록 항상 프롬프트에 포함합니다.
- 품질: LLM 요약 없이 원문을 그대로 활용해 왜 그런 답을 했는지 투명합니다.
- 일관성: 세션이 길어져도 핵심 맥락이 유지되어 답변 품질이 흔들리지 않습니다.
- 즉시성: 새 정보 입력 후 다음 프레임에 미리보기/응답 품질에 반영됩니다(저장 직후 즉시 읽기 대신 1프레임 지연).
- 사용자 신뢰: 휴리스틱 없이 LLM이 직접 추출·판단해 편향과 오류를 줄였습니다.

## 기술 메모(참고)
- 저장소: 프로젝트 루트 `data/vectors` 경로에 사용자별 컬렉션으로 저장됩니다.
- 백엔드: Chroma(Vector DB). 현재 환경에서는 레거시 경로를 안전하게 활용하며, 폐기 경고는 내부 억제 처리되어 사용자 콘솔 노이즈를 최소화합니다.
- 실행 환경: Streamlit는 `python -m streamlit run` 방식으로 실행하여 환경 간 충돌을 피하고, 테스트 스크립트는 Streamlit 컨텍스트 없이도 동작하도록 분리되어 있습니다.

## 최근 변경 요약 (2025-11)
- 추출 시점 기본값을 `post` → `pre`로 전환: 사용자 발화 직후 백그라운드 추출/저장, 같은 턴 주입 없이 다음 프레임/다음 턴부터 반영.
- CORE_QUERIES에 체중 관련 키워드 강화: “몸무게/체중/킬로그램/weight/kg”.
- 중복 제거 정규화 강화: 번호 매김 제거, “고양이 이름은 X이다/입니다/임 → 고양이 이름은 X”, “사용자의 집 ” 접두어 제거.
- 고정 블록에서 `todo(해야 할 일)` 유형 제외: 안전/프로필 중심 유지.
- 미리보기 재계산 정책 개선: 이벤트+TTL 캐시, 저장 직후 1프레임 지연, 과도한 재계산/저장소 경합 감소.
- UI 정리: 개인화 컨텍스트 출력창 이중 표기 제거(단일 텍스트 영역 유지).
