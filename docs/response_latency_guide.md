# Meow Chat 응답 지연 가이드

본 문서는 현재 응답이 느린 주요 원인과, 응답 품질을 유지하면서 속도를 개선하는 안전한 방안을 정리합니다. 실제 코드 변경 없이 원인–대응 전략을 한눈에 볼 수 있도록 구성했습니다.

## 파이프라인 한눈에 보기

- ReAct 루프: 계획(plan) → 실행(execute: MCP 도구 호출) → 자가평가(self-eval) → 합성(compose)
- 컨텍스트: pinned_core_facts(개인화), 도구 카탈로그, 관찰 요약(brief_obs), 초안(final_msg)
- 최종 출력: 스몰토크/도구 미사용이면 finish(message) 그대로, 도구 사용 시 관찰을 반영해 재작성

## 왜 느린가(원인 분석)

1) 첫 토큰까지 대기(TTFB)가 길어짐
- 매 턴 ReAct의 여러 단계가 선행되어야 하며, 도구 의존형 질문(검색/RAG, 랩 분석 등)일수록 지연 누적

2) LLM 입력 토큰 과다
- pinned_core_facts, 도구 카탈로그(이름+설명), 관찰 요약, 초안 텍스트가 모두 합쳐져 컨텍스트가 커짐 → 모델 처리 시간 증가

3) MCP 도구 호출 지연
- 랩 추출은 내부에서 OCR→정규화→LLM 구조화가 연쇄적으로 일어나 고비용/고지연
- 벡터 검색/임베딩 및 외부 API 호출은 네트워크 왕복 시간이 누적

4) 도구 카탈로그 조회/프롬프트 오버헤드
- 매 턴 get_tools()로 도구 목록을 조회하고, 플래너 입력에 길게 포함 → 프롬프트와 호출 비용 모두 증가

5) 보조 오버헤드
- pinned_core_facts를 턴마다 새로 생성
- 오케스트레이터 로그의 잦은 렌더링(체감에 소폭 영향)

참고: 과거 품질 저하는 “allowed_tools를 빈 리스트로 전달”과 “플래너 경량 모델 분리”로 도구 사용이 막히거나 조기 종료가 늘어난 것이 주된 원인이었고, 현재는 롤백되어 품질 정상입니다.

## 품질 유지 전제의 개선 방안(안전 순)

아래 항목은 응답 품질 저하 없이 지연을 낮출 수 있는 방안입니다. “빠른 체감 개선”을 앞쪽에 배치했습니다.

1) LLM 토큰/호출 줄이기
- pinned_core_facts 재사용: 새 메모리가 저장된 턴 이후에만 재생성, 그 외에는 세션 캐시 텍스트 재사용
- brief_obs 축소: 최근 5개→2~3개(각 200자→120~160자)
- 도구 카탈로그 축약: Top-N(예: 8~12개)만 제공하거나, 핵심 도구 우선 + 나머지 생략

2) 오케스트레이션 반복/흐름 최적화
- ReAct 반복 기본 3회 권장(무거운 케이스 2~3회 제한)
- finish(message) 즉시 출력 규칙 유지로 스몰토크/간단 질의 TTFB 최소화

3) MCP/도구 호출 최적화
- 랩 추출 결과 캐싱: 이미지 파일 해시(MD5/SHA) 기준으로 JSON 결과 캐시 → 재분석 시 즉시 히트
- OCR 입력 리사이즈 표준화: 320~640px 폭 등 일관 옵션으로 처리 시간 단축(품질 저하 최소)
- 벡터 검색 캐시/프리페치: 상위-K 결과를 짧은 TTL로 캐시하거나 최근 주제 기반 사전 로드

4) 도구 카탈로그/연결 관리
- get_tools() TTL 캐싱(예: 30~60초)으로 매 턴 조회 비용 절감
- MCP 클라이언트/연결 세션 재사용으로 초기화/핸드셰이크 비용 절감

5) 모델/프롬프트 경량화(품질 유지)
- 합성 프롬프트에서 중복/장문 지침을 간소화(핵심 규칙만 유지)
- 플래너/셀프평가는 메인 모델 그대로 사용(경량 모델 분리는 품질 리스크 큼)

6) 체감 속도 개선(UX)
- “빠른 1차 요약 → 정교한 확정본” 2단계 스트리밍: 플래너 직후 가능한 1~2문장을 먼저 스트리밍해 TTFB를 단축하고, 도구 관찰 후 본문을 이어서 출력

## 우선순위 로드맵(권장)

- 1단계(빠른 적용)
  - pinned_core_facts 세션 캐시 재사용(재계산 조건부)
  - 도구 카탈로그 TTL 캐싱 + 플래너 프롬프트 Top-N 축약
  - brief_obs 2~3개로 축소, 초안·요약 길이 제한
  - ReAct 반복 기본 3회 유지(이미 슬라이더 제공)

- 2단계(중간 난이도)
  - 랩 추출 캐시(이미지 해시 키) + OCR 표준 리사이즈
  - 벡터 검색 캐시/프리페치
  - MCP 연결 재사용 강화

- 3단계(UX 보강)
  - 2단계 스트리밍(빠른 초안 → 확정본)

## 모니터링 체크리스트

- 메트릭
  - TTFB(ms), 전체 응답 시간(ms)
  - ReAct 반복 횟수, 사용된 도구 개수 및 각 호출 시간
  - LLM 요청당 입력/출력 토큰 수
  - 캐시 히트율(랩 추출/벡터 검색/도구 목록)
- 관찰 포인트
  - finish(message)로 끝난 비율(스몰토크/간단 질의의 건전성 지표)
  - 품질 회귀 여부(정답률, 사용자 수정율, 재질문율)

## 적용 포인트(코드 맵)

- 오케스트레이션/스트리밍
  - `frontend/services/streaming.py`: 최종 합성, 스몰토크 폴백, brief_obs/프롬프트 길이 조절, 도구 카탈로그 제공량 축약
  - `frontend/services/orchestrator.py`: 플래너 프롬프트, get_tools() 결과 반영, ReAct 반복 횟수
  - `frontend/app.py`: pinned_core_facts 생성/재사용, UI 로그 업데이트 빈도 관리
- 랩 추출/캐시/리사이즈
  - `backend/app/services/analysis/lab_table_extractor.py`: 모델 선택/파이프라인 구성
  - 캐시 레이어(신규): 이미지 해시→JSON 결과 저장/로드
  - OCR 전처리(리사이즈) 옵션 표준화

## 주의(회피할 최적화)

- allowed_tools를 빈 리스트로 전달하여 플래너를 무력화하는 최적화: 품질 하락 위험 높음
- 플래너/셀프평가를 검증 없이 경량 모델로 분리: 조기 종료/오판 증가로 품질 저하

---

필요 시 위 로드맵에 따라 단계적으로 적용하고, 각 단계 뒤에 모니터링 지표로 회귀 여부를 확인하세요. 캐싱·프롬프트 경량화·반복 회수 조정만으로도 체감 속도는 크게 개선될 가능성이 높습니다.
