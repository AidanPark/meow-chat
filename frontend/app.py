"""
Meow Chat í”„ë¡ íŠ¸ì—”ë“œ
1) LangGraph ê¸°ë°˜ ì—ì´ì „íŠ¸ë¡œ MCP ì„œë²„ì˜ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³ , ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ UIì— ì „ë‹¬í•œë‹¤.
2) ì‚¬ìš©ì ëŒ€í™”ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ê³ , ì¼ì • í„´ì´ ë„˜ìœ¼ë©´ LLM ìš”ì•½ìœ¼ë¡œ ì••ì¶•í•œë‹¤.
3) ì¥ê¸° ë©”ëª¨ë¦¬(MCP + Chroma), ì´ë¯¸ì§€ ì—…ë¡œë“œ, í”„ë¡œí•„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë“± ë¶€ê°€ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
"""

import os
import sys
import asyncio
import time
from datetime import datetime
import io
import json
import streamlit as st
from typing import Any

# MCP ì„œë²„ì™€ ì—°ê²°í•˜ëŠ” LangChain ì–´ëŒ‘í„°
from langchain_mcp_adapters.client import MultiServerMCPClient


from dotenv import load_dotenv, find_dotenv
from ruamel.yaml import YAML

# ë™ì¼ ê²½ë¡œì˜ ëª¨ë“ˆì„ ìš°ì„  ì„í¬íŠ¸í•  ìˆ˜ ìˆë„ë¡ sys.path ì •ë¹„
CURRENT_DIR = os.path.dirname(__file__)
if CURRENT_DIR and CURRENT_DIR not in sys.path:
    sys.path.insert(0, CURRENT_DIR)

UPLOAD_ROOT = os.path.join(CURRENT_DIR, "uploads")

# í”„ë¡ íŠ¸ì—”ë“œ ì„œë¹„ìŠ¤/ì„¤ì • ëª¨ë“ˆ
from config.loader import load_mcp_server_config
from config.defaults import RECENT_TURN_WINDOW, SUMMARIZE_TRIGGER_TURNS, RETRIEVAL_TOP_K
from services.streaming import stream_agent_generator
from services.context_builder import build_context_messages
from services.summarizer import maybe_update_summary
from ui.styles import inject_core_css
from services.memory.memory_retriever import retrieve_memories, write_memories
from services.memory.memory_writer import extract_candidates
from services.memory.memory_utils import trim_memory_block
from services.memory.core_facts import build_pinned_core_facts_block
from services.memory.memory_search import search_memories, MEMORY_TYPES
from services.orchestrator import run_auto_plan, run_react_rag

# ---------------------------------------------------------------------------
# ì „ì²´ UI íë¦„ ì•ˆë‚´
# 1) ì „ì—­ ì„¤ì •: .envì™€ MCP ì„œë²„ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¤ê³ , Streamlit í˜ì´ì§€ ì˜µì…˜ê³¼ CSSë¥¼ ì ìš©í•œë‹¤.
# 2) ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: ë©”ì‹œì§€, ìš”ì•½, ë©”ëª¨ë¦¬, ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë“± ëŒ€í™” ìœ ì§€ì— í•„ìš”í•œ ìƒíƒœ ê°’ì„ ì¤€ë¹„í•œë‹¤.
# 3) Sidebar:
#    - í”„ë¡œí•„ ì „í™˜ ë° ìƒˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
#    - ì´ë¯¸ì§€ ì—…ë¡œë“œ ê´€ë¦¬
#    - ì¥ê¸° ë©”ëª¨ë¦¬/í•µì‹¬ ì‚¬ì‹¤ ê´€ë ¨ ìŠ¬ë¼ì´ë”ì™€ ìŠ¤ìœ„ì¹˜
#    - í™˜ê²½ ì§„ë‹¨(í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì—¬ë¶€), ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬
# 4) ë©”ì¸ ì˜ì—­:
#    - ê³¼ê±° ë©”ì‹œì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ë Œë”ë§
#    - ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìœ¼ë©´ ë©”ì‹œì§€ ëª©ë¡ì— ì¶”ê°€í•˜ê³ , LangGraph ì—ì´ì „íŠ¸ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
#    - ì‹¤í–‰ ë„ì¤‘ stream_agent_generator ê°€ í† í°ì„ streaming í•˜ë©°, ì™„ë£Œ í›„ ìš”ì•½ ë° ë©”ëª¨ë¦¬ ì €ì¥ ë¡œì§ ìˆ˜í–‰
# 5) ëŒ€í™” ì¢…ë£Œ í›„ UIëŠ” ë§ˆì§€ë§‰ ì‘ë‹µ, ì‚¬ìš©ëœ ë„êµ¬, ìš”ì•½ ê²°ê³¼, ë©”ëª¨ë¦¬ ê¸°ë¡ ë“±ì„ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬í•œë‹¤.
# ---------------------------------------------------------------------------

# ì‹¤í–‰ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(find_dotenv())

# ìŠ¤íŠ¸ë¦¼ë¦¿ í˜ì´ì§€ ì†ì„± êµ¬ì„±
st.set_page_config(page_title="Meow Chat", page_icon="ğŸ±", layout="wide")

# í•µì‹¬ CSS ì‚½ì…
inject_core_css()

# MCP ì„œë²„ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
SERVERS = load_mcp_server_config()

# ì„¸ì…˜ ìƒíƒœ ê¸°ë³¸ê°’ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "uploaded_images" not in st.session_state:
    st.session_state.uploaded_images = []
if "tool_history" not in st.session_state:
    st.session_state.tool_history = []
if "previous_uploaded_count" not in st.session_state:
    st.session_state.previous_uploaded_count = 0
if "user_id" not in st.session_state:
    st.session_state.user_id = os.getenv("USER", "default")
if "use_memory" not in st.session_state:
    st.session_state.use_memory = True
if "retrieval_top_k" not in st.session_state:
    st.session_state.retrieval_top_k = RETRIEVAL_TOP_K
if "recent_turn_window" not in st.session_state:
    st.session_state.recent_turn_window = RECENT_TURN_WINDOW
if "summarize_trigger_turns" not in st.session_state:
    st.session_state.summarize_trigger_turns = SUMMARIZE_TRIGGER_TURNS
if "last_retrieved_memories" not in st.session_state:
    st.session_state.last_retrieved_memories = []
if "last_saved_memory_ids" not in st.session_state:
    st.session_state.last_saved_memory_ids = []
if "memory_token_budget" not in st.session_state:
    st.session_state.memory_token_budget = 1200
if "memory_item_token_cap" not in st.session_state:
    st.session_state.memory_item_token_cap = 150
if "pinned_core_enabled" not in st.session_state:
    st.session_state.pinned_core_enabled = True
if "pinned_token_budget" not in st.session_state:
    st.session_state.pinned_token_budget = 400
if "manual_injected_memories" not in st.session_state:
    st.session_state.manual_injected_memories = []
if "profiles" not in st.session_state:
    st.session_state.profiles = [st.session_state.user_id or "default"]
if "active_profile" not in st.session_state:
    st.session_state.active_profile = st.session_state.user_id
if "_prev_active_profile" not in st.session_state:
    st.session_state._prev_active_profile = st.session_state.active_profile
if "auto_max_steps" not in st.session_state:
    st.session_state.auto_max_steps = 8
if "auto_debug_view" not in st.session_state:
    st.session_state.auto_debug_view = False
if "last_auto_plan_state" not in st.session_state:
    st.session_state.last_auto_plan_state = None
if "auto_mode" not in st.session_state:
    st.session_state.auto_mode = "Planner"  # or "ReAct"
if "auto_allowed_tools" not in st.session_state:
    st.session_state.auto_allowed_tools = []
if "react_max_iters" not in st.session_state:
    st.session_state.react_max_iters = 4
if "owner_id" not in st.session_state:
    st.session_state.owner_id = ""
if "cat_id" not in st.session_state:
    st.session_state.cat_id = ""
if "pinned_preview" not in st.session_state:
    st.session_state.pinned_preview = None


@st.cache_resource
def get_model_and_client():
    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    # LangChain ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œ ë²„ì „ ë¶ˆì¼ì¹˜ê°€ ì¦ìœ¼ë¯€ë¡œ, ì‹¤íŒ¨í•˜ë©´ ë²„ì „ ì •ë³´ë¥¼ í•¨ê»˜ ì•ˆë‚´í•œë‹¤.
    try:
        from langchain_openai import ChatOpenAI  # type: ignore
    except Exception as e:
        import importlib.metadata as _md
        def _ver(pkg: str) -> str:
            try:
                return _md.version(pkg)
            except Exception:
                return "not-installed"

        lc = _ver("langchain")
        lcc = _ver("langchain-core")
        lco = _ver("langchain-openai")
        lg = _ver("langgraph")
        st.error(
            "LangChain/OpenAI ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜ë¡œ ì•±ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "ì›ì¸: ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ë²„ì „ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.\n\n"
            f"ì„¤ì¹˜ëœ ë²„ì „:\n- langchain={lc}\n- langchain-core={lcc}\n- langchain-openai={lco}\n- langgraph={lg}\n\n"
            "ê¶Œì¥ í•´ê²°ì±…:\n"
            "- í”„ë¡œì íŠ¸ì˜ ê³ ì • ë²„ì „ì„ ë§ì¶”ì„¸ìš” (backend/requirements.txt ì°¸ê³ ).\n"
            "- ìµœì†Œ ì¡°í•© ì˜ˆì‹œ: langchain==1.0.3, langchain-openai==1.0.1, langgraph==1.0.2\n"
            "- ë˜ëŠ” ëª¨ë“  ê´€ë ¨ íŒ¨í‚¤ì§€ ìµœì‹  ë²„ì „ìœ¼ë¡œ ë™ê¸° ì—…ê·¸ë ˆì´ë“œ\n"
            "\nìì„¸í•œ ì˜¤ë¥˜: " + str(e)
        )
        st.stop()

    model = ChatOpenAI(model="gpt-4.1-mini", streaming=True)
    client = MultiServerMCPClient(SERVERS)  # type: ignore[arg-type]
    return model, client


def run_ocr_on_images(paths: list[str], client) -> list[tuple[str, str]]:
    if not paths:
        return []

    async def _run():
        tools = await client.get_tools()
        ocr_tool = None
        for tool in tools:
            if getattr(tool, "name", "") == "ocr_image_file":
                ocr_tool = tool
                break
        if ocr_tool is None:
            return []

        try:
            res = await ocr_tool.ainvoke({"paths": paths, "do_preprocess": True})
        except Exception as exc:
            err = json.dumps({"error": str(exc)}, ensure_ascii=False)
            return [(path, err) for path in paths]

        results = []
        if isinstance(res, list):
            for idx, item in enumerate(res):
                path = paths[idx] if idx < len(paths) else ""
                raw = ""
                if isinstance(item, dict):
                    path = str(item.get("path", path))
                    if item.get("ocr_result"):
                        raw = str(item.get("ocr_result"))
                    elif item.get("error"):
                        raw = json.dumps({"error": str(item.get("error"))}, ensure_ascii=False)
                elif isinstance(item, str):
                    raw = item
                if not raw:
                    raw = json.dumps({"error": "empty ocr result"}, ensure_ascii=False)
                results.append((path, raw))
        else:
            txt = str(res)
            for path in paths:
                results.append((path, txt))
        return results

    try:
        return asyncio.run(_run())
    except RuntimeError:
        # ì´ë¯¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ” í™˜ê²½(Streamlit)ì—ì„œ ì‹¤í–‰ë  ê°€ëŠ¥ì„± ëŒ€ë¹„
        loop = asyncio.new_event_loop()
        try:
            return loop.run_until_complete(_run())
        finally:
            loop.close()


with st.sidebar:
    st.title("ğŸ± Meow Chat")
    st.subheader("ğŸ‘¤ í”„ë¡œí•„ / ë„¤ì„ìŠ¤í˜ì´ìŠ¤")
    active = st.selectbox(
        "í™œì„± í”„ë¡œí•„",
        options=st.session_state.profiles,
        index=st.session_state.profiles.index(st.session_state.active_profile) if st.session_state.active_profile in st.session_state.profiles else 0,
        key="profile_select",
    )
    with st.container():
        new_prof = st.text_input("ìƒˆ í”„ë¡œí•„ ì´ë¦„", key="new_profile_name")
        if st.button("í”„ë¡œí•„ ì¶”ê°€", use_container_width=True, key="btn_add_profile"):
            name = (new_prof or "").strip()
            if name and name not in st.session_state.profiles:
                st.session_state.profiles.append(name)
                st.session_state.active_profile = name
                st.success(f"í”„ë¡œí•„ '{name}' ì¶”ê°€ ë° í™œì„±í™”")
            elif name in st.session_state.profiles:
                st.info("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í”„ë¡œí•„ì…ë‹ˆë‹¤.")
            else:
                st.warning("í”„ë¡œí•„ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")
    if active != st.session_state.active_profile:
        st.session_state.active_profile = active

    if st.session_state.active_profile != st.session_state._prev_active_profile:
        st.session_state.user_id = st.session_state.active_profile
        st.session_state.messages = []
        st.session_state.summary_text = None
        st.session_state.tool_history = []
        st.session_state.last_retrieved_memories = []
        st.session_state.last_saved_memory_ids = []
        st.session_state.manual_injected_memories = []
        st.session_state.mem_search_results = []
        st.session_state.uploaded_images = []
        st.session_state.previous_uploaded_count = 0
        st.session_state._prev_active_profile = st.session_state.active_profile
        st.info(f"í”„ë¡œí•„ ì „í™˜: '{st.session_state.active_profile}' (ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”)")

    st.divider()

    st.subheader("ğŸ“ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "ëŒ€í™”ì— ì²¨ë¶€í•  ì´ë¯¸ì§€",
        type=["png", "jpg", "jpeg", "gif", "webp"],
        accept_multiple_files=True,
        key="sidebar_image_uploader",
    )
    if uploaded_files:
        previous_names = [getattr(img, "name", "") for img in st.session_state.uploaded_images]
        stored: list[io.BytesIO] = []
        current_names: list[str] = []
        for file in uploaded_files:
            data = file.getvalue()
            buf = io.BytesIO(data)
            buf.name = file.name  # type: ignore[attr-defined]
            stored.append(buf)
            current_names.append(file.name)
        st.session_state.uploaded_images = stored
        st.session_state.previous_uploaded_count = len(stored)
        # ë³„ë„ ì•ˆë‚´ ë©”ì‹œì§€ëŠ” ë„ìš°ì§€ ì•Šê³  ì…ë ¥ì°½ í”„ë¡¬í”„íŠ¸ì—ì„œ ì²¨ë¶€ í˜„í™©ì„ í™•ì¸í•˜ë„ë¡ í•œë‹¤.
    else:
        if st.session_state.uploaded_images:
            st.session_state.uploaded_images = []
            st.session_state.previous_uploaded_count = 0

    # ì²¨ë¶€ ì´ˆê¸°í™” ë²„íŠ¼ì€ ì œê±°í•¨ (ì‚¬ìš©ìëŠ” ìƒˆë¡œ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒˆ í”„ë¡œí•„/ì„¸ì…˜ìœ¼ë¡œ ë¦¬ì…‹ ê°€ëŠ¥)

    st.divider()

    st.subheader("ğŸ§  ë©”ëª¨ë¦¬ ì„¤ì •")
    st.session_state.use_memory = st.checkbox("ì¥ê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©", value=st.session_state.use_memory)
    st.session_state.pinned_core_enabled = st.checkbox("í•µì‹¬ ì‚¬ì‹¤ ê³ ì • ìŠ¬ë¡¯ ì‚¬ìš©", value=st.session_state.pinned_core_enabled)
    st.session_state.retrieval_top_k = st.slider("ê²€ìƒ‰ Top-K", min_value=1, max_value=20, value=int(st.session_state.retrieval_top_k))
    st.session_state.recent_turn_window = st.slider("ìµœê·¼ í„´ ì°½ í¬ê¸°", min_value=3, max_value=20, value=int(st.session_state.recent_turn_window))
    st.session_state.summarize_trigger_turns = st.slider("ìš”ì•½ íŠ¸ë¦¬ê±° í„´ ìˆ˜", min_value=5, max_value=40, value=int(st.session_state.summarize_trigger_turns))
    st.session_state.memory_token_budget = st.slider("ë©”ëª¨ë¦¬ ë¸”ë¡ ìµœëŒ€ í† í°", min_value=200, max_value=4000, value=int(st.session_state.memory_token_budget), step=50)
    st.session_state.memory_item_token_cap = st.slider("í•­ëª©ë‹¹ í† í° ìƒí•œ", min_value=50, max_value=300, value=int(st.session_state.memory_item_token_cap), step=10)
    st.session_state.pinned_token_budget = st.slider("í•µì‹¬ ì‚¬ì‹¤ ìŠ¬ë¡¯ í† í°", min_value=100, max_value=1000, value=int(st.session_state.pinned_token_budget), step=50)
    st.session_state.setdefault("pinned_compact_with_model", False)
    st.session_state.setdefault("pinned_max_queries", 6)
    st.session_state.pinned_compact_with_model = st.checkbox("í•µì‹¬ ì‚¬ì‹¤ ìš”ì•½ ì••ì¶•(ëŠë¦´ ìˆ˜ ìˆìŒ)", value=bool(st.session_state.pinned_compact_with_model))
    st.session_state.pinned_max_queries = st.slider("í•µì‹¬ ì‚¬ì‹¤ ê²€ìƒ‰ ê°•ë„(ì§ˆì˜ ìˆ˜)", min_value=3, max_value=12, value=int(st.session_state.pinned_max_queries))

    with st.expander("ğŸ“Œ í•µì‹¬ ì‚¬ì‹¤ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
        st.caption("owner_id / cat_id ë²”ìœ„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ìš”ë„ ë†’ì€ í”„ë¡œí•„ í•­ëª©ì„ ìš”ì•½í•´ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        col_a, col_b = st.columns([0.5, 0.5])
        with col_a:
            if st.button("ë¯¸ë¦¬ë³´ê¸° ê°±ì‹ ", use_container_width=True, key="btn_refresh_pinned_preview"):
                try:
                    model, _client = get_model_and_client()
                    preview = build_pinned_core_facts_block(
                        user_id=st.session_state.user_id,
                        user_message="",
                        summary_text=st.session_state.get("summary_text"),
                        model=model,
                        max_tokens=int(st.session_state.get("pinned_token_budget", 400)),
                        per_item_cap=int(st.session_state.get("memory_item_token_cap", 150)),
                        compact_with_model=bool(st.session_state.get("pinned_compact_with_model", False)),
                        max_queries=int(st.session_state.get("pinned_max_queries", 6)),
                        owner_id=(st.session_state.owner_id or None),
                        cat_id=(st.session_state.cat_id or None),
                        importance_min=0.8,
                    )
                    st.session_state.pinned_preview = preview or "(ë¹„ì–´ ìˆìŒ)"
                    st.success("í•µì‹¬ ì‚¬ì‹¤ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ê°±ì‹ í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.warning(f"ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
        with col_b:
            if st.button("ë¯¸ë¦¬ë³´ê¸° ì´ˆê¸°í™”", use_container_width=True, key="btn_clear_pinned_preview"):
                st.session_state.pinned_preview = None
        if st.session_state.pinned_preview:
            st.text_area("í•µì‹¬ ì‚¬ì‹¤", value=st.session_state.pinned_preview, height=220, key="ta_pinned_preview")
        else:
            st.caption("ë¯¸ë¦¬ë³´ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë¯¸ë¦¬ë³´ê¸° ê°±ì‹ 'ì„ ëˆŒëŸ¬ ìƒì„±í•˜ì„¸ìš”.")

    st.divider()
    st.subheader("ğŸ‘¥ ê°œì²´ ì„ íƒ (ë³´í˜¸ì/ê³ ì–‘ì´)")
    st.session_state.owner_id = st.text_input("ë³´í˜¸ì ID (owner_id)", value=st.session_state.owner_id, placeholder="ì˜ˆ: owner:aidan")
    st.session_state.cat_id = st.text_input("ê³ ì–‘ì´ ID (cat_id)", value=st.session_state.cat_id, placeholder="ì˜ˆ: cat:momo")

    st.divider()
    st.subheader("ğŸ¤– ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ëª¨ë“œ")
    st.session_state.auto_mode = st.radio("ëª¨ë“œ ì„ íƒ", options=["Planner", "ReAct"], horizontal=True, index=0)
    st.session_state.auto_max_steps = st.slider("ìµœëŒ€ ìŠ¤í… ìˆ˜", min_value=1, max_value=16, value=int(st.session_state.auto_max_steps))
    st.session_state.auto_debug_view = st.checkbox("ë””ë²„ê·¸ ë³´ê¸°(ê³„íš/ë³€ìˆ˜/ì¶œë ¥/ì˜¤ë¥˜)", value=bool(st.session_state.auto_debug_view))
    TOOL_OPTIONS = [
        # Memory
        "memory_search", "memory_read", "memory_upsert",
        # Weather
        "get_weather", "get_forecast", "get_air_quality", "get_time_zone", "search_location",
        # Math
        "add", "subtract", "multiply", "divide", "convert_units", "calculate_percentage",
        # OCR / Lab / Health (ì¡´ì¬ ì‹œ)
        "ocr_image_file", "extract_lab_table", "analyze_cat_health",
    ]
    st.session_state.auto_allowed_tools = st.multiselect(
        "í—ˆìš© ë„êµ¬(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)",
        options=TOOL_OPTIONS,
        default=[],
        help="í”Œë˜ë„ˆ/ë£¨í”„ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë§Œ í—ˆìš©í•©ë‹ˆë‹¤. ì•ˆì „/ë¹„ìš© ì œì–´ìš©",
    )
    if st.session_state.auto_mode == "ReAct":
        st.session_state.react_max_iters = st.slider("ReAct ìµœëŒ€ ë°˜ë³µ", min_value=1, max_value=12, value=int(st.session_state.react_max_iters))
    with st.expander("ğŸ§­ ë§ˆì§€ë§‰ ê³„íš(ìš”ì•½)", expanded=False):
        last_state = st.session_state.get("last_auto_plan_state")
        if last_state:
            plan = last_state.get("plan")
            if plan:
                st.json(plan)
            vars_map = last_state.get("vars") or {}
            if vars_map:
                st.caption("vars")
                st.json(vars_map)
            outs = last_state.get("outputs") or {}
            if outs:
                st.caption("outputs")
                st.json(outs)
            errs = last_state.get("errors") or []
            if errs:
                st.caption("errors")
                for e in errs:
                    st.write(f"- {e}")

    # í™˜ê²½/ë°±ì—”ë“œ ë°°ì§€
    import importlib.util as _import_util
    tiktoken_ok = _import_util.find_spec("tiktoken") is not None
    chroma_ok = _import_util.find_spec("chromadb") is not None
    st.markdown("---")
    st.subheader("ğŸ§© í™˜ê²½ ìƒíƒœ")
    col_a, col_b = st.columns(2)
    with col_a:
        st.caption("Vector Store")
        st.markdown(f"- {'ğŸŸ¢' if chroma_ok else 'ğŸ”´'} Chroma")
        st.caption("Persist dir: data/vectors/")
    with col_b:
        st.caption("Tokenizer")
        st.markdown(f"- {'ğŸŸ¢' if tiktoken_ok else 'ğŸ”´'} tiktoken")

    with st.expander("ğŸ§  ë©”ëª¨ë¦¬ ìƒíƒœ", expanded=False):
        last_ret = st.session_state.get("last_retrieved_memories", [])
        last_saved = st.session_state.get("last_saved_memory_ids", [])
        st.caption(f"ìµœê·¼ ê²€ìƒ‰ëœ ë©”ëª¨ë¦¬: {len(last_ret)}ê°œ")
        for m in last_ret[:5]:
            st.write(f"- {m}")
        st.caption(f"ìµœê·¼ ì €ì¥ëœ ë©”ëª¨ë¦¬: {len(last_saved)}ê°œ")

    st.divider()
    with st.expander("ğŸ“œ íƒ€ì„ë¼ì¸ Â· ë©”ëª¨ë¦¬ ê²€ìƒ‰", expanded=False):
        q = st.text_input("í‚¤ì›Œë“œ", key="mem_search_query", placeholder="ì˜ˆ: ì˜ˆë°©ì ‘ì¢…, ì•Œë ˆë¥´ê¸°, ì‚¬ë£Œ")
        col1, col2 = st.columns(2)
        with col1:
            yf = st.number_input("ì—°ë„(ì‹œì‘)", value=0, min_value=0, max_value=9999, step=1)
        with col2:
            yt = st.number_input("ì—°ë„(ì¢…ë£Œ)", value=0, min_value=0, max_value=9999, step=1)
        year_from = int(yf) if yf else None
        year_to = int(yt) if yt else None
        types = st.multiselect("ìœ í˜• í•„í„°", options=MEMORY_TYPES, default=[])
        limit = st.slider("ìµœëŒ€ í‘œì‹œ ìˆ˜", min_value=10, max_value=200, value=50, step=10)
        if st.button("ê²€ìƒ‰", use_container_width=True):
            try:
                res = search_memories(
                    user_id=st.session_state.user_id,
                    query=q,
                    types=types or None,
                    year_from=year_from,
                    year_to=year_to,
                    limit=int(limit),
                )
                st.session_state.mem_search_results = res
            except Exception as e:
                st.warning(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        results = st.session_state.get("mem_search_results", [])
        if results:
            st.caption(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            sel_indices = []
            for idx, r in enumerate(results[:200]):
                ts = r.get("timestamp") or ""
                rtype = r.get("type") or ""
                content = r.get("content") or ""
                with st.container(border=True):
                    c1, c2 = st.columns([0.8, 0.2])
                    with c1:
                        st.markdown(f"**[{rtype}]** {content}")
                        if ts:
                            st.caption(ts)
                    with c2:
                        if st.checkbox("ì„ íƒ", key=f"mem_pick_{idx}"):
                            sel_indices.append(idx)
            if st.button("ì„ íƒ í•­ëª© ì»¨í…ìŠ¤íŠ¸ì— ë„£ê¸°", type="primary", use_container_width=True):
                picked = []
                for i in sel_indices:
                    if 0 <= i < len(results):
                        txt = (results[i].get("content") or "").strip()
                        if txt:
                            picked.append(txt)
                base = st.session_state.get("manual_injected_memories", [])
                st.session_state.manual_injected_memories = picked + base
                st.success(f"ì»¨í…ìŠ¤íŠ¸ì— {len(picked)}ê°œ í•­ëª©ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
            if st.button("ì„ íƒ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.manual_injected_memories = []
                st.session_state.mem_search_results = []
                st.info("ì„ íƒê³¼ ê²°ê³¼ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")


# ëŒ€í™” ë©”ì‹œì§€ ì˜ì—­ ë Œë”ë§
st.markdown('<div class="chat-messages">', unsafe_allow_html=True)
for role, content in st.session_state.messages:
    with st.chat_message(role):
        st.markdown(content)

st.markdown('</div>', unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥ ì˜ì—­
st.markdown('<div class="input-section">', unsafe_allow_html=True)

prompt_text = "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"
if st.session_state.uploaded_images and len(st.session_state.uploaded_images) > 0:
    prompt_text += f" (ğŸ“ {len(st.session_state.uploaded_images)}ê°œ ì´ë¯¸ì§€ ì²¨ë¶€ë¨)"

st.markdown('</div>', unsafe_allow_html=True)

chat_input_key = f"chat_input_{len(st.session_state.uploaded_images)}"
if prompt := st.chat_input(prompt_text, key=chat_input_key):
    user_message = prompt
    if st.session_state.uploaded_images:
        image_info = f" [ğŸ“ {len(st.session_state.uploaded_images)}ê°œ ì´ë¯¸ì§€ ì²¨ë¶€]"
        user_message += image_info

    saved_image_paths: list[str] = []
    display_images = list(st.session_state.uploaded_images)
    if st.session_state.uploaded_images:
        profile_dir = os.path.abspath(os.path.join(UPLOAD_ROOT, st.session_state.user_id))
        os.makedirs(profile_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        for idx, img in enumerate(st.session_state.uploaded_images):
            try:
                data = img.getvalue()
                original_name = getattr(img, "name", f"upload_{idx}.png")
                safe_name = f"{timestamp}_{idx}_{original_name}"
                path = os.path.abspath(os.path.join(profile_dir, safe_name))
                with open(path, "wb") as f:
                    f.write(data)
                saved_image_paths.append(path)
            except Exception:
                continue
        if saved_image_paths:
            path_lines = "\n".join(f"- {p}" for p in saved_image_paths)
            user_message += "\n\n[ì²¨ë¶€ ì´ë¯¸ì§€ ê²½ë¡œ]\n" + path_lines
        st.session_state.uploaded_images = []
        st.session_state.previous_uploaded_count = 0

    st.session_state.messages.append(("user", user_message))

    with st.chat_message("user"):
        st.markdown(user_message)
        if display_images:
            img_cols = st.columns(min(len(display_images), 3))
            for i, img_file in enumerate(display_images):
                try:
                    img_file.seek(0)
                except Exception:
                    pass
                with img_cols[i % 3]:
                    st.image(img_file, caption=img_file.name, width=120)

    with st.chat_message("assistant"):
        try:
            model, client = get_model_and_client()

            # í•µì‹¬ ì‚¬ì‹¤ ìŠ¬ë¡¯ ìë™ ì§‘ê³„(ì˜µì…˜)
            pinned_block: str | None = None
            try:
                if bool(st.session_state.get("pinned_core_enabled", True)):
                    pinned_block = build_pinned_core_facts_block(
                        user_id=st.session_state.user_id,
                        user_message=user_message,
                        summary_text=None,
                        model=model,
                        max_tokens=int(st.session_state.get("pinned_token_budget", 400)),
                        per_item_cap=int(st.session_state.get("memory_item_token_cap", 150)),
                        compact_with_model=bool(st.session_state.get("pinned_compact_with_model", False)),
                        max_queries=int(st.session_state.get("pinned_max_queries", 6)),
                        owner_id=(st.session_state.owner_id or None),
                        cat_id=(st.session_state.cat_id or None),
                        importance_min=0.8,
                    )
            except Exception:
                pinned_block = None

            # í•­ìƒ ìë™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: Planner ë˜ëŠ” ReAct ëª¨ë“œ
            async def _run_auto():
                allowed_tools = st.session_state.auto_allowed_tools or None
                extra_vars = {
                    "owner_id": st.session_state.owner_id or "",
                    "cat_id": st.session_state.cat_id or "",
                }
                if pinned_block:
                    extra_vars["pinned_core_facts"] = pinned_block
                if st.session_state.auto_mode == "ReAct":
                    state = await run_react_rag(
                        client,
                        model,
                        user_message,
                        allowed_tools=allowed_tools,
                        extra_vars=extra_vars,
                        max_iters=int(st.session_state.react_max_iters),
                    )
                else:
                    limits = {"max_steps": int(st.session_state.auto_max_steps)}
                    state = await run_auto_plan(
                        client,
                        model,
                        user_message,
                        allowed_tools=allowed_tools,
                        extra_vars=extra_vars,
                        limits=limits,
                    )
                return state

            try:
                state = asyncio.run(_run_auto())
            except RuntimeError:
                loop = asyncio.new_event_loop()
                try:
                    state = loop.run_until_complete(_run_auto())
                finally:
                    loop.close()

            # ë„êµ¬ ì‚¬ìš© ê¸°ë¡ ìˆ˜ì§‘
            tool_records = state.get("tools_used") or []
            if tool_records:
                now_stamp = datetime.now().strftime("%H:%M:%S")
                for rec in tool_records:
                    name = rec.get("name") or "(unknown)"
                    args = rec.get("args") or {}
                    st.session_state.tool_history.append({"time": now_stamp, "name": name, "args": args})
                st.info("ğŸ› ï¸ ì‚¬ìš©ëœ ë„êµ¬: " + ", ".join([str(r.get("name")) for r in tool_records if r.get("name")]))

            # ë©”ì‹œì§€ ì¶œë ¥ ë° ìƒíƒœ ì €ì¥
            final_msg = state.get("message") or "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            st.session_state.messages.append(("assistant", final_msg))
            st.markdown(final_msg)
            st.session_state.last_auto_plan_state = state

            # ë””ë²„ê·¸ ë·°(ì˜µì…˜)
            if bool(st.session_state.auto_debug_view):
                with st.expander("ğŸ§ª ìë™ ê³„íš ë””ë²„ê·¸", expanded=False):
                    st.caption("plan")
                    st.json(state.get("plan") or {})
                    st.caption("vars")
                    st.json(state.get("vars") or {})
                    st.caption("outputs")
                    st.json(state.get("outputs") or {})
                    errs = state.get("errors") or []
                    if errs:
                        st.caption("errors")
                        for e in errs:
                            st.write(f"- {e}")
            st.stop()

            # 3) íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤ëŠ” ìœ ì§€í•˜ë˜, OCR ìë™ ì²˜ë¦¬ëŠ” ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.

            rec = {"tokens": [], "used_tools": set(), "tool_details": [], "final_text": None}

            summary = st.session_state.get("summary_text")
            rt_window = int(st.session_state.recent_turn_window)
            sum_trig = int(st.session_state.summarize_trigger_turns)
            summary, pruned_messages = maybe_update_summary(
                summary,
                st.session_state.messages,
                recent_turn_window=rt_window,
                summarize_trigger_turns=sum_trig,
                model=model,
            )
            st.session_state.summary_text = summary
            st.session_state.messages = pruned_messages

            user_id = st.session_state.user_id
            retrieved_texts: list[str] = []
            pinned_text: str | None = None
            if st.session_state.use_memory and st.session_state.pinned_core_enabled:
                try:
                    now_ts = time.time()
                    cache = st.session_state.get("_pinned_cache", {})
                    cache_uid = f"{user_id}"
                    cache_ok = (
                        isinstance(cache, dict)
                        and cache.get("user_id") == cache_uid
                        and (now_ts - float(cache.get("ts", 0))) < 60.0
                        and cache.get("settings") == {
                            "max_tokens": int(st.session_state.pinned_token_budget),
                            "per_item_cap": int(st.session_state.memory_item_token_cap),
                            "compact": bool(st.session_state.pinned_compact_with_model),
                            "max_queries": int(st.session_state.pinned_max_queries),
                        }
                    )
                    if cache_ok:
                        pinned_text = cache.get("text")
                    else:
                        pinned_text = build_pinned_core_facts_block(
                            user_id=user_id,
                            user_message=user_message,
                            summary_text=summary,
                            model=model,
                            max_tokens=int(st.session_state.pinned_token_budget),
                            per_item_cap=int(st.session_state.memory_item_token_cap),
                            compact_with_model=bool(st.session_state.pinned_compact_with_model),
                            max_queries=int(st.session_state.pinned_max_queries),
                        )
                        st.session_state._pinned_cache = {
                            "user_id": cache_uid,
                            "ts": now_ts,
                            "text": pinned_text,
                            "settings": {
                                "max_tokens": int(st.session_state.pinned_token_budget),
                                "per_item_cap": int(st.session_state.memory_item_token_cap),
                                "compact": bool(st.session_state.pinned_compact_with_model),
                                "max_queries": int(st.session_state.pinned_max_queries),
                            },
                        }
                except Exception:
                    pinned_text = None
            if st.session_state.use_memory:
                try:
                    retrieved_items = retrieve_memories(user_id=user_id, user_message=user_message, summary_text=summary, k=int(st.session_state.retrieval_top_k))
                    retrieved_texts = [it.get("content", "").strip() for it in retrieved_items if (it.get("content") or "").strip()]
                    retrieved_texts = trim_memory_block(
                        texts=retrieved_texts,
                        max_tokens=int(st.session_state.memory_token_budget),
                        per_item_token_cap=int(st.session_state.memory_item_token_cap),
                    )
                except Exception:
                    retrieved_texts = []

            manual = st.session_state.get("manual_injected_memories", [])
            if manual:
                seen = set()
                merged: list[str] = []
                for it in manual + retrieved_texts:
                    k = it.strip()
                    if not k or k in seen:
                        continue
                    seen.add(k)
                    merged.append(k)
                retrieved_texts = merged
            st.session_state.last_retrieved_memories = retrieved_texts

            lc_messages = build_context_messages(
                summary_text=summary,
                history_messages=st.session_state.messages,
                new_user_message=user_message,
                recent_turn_window=rt_window,
                retrieved_memories=(retrieved_texts or None) if st.session_state.use_memory else None,
                pinned_core_facts=pinned_text if (st.session_state.use_memory and st.session_state.pinned_core_enabled) else None,
            )

            text = st.write_stream(stream_agent_generator(lc_messages, rec, model, client))

            now = datetime.now().strftime("%H:%M:%S")
            for d in rec["tool_details"]:
                st.session_state.tool_history.append({"time": now, **d})

            used_tools = list(rec["used_tools"]) if rec.get("used_tools") else []
            if used_tools:
                st.info(f"ğŸ› ï¸ ì‚¬ìš©ëœ ë„êµ¬: {', '.join(used_tools)}")

            final_str = text if isinstance(text, str) else (rec.get("final_text") or "")
            st.session_state.messages.append(("assistant", final_str))

            if st.session_state.use_memory:
                try:
                    candidates = extract_candidates(recent_turns=st.session_state.messages, assistant_reply=final_str, model=model)
                    if candidates:
                        saved_ids = write_memories(user_id=user_id, memories=candidates)
                        st.session_state.last_saved_memory_ids = saved_ids
                        if saved_ids:
                            st.caption(f"ğŸ§  ì¥ê¸° ë©”ëª¨ë¦¬ {len(saved_ids)}ê°œ ì €ì¥ë¨")
                except Exception:
                    pass

        except Exception as e:
            err = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            st.markdown(err)
            st.session_state.messages.append(("assistant", err))

# ì•± ë¡œì§ ì¢…ë£Œ
