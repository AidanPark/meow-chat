{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e542c052ee73bc41",
   "metadata": {},
   "source": [
    "### Korean OCR with PaddleOCR\n",
    "\n",
    "í…ŒìŠ¤íŠ¸: PaddleOCR ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì–»ì–´ë‚´ê³  llm ì„ í†µí•´ ë°ì´íƒ€ êµ¬ì¡°í™”ë¥¼ ì‹œë„í•œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688414e9-107e-418d-b91f-0c643b646324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T14:29:55.056934Z",
     "start_time": "2025-10-09T14:29:51.695900Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import paddleocr\n",
    "import base64\n",
    "\n",
    "# OCR ì—”ì§„\n",
    "from paddleocr import PaddleOCR\n",
    "import inspect\n",
    "\n",
    "# ì´ë¯¸ì§€/ê³¼í•™ ê³„ì‚°\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤\n",
    "try:\n",
    "    from app.services.analysis.image_preprocessing import (\n",
    "        # ê³µí†µ í•¨ìˆ˜ë“¤\n",
    "        pdf_to_images, open_with_exif, save_png_bytes, apply_pipeline,\n",
    "        \n",
    "        # ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤\n",
    "        flatten_transparency, auto_crop_with_margin, normalize_mode,\n",
    "        upscale_min_resolution, illumination_flatten, suppress_glare,\n",
    "        weak_autocontrast, apply_clahe, conservative_sharpen, blacken_reddish_text, blacken_bluish_text, to_grayscale,\n",
    "        adaptive_binarize_for_ocr, enhance_table_lines, table_smart_crop,\n",
    "        add_white_border, downscale_target_long_edge, ocr_quality_gate,\n",
    "        \n",
    "        # ê³ ê¸‰ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (í•„ìš”ì‹œ)\n",
    "        detect_document_quad, perspective_unwarp, deskew_textlines,\n",
    "        conditional_dewarp\n",
    "    )\n",
    "    print(\"âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ import ì™„ë£Œ!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ğŸ“‚ í˜„ì¬ sys.path:\", sys.path[-3:])  \n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "sys.path.append('/home/aidan/work/meow-chat')\n",
    "\n",
    "# í™˜ê²½ ì •ë³´ í™•ì¸\n",
    "print(f\"ğŸ Python ê²½ë¡œ: {sys.executable}\")\n",
    "print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# PATH í™•ì¸ (ì²˜ìŒ 3ê°œë§Œ)\n",
    "path_list = os.environ['PATH'].split(':')\n",
    "print(f\"\\nğŸ“‹ PATH ìˆœì„œ:\")\n",
    "for i, path in enumerate(path_list[:3], 1):\n",
    "    marker = \"âœ…\" if \"meow-chat\" in path else \"ğŸ“\"\n",
    "    print(f\"  {i}. {marker} {path}\")\n",
    "\n",
    "print(f\"\\nğŸ” í˜„ì¬ PaddleOCR ë²„ì „: {paddleocr.__version__}\")\n",
    "\n",
    "# PaddleOCR ìƒì„±ìì˜ íŒŒë¼ë¯¸í„° í™•ì¸\n",
    "signature = inspect.signature(PaddleOCR.__init__)\n",
    "print(f\"\\nğŸ“‹ ì§€ì›í•˜ëŠ” íŒŒë¼ë¯¸í„°:\")\n",
    "for param_name, param in signature.parameters.items():\n",
    "    if param_name != 'self':\n",
    "        default = param.default if param.default != inspect.Parameter.empty else \"í•„ìˆ˜\"\n",
    "        print(f\"   {param_name}: {default}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f604365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìœ„ì¹˜)\n",
    "load_dotenv()  # í˜„ì¬ ë””ë ‰í† ë¦¬ì™€ ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ìë™ìœ¼ë¡œ .env íŒŒì¼ì„ ì°¾ìŒ\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# í™˜ê²½ í™•ì¸\n",
    "print(f\"ğŸ”‘ API Key ì„¤ì •: {'âœ… ì™„ë£Œ' if os.getenv('OPENAI_API_KEY') else 'âŒ ì—†ìŒ'}\")\n",
    "print(f\"ğŸ“‚ í˜„ì¬ ê²½ë¡œ: {os.getcwd()}\")\n",
    "print(f\"ğŸ“„ PDF íŒŒì¼ ì¡´ì¬: {'âœ… ìˆìŒ' if os.path.exists('../../test/data/ì€ë‚´ê³¼.pdf') else 'âŒ ì—†ìŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8eba9-ff8c-41eb-b8d2-46bae3d7ea54",
   "metadata": {},
   "source": [
    "### 1. OCR ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66777d25-d52b-47b2-ae81-f4d00134fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.ocr.paddle_ocr import PaddleOCRService\n",
    "\n",
    "ocr = PaddleOCRService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr.get_available_langs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr.get_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr.get_current_model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr.get_current_preprocessing_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/test_image_1.jpg')\n",
    "\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241106.jpg')   # ---------- ë‚ ì§œê°€ ì—¬ëŸ¬ê°œ\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241107_2.jpg')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241107.jpg')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241121_2.png')  # ---------- ë‚ ì§œ ì—†ëŠ”ê²ƒ\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241121.png')    # ---------- ì‚¬ì§„ìœ¼ë¡œ ì§ì–´ì„œ ì‚ëš¤ì–´ì§„ê²ƒ ê°’ ì•ˆë‚˜ì˜´. \n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241123_2.png')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241123.png')    # ---------- ì¸ì‡„ì¼ìë§Œ ìˆìŒ\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241205_2.jpg')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241205.jpg')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241219.png')    # ---------- ì‚¬ì§„ìœ¼ë¡œ ì§ì–´ì„œ ì‚ëš¤ì–´ì§„ê²ƒ\n",
    "img_path = os.path.abspath('notebooks/ocr/assets/images/20241221_2.jpg')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241221.jpg')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241224_2.png')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241224.png')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20241231.png')\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250107.png')    # ----------\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250110.png')    # ---------- ë°ì´ë¸” êµ¬ì¡° íŠ¹ì´í•œê²ƒ. value ì—´ ë ˆì´ë¸”ì´ ë‚ ì§œì„\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250116_2.png')  \n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250116_3.png')  # ---------- blue ê¸€ì ì¸ì‹ì´ ì˜ ì•ˆë¨\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250116_4.png') \n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250116.png') \n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250119_2.png')  # ---------- íë¦¿í•œ ì´ë¯¸ì§€\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250119_3.png') \n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250119.png')    # ---------- íë¦¿í•œ ì´ë¯¸ì§€\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250125.jpeg') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜ RDW-CV  RETIC#\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250203.jpeg') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250207.jpeg') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250209.jpeg') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250216.jpeg') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250222.png') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250228.png') # ----------   A4 ì§€ 1ì¥ ì´ìƒ ë¶„ëŸ‰ì€ ëŒ€ëŸ‰ ì˜¤ë¥˜\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250301.png')\n",
    "\n",
    "\n",
    "\n",
    "# img_path = os.path.abspath('notebooks/ocr/assets/images/20250125.jpeg')\n",
    "\n",
    "\n",
    "\n",
    "print(f\"ë¶„ì„í•  ì´ë¯¸ì§€: {img_path}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd200baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    img_bytes: bytes,    \n",
    "    debug: bool = True,\n",
    ") -> bytes:\n",
    "    try:\n",
    "        if debug:\n",
    "            print(\"ğŸ¥ ì˜ë£Œ ë¬¸ì„œìš© ì „ì²˜ë¦¬ ì‹œì‘\")\n",
    "        \n",
    "        img = open_with_exif(img_bytes) # EXIF íšŒì „ êµì •\n",
    "        original_size = img.size\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {original_size}\")\n",
    "        \n",
    "        steps = [\n",
    "            # ê¸°ë³¸ ì •ë¦¬ (í•„ìˆ˜ ì„ í–‰ ë‹¨ê³„)\n",
    "            (flatten_transparency, {}),              # íˆ¬ëª…ë„ ì œê±°\n",
    "            (normalize_mode, {}),                    # ëª¨ë“œ í‘œì¤€í™” (L/RGB)\n",
    "            \n",
    "            # ê¸°í•˜í•™ì  ë³´ì • (í”½ì…€ ìˆ˜ì¤€ ì‘ì—…)\n",
    "            # (auto_crop_with_margin, {}),           # ì—¬ë°± ì œê±°\n",
    "            (conditional_dewarp, {}),                # í˜ì´ì§€ íœ˜ì–´ì§ ë³´ì • \n",
    "            (deskew_textlines, {}),                  # ë¯¸ì„¸ ê¸°ìš¸ê¸° ë³´ì •\n",
    "          \n",
    "            # í•´ìƒë„ í‘œì¤€í™” (ìµœì†Œ í’ˆì§ˆ í™•ë³´)\n",
    "            (upscale_min_resolution, {}),            \n",
    "            \n",
    "            # ë¹›ë°˜ì‚¬ ì œê±°\n",
    "            (suppress_glare, {}),                   \n",
    "            \n",
    "            # ëŒ€ë¹„ í–¥ìƒ\n",
    "            (weak_autocontrast, {}),               \n",
    "            \n",
    "            # ìƒ‰ í…ìŠ¤íŠ¸ ë³´ì •(ìˆìœ¼ë©´)\n",
    "            (blacken_reddish_text, {}),  \n",
    "            (blacken_bluish_text, {}), \n",
    "\n",
    "            # íšŒìƒ‰í™”\n",
    "            (to_grayscale, {}),                   \n",
    "\n",
    "            # í‘œ ë¼ì¸ ê°•í™”\n",
    "            (enhance_table_lines, {}), \n",
    "            \n",
    "            # ìµœì¢… í¬ê¸° ì¡°ì • (í† í° ì ˆì•½)\n",
    "            (downscale_target_long_edge, {}),      \n",
    "\n",
    "            # ì„ ëª…ë„ í–¥ìƒ\n",
    "            (conservative_sharpen, {}),           \n",
    "        ]\n",
    "    \n",
    "        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "        img = apply_pipeline(img, steps)\n",
    "        \n",
    "        # PNGë¡œ ì €ì¥\n",
    "        buf = io.BytesIO()\n",
    "        if img.mode == 'L':  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼\n",
    "            img.save(buf, format=\"JPEG\", quality=85, optimize=True)\n",
    "        else:  # RGB\n",
    "            img.save(buf, format=\"JPEG\", quality=85, optimize=True, subsampling=2)\n",
    "        result_bytes = buf.getvalue()\n",
    "        \n",
    "        if debug:\n",
    "            final_size = img.size\n",
    "            print(f\"ğŸ“ ìµœì¢… ì´ë¯¸ì§€ í¬ê¸°: {final_size}\")\n",
    "            print(f\"ğŸ”„ í¬ê¸° ë³€í™”: {original_size} â†’ {final_size}\")\n",
    "            # ìš©ëŸ‰ ë³€í™” ë° í¼ì„¼íŠ¸ ê³„ì‚°\n",
    "            original_bytes = len(img_bytes)\n",
    "            result_bytes_len = len(result_bytes)\n",
    "            percentage = (result_bytes_len / original_bytes) * 100\n",
    "            \n",
    "            print(f\"ğŸ’¾ ìš©ëŸ‰ ë³€í™”: {original_bytes:,} bytes â†’ {result_bytes_len:,} bytes ({percentage:.1f}%)\")\n",
    "            print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "        \n",
    "        return result_bytes\n",
    "        \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        print(f\"âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}\")\n",
    "        return img_bytes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ê³  ì „ì²˜ë¦¬í•˜ì—¬ ë°”ì´íŠ¸ë¡œ ë³€í™˜\n",
    "with open(img_path, 'rb') as f:\n",
    "    _raw_bytes = f.read()\n",
    "\n",
    "_pre_bytes = preprocess(_raw_bytes, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c203655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bytesë¥¼ PIL Imageë¡œ ë³€í™˜\n",
    "processed_img = PILImage.open(io.BytesIO(_pre_bytes))\n",
    "\n",
    "# ì›ë³¸ê³¼ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ í‘œì‹œ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€\n",
    "original_img = PILImage.open(img_path)\n",
    "axes[0].imshow(original_img)\n",
    "axes[0].set_title('original_img', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€\n",
    "if processed_img.mode == 'L':  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼\n",
    "    axes[1].imshow(processed_img, cmap='gray', vmin=0, vmax=255)\n",
    "else:  # ì»¬ëŸ¬\n",
    "    axes[1].imshow(processed_img)\n",
    "axes[1].set_title('processed_img', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR ì‹¤í–‰\n",
    "print(f\"ğŸ” OCR ë¶„ì„ ì‹œì‘: {img_path}\")\n",
    "try:\n",
    "    result = ocr.run_ocr_from_bytes(_pre_bytes)\n",
    "    print(\"âœ… OCR ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(f\"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f46e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR ê²°ê³¼ ì¶œë ¥ - ìƒˆë¡œìš´ í˜•íƒœë¡œ í…ŒìŠ¤íŠ¸\n",
    "# print(result)\n",
    "\n",
    "ocr_data = ocr.extract_text_with_confidence(result[0])\n",
    "print(f\" ocr_data {ocr_data}\")\n",
    "\n",
    "print(\"ğŸ“‹ OCR ê²°ê³¼:\")\n",
    "for i, item in enumerate(ocr_data, 1):\n",
    "    print(f\"  {i}. {item}\")\n",
    "\n",
    "print(f\"\\nì´ {len(ocr_data)}ê°œ í…ìŠ¤íŠ¸ ì¸ì‹ë¨\")\n",
    "\n",
    "# json_string = ocr.convert_to_structured_json(result)\n",
    "# print(\"ğŸ“„ convert_to_structured_json ê²°ê³¼:\")\n",
    "# print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# LLM ì „ìš© íŒŒì„œ: LLMì´ í† í° ì¸ë±ìŠ¤ë§Œ ë°˜í™˜í•˜ê³ , ì‹¤ì œ ê°’ì€ ë°˜ë“œì‹œ ocr_dataì˜ í…ìŠ¤íŠ¸/ì»¨í”¼ë˜ìŠ¤ë¡œë¶€í„° ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "# - valueëŠ” í•­ìƒ ìˆ˜ì¹˜í˜•ì´ì–´ì•¼ í•˜ë©°, ê°’ ëì˜ H/L/N/High/Low/Normal ì ‘ë¯¸ëŠ” ì œê±° í›„ ìˆ«ìë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "# - code_confidenceëŠ” ocr_dataì˜ í•´ë‹¹ code í† í°ì˜ confidenceë¥¼ ë¬¸ìì—´ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤(ë°˜ì˜¬ë¦¼/í¬ë§· ë³€ê²½ ì—†ìŒ).\n",
    "# - unit/reference ì—­ì‹œ ocr_dataì˜ í…ìŠ¤íŠ¸ë¡œë¶€í„°ë§Œ ì¶”ì¶œ/ê°€ê³µí•©ë‹ˆë‹¤(ì„ì˜ ìƒì„± ê¸ˆì§€).\n",
    "\n",
    "_num_re = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?\")\n",
    "_range_re = re.compile(r\"([-+]?\\d+(?:\\.\\d+)?)\\s*[-â€“~]\\s*([-+]?\\d+(?:\\.\\d+)?)\")\n",
    "_suffix_re = re.compile(r\"\\s*(?:\\(|\\[)?\\s*(?i:(?:high|low|normal)|h|l|n)\\s*(?:\\)|\\])?\\s*$\")\n",
    "_unit_tail_re = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?\\s*([A-Za-zÂµ/%]+)$\")\n",
    "\n",
    "\n",
    "def _extract_numeric(text: str) -> Optional[str]:\n",
    "    if not text:\n",
    "        return None\n",
    "    t = text.strip()\n",
    "    # ì ‘ë¯¸(H/L/N/High/Low/Normal) ì œê±°\n",
    "    t = _suffix_re.sub(\"\", t)\n",
    "    m = _num_re.search(t)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "\n",
    "def _extract_unit_from_text(text: str) -> Optional[str]:\n",
    "    if not text:\n",
    "        return None\n",
    "    t = text.strip()\n",
    "    m = _unit_tail_re.search(t)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def _extract_range(text: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    if not text:\n",
    "        return None, None\n",
    "    m = _range_re.search(text)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return m.group(1), m.group(2)\n",
    "\n",
    "\n",
    "def _safe_get_token(tokens: List[Dict[str, Any]], idx: Optional[int]) -> Optional[Dict[str, Any]]:\n",
    "    if idx is None:\n",
    "        return None\n",
    "    if not isinstance(idx, int):\n",
    "        return None\n",
    "    if idx < 0 or idx >= len(tokens):\n",
    "        return None\n",
    "    return tokens[idx]\n",
    "\n",
    "\n",
    "def _build_tests_from_indices(tokens: List[Dict[str, Any]], plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    out = []\n",
    "    tests = plan.get(\"tests\", []) if isinstance(plan, dict) else []\n",
    "    for t in tests:\n",
    "        code_idx = t.get(\"code_idx\")\n",
    "        value_idx = t.get(\"value_idx\")\n",
    "        unit_idx = t.get(\"unit_idx\")\n",
    "        ref_min_idx = t.get(\"ref_min_idx\")\n",
    "        ref_max_idx = t.get(\"ref_max_idx\")\n",
    "        range_idx = t.get(\"range_idx\")\n",
    "\n",
    "        tok_code = _safe_get_token(tokens, code_idx)\n",
    "        tok_value = _safe_get_token(tokens, value_idx)\n",
    "        tok_unit = _safe_get_token(tokens, unit_idx)\n",
    "        tok_ref_min = _safe_get_token(tokens, ref_min_idx)\n",
    "        tok_ref_max = _safe_get_token(tokens, ref_max_idx)\n",
    "        tok_range = _safe_get_token(tokens, range_idx)\n",
    "\n",
    "        code_text = (tok_code or {}).get(\"text\") or \"UNKNOWN\"\n",
    "        code_confidence = str((tok_code or {}).get(\"confidence\") if tok_code and \"confidence\" in tok_code else \"\")\n",
    "\n",
    "        # value: ë°˜ë“œì‹œ ìˆ˜ì¹˜í˜•, ì ‘ë¯¸(H/L/N/High/Low/Normal) ì œê±° í›„ ìˆ«ìë§Œ\n",
    "        raw_value_text = (tok_value or {}).get(\"text\") if tok_value else None\n",
    "        value_num = _extract_numeric(raw_value_text or \"\")\n",
    "        if value_num is None:\n",
    "            value_num = \"UNKNOWN\"\n",
    "\n",
    "        # unit: ìš°ì„  unit_idx, ì—†ìœ¼ë©´ value í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ìœ„ ì¶”ì¶œ ì‹œë„\n",
    "        unit_text = (tok_unit or {}).get(\"text\") if tok_unit else None\n",
    "        if not unit_text and raw_value_text:\n",
    "            unit_text = _extract_unit_from_text(raw_value_text)\n",
    "        unit_text = unit_text or \"UNKNOWN\"\n",
    "\n",
    "        # reference: ref_min/ref_max ì¸ë±ìŠ¤ê°€ ìš°ì„ , ì—†ìœ¼ë©´ range_idxì—ì„œ íŒŒì‹±\n",
    "        ref_min = _extract_numeric((tok_ref_min or {}).get(\"text\") or \"\") if tok_ref_min else None\n",
    "        ref_max = _extract_numeric((tok_ref_max or {}).get(\"text\") or \"\") if tok_ref_max else None\n",
    "        if (ref_min is None or ref_max is None) and tok_range:\n",
    "            rmin, rmax = _extract_range((tok_range or {}).get(\"text\") or \"\")\n",
    "            ref_min = ref_min or rmin\n",
    "            ref_max = ref_max or rmax\n",
    "        ref_min = ref_min or \"UNKNOWN\"\n",
    "        ref_max = ref_max or \"UNKNOWN\"\n",
    "\n",
    "        out.append({\n",
    "            \"code\": str(code_text),\n",
    "            \"code_confidence\": code_confidence if code_confidence != \"\" else \"UNKNOWN\",\n",
    "            \"value\": str(value_num),\n",
    "            \"reference_min\": str(ref_min),\n",
    "            \"reference_max\": str(ref_max),\n",
    "            \"unit\": str(unit_text),\n",
    "        })\n",
    "    return {\"tests\": out}\n",
    "\n",
    "\n",
    "def analyze_medical_ocr_data_with_llm(ocr_data: List[Dict[str, Any]], model: str = \"gpt-4o\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    LLMë§Œì„ ì‚¬ìš©í•´ ë‹¤ì–‘í•œ í˜•íƒœì˜ OCR í† í°ìœ¼ë¡œë¶€í„° í…Œì´ë¸”(ê²€ì‚¬ì½”ë“œ/ê°’/ì°¸ê³ ë²”ìœ„/ë‹¨ìœ„)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    - LLMì€ ë°˜ë“œì‹œ tokens ë°°ì—´ì˜ ì¸ë±ìŠ¤ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤(ë¬¸ìì—´ ê°’ì„ ì§ì ‘ ìƒì„± ê¸ˆì§€).\n",
    "    - valueëŠ” ìˆ˜ì¹˜í˜•ë§Œ í—ˆìš©í•˜ë©°, ì ‘ë¯¸ H/L/N/High/Low/Normalì€ ë¬´ì‹œ í›„ ìˆ«ìë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    - code_confidenceëŠ” ocr_dataì˜ í•´ë‹¹ code í† í° confidenceë¥¼ ë¬¸ìì—´ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    - model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„(ê¸°ë³¸ê°’ \"gpt-4o\").\n",
    "    ë°˜í™˜: {\"tests\":[{code, code_confidence, value, reference_min, reference_max, unit}]}\n",
    "    \"\"\"\n",
    "    tokens_for_llm = [\n",
    "        {\"idx\": i, \"text\": str(x.get(\"text\", \"\")), \"confidence\": float(x.get(\"confidence\", 0.0))}\n",
    "        for i, x in enumerate(ocr_data)\n",
    "        if str(x.get(\"text\", \"\")).strip()\n",
    "    ]\n",
    "\n",
    "    system_prompt = (\n",
    "        \"ë‹¹ì‹ ì€ ë°˜ë ¤ë™ë¬¼ ê²€ì‚¬ê²°ê³¼ì§€ OCR í† í°ë“¤ë¡œë¶€í„° í…Œì´ë¸” ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "        \"ë‹¤ìŒ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”:\\n\"\n",
    "        \"1) ë‹¤ì–‘í•œ ë ˆì´ì•„ì›ƒ ì²˜ë¦¬: name/result/unit/reference, name/reference/result/unit ë“± ìˆœì„œê°€ ë‹¬ë¼ë„ í† í° ì¸ì ‘ì„±ê³¼ í˜•ìƒì„ í™œìš©í•´ ëŒ€ì‘.\\n\"\n",
    "        \"2) ì»¬ëŸ¼ í—¤ë”ê°€ ë³´ì´ë©´ í—¤ë”ë¥¼ ê·¼ê±°ë¡œ ë§¤í•‘, ì—†ìœ¼ë©´ ìˆ«ì/ë²”ìœ„/ë‹¨ìœ„ íŒ¨í„´ê³¼ í–‰ ê·¸ë£¹ì„ ì¶”ì •.\\n\"\n",
    "        \"3) ì°¸ê³ ë²”ìœ„ëŠ” 'min-max' í•˜ë‚˜ì˜ í† í°ì´ê±°ë‚˜, min/maxê°€ ë¶„ë¦¬ë  ìˆ˜ ìˆìŒ.\\n\"\n",
    "        \"4) ë°˜í™˜ ì‹œ ì ˆëŒ€ ë¬¸ìì—´ ê°’(ì½”ë“œ/ê°’/ë‹¨ìœ„/ë²”ìœ„)ì„ ì§ì ‘ ìƒì„±í•˜ì§€ ë§ê³ , ì œê³µëœ tokens ë°°ì—´ì˜ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©.\\n\"\n",
    "        \"5) ê²°ê³¼ í¬ë§·ì€ ì•„ë˜ì™€ ê°™ìŒ: {\\\"tests\\\":[{\\\"code_idx\\\":int,\\\"value_idx\\\":int|null,\\\"unit_idx\\\":int|null,\\\"ref_min_idx\\\":int|null,\\\"ref_max_idx\\\":int|null,\\\"range_idx\\\":int|null}]}.\\n\"\n",
    "        \"6) ì¸ë±ìŠ¤ëŠ” tokens[idx]ë¥¼ ê°€ë¦¬ì¼œì•¼ í•˜ë©° ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = (\n",
    "        \"ì•„ë˜ tokens(JSON ë°°ì—´, ê° ì›ì†ŒëŠ” {idx,text,confidence})ë§Œì„ ì´ìš©í•´ ê²€ì‚¬ í•­ëª©ì„ ì¶”ì¶œí•˜ì„¸ìš”.\\n\"\n",
    "        \"- ë¬¸ìì—´ ê°’ì„ ì§ì ‘ ë§Œë“¤ì§€ ë§ê³  ì¸ë±ìŠ¤ë§Œ ë°˜í™˜í•˜ì„¸ìš”.\\n\"\n",
    "        \"- rangeê°€ í•˜ë‚˜ì˜ í† í°ì— min-maxë¡œ ìˆìœ¼ë©´ range_idxë§Œ ì±„ìš°ê³  ref_min_idx/ref_max_idxëŠ” null ê°€ëŠ¥.\\n\"\n",
    "        \"- ë¶„ë¦¬ë˜ì–´ ìˆìœ¼ë©´ ref_min_idx/ref_max_idxë¡œ ê°ê° ì§€ì •.\\n\"\n",
    "        \"- unitì€ ë³„ë„ í† í°ì´ë©´ unit_idx, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ null.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": user_prompt},\n",
    "                    {\"type\": \"text\", \"text\": json.dumps({\"tokens\": tokens_for_llm}, ensure_ascii=False)}\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    plan = json.loads(response.choices[0].message.content)\n",
    "    return _build_tests_from_indices(tokens_for_llm, plan)\n",
    "\n",
    "print(\"ğŸ§  LLM ì „ìš©(ì¸ë±ìŠ¤ ê¸°ë°˜) íŒŒì„œ: model íŒŒë¼ë¯¸í„° ì¶”ê°€ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eae79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦: í˜„ì¬ ë…¸íŠ¸ë¶ì˜ ocr_dataë¥¼ LLM ì „ìš©(ì¸ë±ìŠ¤ ê¸°ë°˜) íŒŒì„œì— ë„£ì–´ ê²°ê³¼ í™•ì¸\n",
    "# gpt-4o í˜¸ì¶œ ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ ëª¨ë¸ì„ gpt-4o-minië¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "parsed = analyze_medical_ocr_data_with_llm(ocr_data, model=\"gpt-4o\")\n",
    "print(json.dumps(parsed, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654155c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o: 6409.3 ms, tests=14\n",
      "gpt-4o-mini: 11855.6 ms, tests=14\n",
      "gpt-4o-mini: 11855.6 ms, tests=14\n",
      "gpt-4.1-mini: 7107.2 ms, tests=14\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "gpt-4o: 6409.3 ms, tests=14\n",
      "gpt-4o-mini: 11855.6 ms, tests=14\n",
      "gpt-4.1-mini: 7107.2 ms, tests=14\n",
      "\n",
      "--- ì°¨ì´: gpt-4o vs gpt-4o-mini ---\n",
      "- idx 3 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'BASO (%)', 'value': 'UNKNOWN', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': '%'}\n",
      "  gpt-4o-mini: {'code': 'BASO (%)', 'value': 'UNKNOWN', 'reference_min': '0.01', 'reference_max': '0.26', 'unit': 'UNKNOWN'}\n",
      "- idx 4 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'NEUT', 'value': '18.065', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'NEUT', 'value': '1.15', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': 'UNKNOWN'}\n",
      "- idx 5 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'LYMPH', 'value': '1.78', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'LYMPH', 'value': '0.92', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': 'UNKNOWN'}\n",
      "- idx 6 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'MONO', 'value': '0.569', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'MONO', 'value': '0.05', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': 'UNKNOWN'}\n",
      "- idx 7 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'EOS', 'value': '0.189', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'EOS', 'value': '0.17', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': 'UNKNOWN'}\n",
      "- idx 8 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'BASO', 'value': 'UNKNOWN', 'reference_min': '0.01', 'reference_max': '0.26', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'BASO', 'value': '0.01', 'reference_min': '0.01', 'reference_max': '0.26', 'unit': 'KuL'}\n",
      "- idx 9 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'PLT', 'value': '305', 'reference_min': '151', 'reference_max': '600', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'PLT', 'value': '151', 'reference_min': '151', 'reference_max': '600', 'unit': 'UNKNOWN'}\n",
      "- idx 11 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'PDV', 'value': 'UNKNOWN', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'fL'}\n",
      "  gpt-4o-mini: {'code': 'PDV', 'value': 'UNKNOWN', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'UNKNOWN'}\n",
      "- idx 13 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'RETHGB', 'value': 'UNKNOWN', 'reference_min': '13.2', 'reference_max': '20.8', 'unit': 'pg'}\n",
      "  gpt-4o-mini: {'code': 'RETHGB', 'value': '13.2', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'pg'}\n",
      "\n",
      "--- ì°¨ì´: gpt-4o vs gpt-4.1-mini ---\n",
      "- idx 4 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'NEUT', 'value': '18.065', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'NEUT', 'value': '18.065', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': '18.065 KuL'}\n",
      "- idx 5 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'LYMPH', 'value': '1.78', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'LYMPH', 'value': '1.78', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': '1.78 KuL'}\n",
      "- idx 6 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'MONO', 'value': '0.569', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'MONO', 'value': '0.569', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': '0.569 KuL'}\n",
      "- idx 7 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'EOS', 'value': '0.189', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'EOS', 'value': '0.189', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': '0.189 KuL'}\n",
      "- idx 9 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'PLT', 'value': '305', 'reference_min': '151', 'reference_max': '600', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'PLT', 'value': '305', 'reference_min': '151', 'reference_max': '600', 'unit': '305 KuL'}\n",
      "- idx 13 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'RETHGB', 'value': 'UNKNOWN', 'reference_min': '13.2', 'reference_max': '20.8', 'unit': 'pg'}\n",
      "  gpt-4.1-mini: {'code': 'RETHGB', 'value': '13.2', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'pg'}\n",
      "gpt-4.1-mini: 7107.2 ms, tests=14\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "gpt-4o: 6409.3 ms, tests=14\n",
      "gpt-4o-mini: 11855.6 ms, tests=14\n",
      "gpt-4.1-mini: 7107.2 ms, tests=14\n",
      "\n",
      "--- ì°¨ì´: gpt-4o vs gpt-4o-mini ---\n",
      "- idx 3 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'BASO (%)', 'value': 'UNKNOWN', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': '%'}\n",
      "  gpt-4o-mini: {'code': 'BASO (%)', 'value': 'UNKNOWN', 'reference_min': '0.01', 'reference_max': '0.26', 'unit': 'UNKNOWN'}\n",
      "- idx 4 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'NEUT', 'value': '18.065', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'NEUT', 'value': '1.15', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': 'UNKNOWN'}\n",
      "- idx 5 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'LYMPH', 'value': '1.78', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'LYMPH', 'value': '0.92', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': 'UNKNOWN'}\n",
      "- idx 6 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'MONO', 'value': '0.569', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'MONO', 'value': '0.05', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': 'UNKNOWN'}\n",
      "- idx 7 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'EOS', 'value': '0.189', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'EOS', 'value': '0.17', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': 'UNKNOWN'}\n",
      "- idx 8 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'BASO', 'value': 'UNKNOWN', 'reference_min': '0.01', 'reference_max': '0.26', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'BASO', 'value': '0.01', 'reference_min': '0.01', 'reference_max': '0.26', 'unit': 'KuL'}\n",
      "- idx 9 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'PLT', 'value': '305', 'reference_min': '151', 'reference_max': '600', 'unit': 'KuL'}\n",
      "  gpt-4o-mini: {'code': 'PLT', 'value': '151', 'reference_min': '151', 'reference_max': '600', 'unit': 'UNKNOWN'}\n",
      "- idx 11 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'PDV', 'value': 'UNKNOWN', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'fL'}\n",
      "  gpt-4o-mini: {'code': 'PDV', 'value': 'UNKNOWN', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'UNKNOWN'}\n",
      "- idx 13 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'RETHGB', 'value': 'UNKNOWN', 'reference_min': '13.2', 'reference_max': '20.8', 'unit': 'pg'}\n",
      "  gpt-4o-mini: {'code': 'RETHGB', 'value': '13.2', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'pg'}\n",
      "\n",
      "--- ì°¨ì´: gpt-4o vs gpt-4.1-mini ---\n",
      "- idx 4 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'NEUT', 'value': '18.065', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'NEUT', 'value': '18.065', 'reference_min': '1.15', 'reference_max': '10.29', 'unit': '18.065 KuL'}\n",
      "- idx 5 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'LYMPH', 'value': '1.78', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'LYMPH', 'value': '1.78', 'reference_min': '0.92', 'reference_max': '6.38', 'unit': '1.78 KuL'}\n",
      "- idx 6 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'MONO', 'value': '0.569', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'MONO', 'value': '0.569', 'reference_min': '0.05', 'reference_max': '0.67', 'unit': '0.569 KuL'}\n",
      "- idx 7 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'EOS', 'value': '0.189', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'EOS', 'value': '0.189', 'reference_min': '0.17', 'reference_max': '1.57', 'unit': '0.189 KuL'}\n",
      "- idx 9 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'PLT', 'value': '305', 'reference_min': '151', 'reference_max': '600', 'unit': 'KuL'}\n",
      "  gpt-4.1-mini: {'code': 'PLT', 'value': '305', 'reference_min': '151', 'reference_max': '600', 'unit': '305 KuL'}\n",
      "- idx 13 ë‹¤ë¦„:\n",
      "  gpt-4o: {'code': 'RETHGB', 'value': 'UNKNOWN', 'reference_min': '13.2', 'reference_max': '20.8', 'unit': 'pg'}\n",
      "  gpt-4.1-mini: {'code': 'RETHGB', 'value': '13.2', 'reference_min': 'UNKNOWN', 'reference_max': 'UNKNOWN', 'unit': 'pg'}\n"
     ]
    }
   ],
   "source": [
    "# ë¹„êµ ì‹¤í–‰: gpt-4o(ê¸°ì¤€) 1íšŒë§Œ ì‹¤í–‰í•˜ê³ , gpt-4o-mini/4.1-miniì™€ ê°ê° ë¹„êµ\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# ì…ë ¥ì€ ë™ì¼í•˜ê²Œ ìœ ì§€\n",
    "_tokens = copy.deepcopy(ocr_data)\n",
    "\n",
    "# ê¸°ì¤€ ëª¨ë¸ì€ í•œ ë²ˆë§Œ ì‹¤í–‰\n",
    "baseline_label = \"gpt-4o\"\n",
    "baseline_model = \"gpt-4o\"\n",
    "\n",
    "# ë¹„êµ ëŒ€ìƒì€ ë‘ ê°œë§Œ: 4o-mini, 4.1-mini\n",
    "compare_cases = [\n",
    "    (\"gpt-4o-mini\", \"gpt-4o-mini\"),\n",
    "    (\"gpt-4.1-mini\", \"gpt-4.1-mini\"),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1) ê¸°ì¤€(gpt-4o) 1íšŒ ì‹¤í–‰\n",
    "start = time.perf_counter()\n",
    "baseline_out = analyze_medical_ocr_data_with_llm(_tokens, model=baseline_model)\n",
    "baseline_ms = (time.perf_counter() - start) * 1000.0\n",
    "results[baseline_label] = {\"ms\": baseline_ms, \"output\": baseline_out}\n",
    "\n",
    "# 2) ë¹„êµ ëŒ€ìƒ ê°ê° 1íšŒ ì‹¤í–‰\n",
    "for label, model in compare_cases:\n",
    "    start = time.perf_counter()\n",
    "    out = analyze_medical_ocr_data_with_llm(_tokens, model=model)\n",
    "    dur = (time.perf_counter() - start) * 1000.0\n",
    "    results[label] = {\"ms\": dur, \"output\": out}\n",
    "\n",
    "# ê°„ë‹¨ ë¹„êµ í•¨ìˆ˜ë“¤\n",
    "\n",
    "def _normalize_test_item(t):\n",
    "    return {\n",
    "        \"code\": t.get(\"code\"),\n",
    "        \"value\": t.get(\"value\"),\n",
    "        \"reference_min\": t.get(\"reference_min\"),\n",
    "        \"reference_max\": t.get(\"reference_max\"),\n",
    "        \"unit\": t.get(\"unit\"),\n",
    "    }\n",
    "\n",
    "norm = {k: list(map(_normalize_test_item, v[\"output\"].get(\"tests\", []))) for k, v in results.items()}\n",
    "\n",
    "# ìš”ì•½ì€ í•œ ë²ˆë§Œ ì¶œë ¥\n",
    "print(\"=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "ordered_labels = [baseline_label] + [lbl for lbl, _ in compare_cases]\n",
    "for k in ordered_labels:\n",
    "    v = results[k]\n",
    "    print(f\"{k}: {v['ms']:.1f} ms, tests={len(v['output'].get('tests', []))}\")\n",
    "\n",
    "# ìŒë³„ ì°¨ì´ ë¹„êµ (4o vs 4o-mini, 4o vs 4.1-mini)\n",
    "\n",
    "def _diff_pair(a_label, b_label):\n",
    "    print(f\"\\n--- ì°¨ì´: {a_label} vs {b_label} ---\")\n",
    "    a_tests = norm.get(a_label, [])\n",
    "    b_tests = norm.get(b_label, [])\n",
    "    max_len = max(len(a_tests), len(b_tests))\n",
    "    diff_count = 0\n",
    "    for i in range(max_len):\n",
    "        a_item = a_tests[i] if i < len(a_tests) else None\n",
    "        b_item = b_tests[i] if i < len(b_tests) else None\n",
    "        if a_item != b_item:\n",
    "            diff_count += 1\n",
    "            print(f\"- idx {i} ë‹¤ë¦„:\\n  {a_label}: {a_item}\\n  {b_label}: {b_item}\")\n",
    "    if diff_count == 0:\n",
    "        print(\"(ì°¨ì´ ì—†ìŒ)\")\n",
    "\n",
    "_diff_pair(\"gpt-4o\", \"gpt-4o-mini\")\n",
    "_diff_pair(\"gpt-4o\", \"gpt-4.1-mini\")\n",
    "\n",
    "# í•„ìš” ì‹œ ì „ì²´ JSON ì¶œë ¥ (ì£¼ì„ í•´ì œ)\n",
    "# print(json.dumps(results, ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meow-chat",
   "language": "python",
   "name": "meow-chat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
