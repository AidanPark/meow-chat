{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ¥ ê³ ì–‘ì´ ì˜ë£Œ ë¬¸ì„œ ë¶„ì„ (Tesseract + LayoutParser)\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ `data/ì€ë‚´ê³¼.pdf` íŒŒì¼ì„ Tesseract + LayoutParserë¡œ ë¶„ì„í•˜ì—¬ ì˜ë£Œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
                "\n",
                "## ì£¼ìš” ê¸°ëŠ¥\n",
                "- PDF â†’ ì´ë¯¸ì§€ ë³€í™˜\n",
                "- LayoutParserë¥¼ í†µí•œ ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë¶„ì„\n",
                "- Tesseract OCRì„ í†µí•œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ\n",
                "- ì˜ë£Œ ê²€ì‚¬ ê²°ê³¼ êµ¬ì¡°í™”\n",
                "- JSON í˜•íƒœë¡œ ë°ì´í„° ì €ì¥\n",
                "\n",
                "## PaddleOCRê³¼ì˜ ì°¨ì´ì \n",
                "- **LayoutParser**: ë¬¸ì„œì˜ ë ˆì´ì•„ì›ƒ(í…Œì´ë¸”, í…ìŠ¤íŠ¸ ë¸”ë¡ ë“±)ì„ ë¨¼ì € ë¶„ì„\n",
                "- **Tesseract**: êµ¬ì¡°í™”ëœ ì˜ì—­ë³„ë¡œ ì •í™•í•œ OCR ìˆ˜í–‰\n",
                "- **ë” ì •í™•í•œ í…Œì´ë¸” ì¸ì‹**: ì˜ë£Œ ë¬¸ì„œì˜ í‘œ êµ¬ì¡°ë¥¼ ë” ì˜ íŒŒì•…"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸\n",
                "# sudo apt-get update\n",
                "\n",
                "# Tesseract OCR ë° í•œêµ­ì–´ ì–¸ì–´íŒ© ì„¤ì¹˜\n",
                "# sudo apt-get install tesseract-ocr tesseract-ocr-eng tesseract-ocr-kor\n",
                "\n",
                "# ì„¤ì¹˜ í™•ì¸\n",
                "# tesseract --version\n",
                "# tesseract --list-langs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: PyMuPDF in ./venv/lib/python3.10/site-packages (1.26.4)\n",
                        "Requirement already satisfied: Pillow in ./venv/lib/python3.10/site-packages (11.3.0)\n",
                        "Requirement already satisfied: openai in ./venv/lib/python3.10/site-packages (1.109.1)\n",
                        "Requirement already satisfied: python-dotenv in ./venv/lib/python3.10/site-packages (1.1.1)\n",
                        "Requirement already satisfied: pytesseract in ./venv/lib/python3.10/site-packages (0.3.13)\n",
                        "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.3.2)\n",
                        "Requirement already satisfied: opencv-python in ./venv/lib/python3.10/site-packages (4.12.0.88)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.10/site-packages (from openai) (4.11.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.10/site-packages (from openai) (0.28.1)\n",
                        "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from openai) (0.11.0)\n",
                        "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.10/site-packages (from openai) (2.11.9)\n",
                        "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
                        "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.10/site-packages (from openai) (4.67.1)\n",
                        "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.10/site-packages (from openai) (4.15.0)\n",
                        "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
                        "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
                        "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
                        "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
                        "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.10/site-packages (from pytesseract) (25.0)\n",
                        "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
                        "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
                        "Requirement already satisfied: layoutparser in ./venv/lib/python3.10/site-packages (0.2.0)\n",
                        "Collecting scipy\n",
                        "  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
                        "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from layoutparser) (2.2.6)\n",
                        "Requirement already satisfied: opencv-python in ./venv/lib/python3.10/site-packages (from layoutparser) (4.12.0.88)\n",
                        "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from layoutparser) (2.3.2)\n",
                        "Requirement already satisfied: pillow in ./venv/lib/python3.10/site-packages (from layoutparser) (11.3.0)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from layoutparser) (6.0.2)\n",
                        "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from layoutparser) (2.8.0)\n",
                        "Requirement already satisfied: torchvision in ./venv/lib/python3.10/site-packages (from layoutparser) (0.23.0)\n",
                        "Requirement already satisfied: iopath in ./venv/lib/python3.10/site-packages (from layoutparser) (0.1.10)\n",
                        "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from iopath->layoutparser) (4.67.1)\n",
                        "Requirement already satisfied: typing_extensions in ./venv/lib/python3.10/site-packages (from iopath->layoutparser) (4.15.0)\n",
                        "Requirement already satisfied: portalocker in ./venv/lib/python3.10/site-packages (from iopath->layoutparser) (3.2.0)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->layoutparser) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->layoutparser) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->layoutparser) (2025.2)\n",
                        "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->layoutparser) (1.17.0)\n",
                        "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (3.19.1)\n",
                        "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (1.14.0)\n",
                        "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (3.4.2)\n",
                        "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (3.1.6)\n",
                        "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (2025.9.0)\n",
                        "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.8.93)\n",
                        "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.8.90)\n",
                        "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.8.90)\n",
                        "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (9.10.2.21)\n",
                        "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.8.4.1)\n",
                        "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (11.3.3.83)\n",
                        "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (10.3.9.90)\n",
                        "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (11.7.3.90)\n",
                        "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.5.8.93)\n",
                        "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (0.7.1)\n",
                        "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (2.27.3)\n",
                        "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.8.90)\n",
                        "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (12.8.93)\n",
                        "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (1.13.1.3)\n",
                        "Requirement already satisfied: triton==3.4.0 in ./venv/lib/python3.10/site-packages (from torch->layoutparser) (3.4.0)\n",
                        "Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from triton==3.4.0->torch->layoutparser) (59.6.0)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->layoutparser) (1.3.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->layoutparser) (3.0.3)\n",
                        "Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
                        "Installing collected packages: scipy\n",
                        "Successfully installed scipy-1.15.3\n",
                        "ğŸ”§ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\n",
                        "âš ï¸ TesseractëŠ” ì‹œìŠ¤í…œ ë ˆë²¨ì—ì„œ ë³„ë„ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
                        "ğŸ’¡ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\n",
                        "   sudo apt-get update\n",
                        "   sudo apt-get install tesseract-ocr tesseract-ocr-eng tesseract-ocr-kor\n"
                    ]
                }
            ],
            "source": [
                "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
                "!pip install PyMuPDF Pillow openai python-dotenv pytesseract pandas opencv-python\n",
                "\n",
                "# LayoutParser ì„¤ì¹˜ (Detectron2 ì—†ì´)\n",
                "!pip install layoutparser scipy\n",
                "\n",
                "# Detectron2ëŠ” ë³„ë„ë¡œ ì„¤ì¹˜ (ì˜µì…˜)\n",
                "# !pip install torch torchvision\n",
                "# !pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
                "\n",
                "print(\"ğŸ”§ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
                "print(\"âš ï¸ TesseractëŠ” ì‹œìŠ¤í…œ ë ˆë²¨ì—ì„œ ë³„ë„ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
                "print(\"ğŸ’¡ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
                "print(\"   sudo apt-get update\")\n",
                "print(\"   sudo apt-get install tesseract-ocr tesseract-ocr-eng tesseract-ocr-kor\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\n",
                        "ğŸ” Tesseract ë²„ì „: 4.1.1\n",
                        "ğŸ“Š LayoutParser ë²„ì „: 0.2.0\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import base64\n",
                "import json\n",
                "from typing import List, Dict, Any, Tuple\n",
                "import fitz  # PyMuPDF\n",
                "from PIL import Image, ImageEnhance, ImageFilter\n",
                "import io\n",
                "from dotenv import load_dotenv\n",
                "from openai import OpenAI\n",
                "import pandas as pd\n",
                "from IPython.display import display\n",
                "import re\n",
                "from datetime import datetime\n",
                "import numpy as np\n",
                "import cv2\n",
                "\n",
                "# Tesseract ë° LayoutParser\n",
                "import pytesseract\n",
                "import layoutparser as lp\n",
                "from layoutparser.models import Detectron2LayoutModel\n",
                "from layoutparser.elements import TextBlock, Rectangle\n",
                "\n",
                "print(\"ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")\n",
                "print(f\"ğŸ” Tesseract ë²„ì „: {pytesseract.get_tesseract_version()}\")\n",
                "print(f\"ğŸ“Š LayoutParser ë²„ì „: {lp.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. PDF ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ”§ PDF ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
                    ]
                }
            ],
            "source": [
                "def pdf_to_images(pdf_path: str, resolution_scale: float = 2.0) -> List[np.ndarray]:\n",
                "    \"\"\"PDFë¥¼ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (OCR ìµœì í™”)\"\"\"\n",
                "    doc = fitz.open(pdf_path)\n",
                "    images = []\n",
                "    \n",
                "    print(f\"ğŸ“„ PDF í˜ì´ì§€ ìˆ˜: {len(doc)}\")\n",
                "    print(f\"âš™ï¸ í•´ìƒë„ ìŠ¤ì¼€ì¼: {resolution_scale}x\")\n",
                "    \n",
                "    for page_num in range(len(doc)):\n",
                "        page = doc.load_page(page_num)\n",
                "        \n",
                "        # ê³ í’ˆì§ˆ ë³€í™˜ì„ ìœ„í•œ ë§¤íŠ¸ë¦­ìŠ¤ ì„¤ì •\n",
                "        mat = fitz.Matrix(resolution_scale, resolution_scale)\n",
                "        \n",
                "        # ê³ í’ˆì§ˆ í”½ìŠ¤ë§µ ìƒì„±\n",
                "        pix = page.get_pixmap(\n",
                "            matrix=mat,\n",
                "            alpha=False,\n",
                "            annots=True,\n",
                "            clip=None\n",
                "        )\n",
                "        \n",
                "        # NumPy ë°°ì—´ë¡œ ë³€í™˜ (LayoutParser í˜¸í™˜)\n",
                "        img_data = pix.tobytes(\"png\")\n",
                "        img = Image.open(io.BytesIO(img_data))\n",
                "        img_array = np.array(img)\n",
                "        \n",
                "        # BGRë¡œ ë³€í™˜ (OpenCV í˜¸í™˜)\n",
                "        if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n",
                "            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
                "        \n",
                "        images.append(img_array)\n",
                "        \n",
                "        # ì´ë¯¸ì§€ ì •ë³´ ì¶œë ¥\n",
                "        size_mb = len(img_data) / (1024 * 1024)\n",
                "        print(f\"  ğŸ“‘ í˜ì´ì§€ {page_num + 1}:\")\n",
                "        print(f\"     ğŸ“ í”½ì…€ í¬ê¸°: {img_array.shape[1]} x {img_array.shape[0]}\")\n",
                "        print(f\"     ğŸ’¾ íŒŒì¼ í¬ê¸°: {len(img_data):,} bytes ({size_mb:.1f}MB)\")\n",
                "        print(f\"     ğŸ¨ ì±„ë„: {img_array.shape[2] if len(img_array.shape) == 3 else 1}\")\n",
                "        \n",
                "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
                "        pix = None\n",
                "    \n",
                "    doc.close()\n",
                "    return images\n",
                "\n",
                "def preprocess_image_for_ocr(image: np.ndarray) -> np.ndarray:\n",
                "    \"\"\"OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬\"\"\"\n",
                "    \n",
                "    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
                "    if len(image.shape) == 3:\n",
                "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
                "    else:\n",
                "        gray = image.copy()\n",
                "    \n",
                "    # ë…¸ì´ì¦ˆ ì œê±°\n",
                "    denoised = cv2.medianBlur(gray, 3)\n",
                "    \n",
                "    # ëŒ€ë¹„ í–¥ìƒ\n",
                "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
                "    enhanced = clahe.apply(denoised)\n",
                "    \n",
                "    # ì´ì§„í™” (ì ì‘í˜• ì„ê³„ê°’)\n",
                "    binary = cv2.adaptiveThreshold(\n",
                "        enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
                "    )\n",
                "    \n",
                "    # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì •ë¦¬\n",
                "    kernel = np.ones((1,1), np.uint8)\n",
                "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
                "    \n",
                "    return cleaned\n",
                "\n",
                "def save_image_preview(image: np.ndarray, filename: str):\n",
                "    \"\"\"ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ì €ì¥\"\"\"\n",
                "    # BGRì„ RGBë¡œ ë³€í™˜ í›„ PIL Imageë¡œ ë³€í™˜\n",
                "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
                "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "        pil_image = Image.fromarray(rgb_image)\n",
                "    else:\n",
                "        pil_image = Image.fromarray(image)\n",
                "    \n",
                "    # ë¯¸ë¦¬ë³´ê¸°ìš© í¬ê¸° ì¡°ì •\n",
                "    pil_image.thumbnail((800, 800))\n",
                "    pil_image.save(filename)\n",
                "    print(f\"ğŸ–¼ï¸ ë¯¸ë¦¬ë³´ê¸° ì €ì¥: {filename}\")\n",
                "\n",
                "print(\"ğŸ”§ PDF ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. LayoutParser ëª¨ë¸ ì´ˆê¸°í™”"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ¤– LayoutParser ëª¨ë¸ ë¡œë”© ì¤‘...\n",
                        "âŒ LayoutParser ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: No module named 'detectron2'\n",
                        "ğŸ’¡ ëŒ€ì•ˆ: TableBank ëª¨ë¸ ì‹œë„...\n",
                        "âŒ TableBank ëª¨ë¸ë„ ì‹¤íŒ¨: No module named 'detectron2'\n",
                        "âš ï¸ LayoutParser ì—†ì´ Tesseractë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
                    ]
                }
            ],
            "source": [
                "def initialize_layout_model():\n",
                "    \"\"\"LayoutParser ëª¨ë¸ ì´ˆê¸°í™”\"\"\"\n",
                "    \n",
                "    print(\"ğŸ¤– LayoutParser ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
                "    \n",
                "    try:\n",
                "        # PubLayNet ëª¨ë¸ ì‚¬ìš© (ë…¼ë¬¸/ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë¶„ì„ì— ìµœì í™”)\n",
                "        model = lp.Detectron2LayoutModel(\n",
                "            config_path='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
                "            model_path='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/model_final.pth',\n",
                "            extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],  # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
                "            label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n",
                "        )\n",
                "        \n",
                "        print(\"âœ… LayoutParser ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
                "        print(\"ğŸ“Š ì§€ì› ë ˆì´ì•„ì›ƒ ìš”ì†Œ: Text, Title, List, Table, Figure\")\n",
                "        \n",
                "        return model\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"âŒ LayoutParser ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
                "        print(\"ğŸ’¡ ëŒ€ì•ˆ: TableBank ëª¨ë¸ ì‹œë„...\")\n",
                "        \n",
                "        try:\n",
                "            # TableBank ëª¨ë¸ë¡œ ëŒ€ì²´ ì‹œë„ (í…Œì´ë¸” íŠ¹í™”)\n",
                "            model = lp.Detectron2LayoutModel(\n",
                "                config_path='lp://TableBank/faster_rcnn_R_50_FPN_3x/config',\n",
                "                model_path='lp://TableBank/faster_rcnn_R_50_FPN_3x/model_final.pth',\n",
                "                extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
                "                label_map={0: \"Table\"}\n",
                "            )\n",
                "            print(\"âœ… TableBank ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
                "            return model\n",
                "            \n",
                "        except Exception as e2:\n",
                "            print(f\"âŒ TableBank ëª¨ë¸ë„ ì‹¤íŒ¨: {e2}\")\n",
                "            print(\"âš ï¸ LayoutParser ì—†ì´ Tesseractë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
                "            return None\n",
                "\n",
                "# ëª¨ë¸ ì´ˆê¸°í™”\n",
                "layout_model = initialize_layout_model()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. PDF ì´ë¯¸ì§€ ë³€í™˜ ë° ë¯¸ë¦¬ë³´ê¸°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“‚ íŒŒì¼ ì„ íƒ (PDF ë˜ëŠ” ì´ë¯¸ì§€)\n",
                        "========================================\n",
                        "ğŸ”¹ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: ì€ë‚´ê³¼.PDF\n",
                        "ğŸ“ íŒŒì¼ ê²½ë¡œ: data/ì€ë‚´ê³¼.PDF\n",
                        "ğŸ“‹ íŒŒì¼ í˜•ì‹: PDF\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'os' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“‹ íŒŒì¼ í˜•ì‹: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_ext\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# output í´ë” ìƒì„±\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pdf:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# PDF ì²˜ë¦¬\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
                    ]
                }
            ],
            "source": [
                "print(\"ğŸ“‚ íŒŒì¼ ì„ íƒ (PDF ë˜ëŠ” ì´ë¯¸ì§€)\")\n",
                "print(\"=\" * 40)\n",
                "\n",
                "# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (data/ í´ë” ê¸°ë³¸ ê²½ë¡œ)\n",
                "filename = input(\"ğŸ“„ data/ í´ë” ë‚´ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì€ë‚´ê³¼.PDF, ê²€ì‚¬ê²°ê³¼.png): \").strip()\n",
                "\n",
                "# ë¹ˆ ì…ë ¥ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
                "if not filename:\n",
                "    filename = \"ì€ë‚´ê³¼.PDF\"\n",
                "    print(f\"ğŸ”¹ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {filename}\")\n",
                "\n",
                "# data/ ê²½ë¡œì™€ ê²°í•©\n",
                "file_path = f\"data/{filename}\"\n",
                "print(f\"ğŸ“ íŒŒì¼ ê²½ë¡œ: {file_path}\")\n",
                "\n",
                "# íŒŒì¼ í™•ì¥ì í™•ì¸\n",
                "file_ext = filename.lower().split('.')[-1]\n",
                "is_pdf = file_ext == 'pdf'\n",
                "is_image = file_ext in ['png', 'jpg', 'jpeg', 'tiff', 'bmp']\n",
                "\n",
                "print(f\"ğŸ“‹ íŒŒì¼ í˜•ì‹: {file_ext.upper()}\")\n",
                "\n",
                "# output í´ë” ìƒì„±\n",
                "os.makedirs(\"output\", exist_ok=True)\n",
                "\n",
                "if is_pdf:\n",
                "    # PDF ì²˜ë¦¬\n",
                "    print(\"ğŸ”„ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘...\")\n",
                "    pdf_images = pdf_to_images(file_path, resolution_scale=2.0)\n",
                "    \n",
                "    # ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ì €ì¥\n",
                "    for i, img_array in enumerate(pdf_images):\n",
                "        save_image_preview(img_array, f\"output/page_{i+1}_preview.png\")\n",
                "    \n",
                "    print(f\"âœ… PDF ë³€í™˜ ì™„ë£Œ! {len(pdf_images)}ê°œ í˜ì´ì§€ ì²˜ë¦¬ë¨\")\n",
                "\n",
                "elif is_image:\n",
                "    # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬\n",
                "    print(\"ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ ì¤‘...\")\n",
                "    \n",
                "    # OpenCVë¡œ ì´ë¯¸ì§€ ë¡œë“œ\n",
                "    img_array = cv2.imread(file_path)\n",
                "    \n",
                "    if img_array is None:\n",
                "        # PILë¡œ ì¬ì‹œë„\n",
                "        pil_img = Image.open(file_path)\n",
                "        img_array = np.array(pil_img)\n",
                "        if len(img_array.shape) == 3:\n",
                "            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
                "    \n",
                "    # ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸°\n",
                "    pdf_images = [img_array]\n",
                "    \n",
                "    # ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ì €ì¥\n",
                "    save_image_preview(img_array, \"output/image_preview.png\")\n",
                "    \n",
                "    print(f\"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ! 1ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ë¨\")\n",
                "\n",
                "else:\n",
                "    print(f\"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_ext}\")\n",
                "    print(\"ğŸ“‹ ì§€ì› í˜•ì‹: PDF, PNG, JPG, JPEG, TIFF, BMP\")\n",
                "    pdf_images = []\n",
                "\n",
                "if pdf_images:\n",
                "    print(f\"ğŸ¯ ì´ {len(pdf_images)}ê°œ ì´ë¯¸ì§€ê°€ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
                "    print(\"ğŸ“‹ ë‹¤ìŒ ì„¹ì…˜(LayoutParser + Tesseract ë¶„ì„)ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
                "else:\n",
                "    print(\"âš ï¸ ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. LayoutParser + Tesseractë¥¼ ì´ìš©í•œ ë°ì´í„° ì¶”ì¶œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ”§ LayoutParser + Tesseract ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
                    ]
                }
            ],
            "source": [
                "def extract_medical_data_with_layoutparser_tesseract(image: np.ndarray, page_num: int = 0) -> pd.DataFrame:\n",
                "    \"\"\"LayoutParser + Tesseractë¡œ í˜ˆì•¡ê²€ì‚¬ ë°ì´í„° ì¶”ì¶œ ë° DataFrame ë°˜í™˜\"\"\"\n",
                "    \n",
                "    print(f\"ğŸ” LayoutParser + Tesseractë¡œ í˜ì´ì§€ {page_num + 1} ë¶„ì„ ì¤‘...\")\n",
                "    \n",
                "    try:\n",
                "        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
                "        processed_image = preprocess_image_for_ocr(image)\n",
                "        \n",
                "        # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ (ë””ë²„ê¹…ìš©)\n",
                "        cv2.imwrite(f\"output/processed_page_{page_num + 1}.png\", processed_image)\n",
                "        print(f\"ğŸ’¾ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ì €ì¥: output/processed_page_{page_num + 1}.png\")\n",
                "        \n",
                "        all_texts = []\n",
                "        layout_results = []\n",
                "        \n",
                "        # LayoutParserë¡œ ë ˆì´ì•„ì›ƒ ë¶„ì„ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)\n",
                "        if layout_model is not None:\n",
                "            print(\"ğŸ“Š LayoutParserë¡œ ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì¤‘...\")\n",
                "            \n",
                "            # RGB ì´ë¯¸ì§€ë¡œ ë³€í™˜ (LayoutParser ìš”êµ¬ì‚¬í•­)\n",
                "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "            \n",
                "            # ë ˆì´ì•„ì›ƒ ê°ì§€\n",
                "            layout = layout_model.detect(rgb_image)\n",
                "            \n",
                "            print(f\"ğŸ“‹ ê°ì§€ëœ ë ˆì´ì•„ì›ƒ ìš”ì†Œ: {len(layout)}ê°œ\")\n",
                "            \n",
                "            # ê° ë ˆì´ì•„ì›ƒ ìš”ì†Œë³„ë¡œ OCR ìˆ˜í–‰\n",
                "            for idx, block in enumerate(layout):\n",
                "                block_type = block.type\n",
                "                coords = block.coordinates\n",
                "                \n",
                "                print(f\"  ğŸ“¦ ìš”ì†Œ {idx+1}: {block_type} at {coords}\")\n",
                "                \n",
                "                # ì˜ì—­ ì¶”ì¶œ\n",
                "                x1, y1, x2, y2 = map(int, [coords[0], coords[1], coords[2], coords[3]])\n",
                "                \n",
                "                # ê²½ê³„ ì²´í¬\n",
                "                x1 = max(0, x1)\n",
                "                y1 = max(0, y1)\n",
                "                x2 = min(processed_image.shape[1], x2)\n",
                "                y2 = min(processed_image.shape[0], y2)\n",
                "                \n",
                "                if x2 > x1 and y2 > y1:\n",
                "                    roi = processed_image[y1:y2, x1:x2]\n",
                "                    \n",
                "                    # Tesseract OCR ìˆ˜í–‰\n",
                "                    if block_type == \"Table\":\n",
                "                        # í…Œì´ë¸”ì˜ ê²½ìš° ë” ì„¸ë°€í•œ ì„¤ì •\n",
                "                        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzê°€-í£.,/%-:()[]'\n",
                "                    else:\n",
                "                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì„¤ì •\n",
                "                        custom_config = r'--oem 3 --psm 6'\n",
                "                    \n",
                "                    try:\n",
                "                        # í•œêµ­ì–´ + ì˜ì–´ OCR\n",
                "                        text = pytesseract.image_to_string(\n",
                "                            roi, \n",
                "                            lang='kor+eng',\n",
                "                            config=custom_config\n",
                "                        ).strip()\n",
                "                        \n",
                "                        if text:\n",
                "                            all_texts.extend(text.split('\\n'))\n",
                "                            layout_results.append({\n",
                "                                'type': block_type,\n",
                "                                'bbox': (x1, y1, x2, y2),\n",
                "                                'text': text\n",
                "                            })\n",
                "                            print(f\"    ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ({len(text)} chars): {text[:50]}...\")\n",
                "                        \n",
                "                    except Exception as ocr_error:\n",
                "                        print(f\"    âŒ OCR ì˜¤ë¥˜: {ocr_error}\")\n",
                "        \n",
                "        else:\n",
                "            # LayoutParser ì—†ì´ Tesseractë§Œ ì‚¬ìš©\n",
                "            print(\"ğŸ”¤ Tesseractë§Œìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ OCR ìˆ˜í–‰...\")\n",
                "            \n",
                "            custom_config = r'--oem 3 --psm 6'\n",
                "            \n",
                "            try:\n",
                "                # í•œêµ­ì–´ + ì˜ì–´ OCR\n",
                "                full_text = pytesseract.image_to_string(\n",
                "                    processed_image, \n",
                "                    lang='kor+eng',\n",
                "                    config=custom_config\n",
                "                ).strip()\n",
                "                \n",
                "                if full_text:\n",
                "                    all_texts = full_text.split('\\n')\n",
                "                    print(f\"ğŸ“ ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜: {len(all_texts)}\")\n",
                "                \n",
                "            except Exception as ocr_error:\n",
                "                print(f\"âŒ Tesseract OCR ì˜¤ë¥˜: {ocr_error}\")\n",
                "                all_texts = []\n",
                "        \n",
                "        # ë¹ˆ ë¼ì¸ ì œê±° ë° ì •ë¦¬\n",
                "        cleaned_texts = [text.strip() for text in all_texts if text.strip()]\n",
                "        \n",
                "        print(f\"ğŸ“ ì •ë¦¬ëœ í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜: {len(cleaned_texts)}\")\n",
                "        \n",
                "        # ë””ë²„ê¹…ìš©: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì¼ë¶€ ì¶œë ¥\n",
                "        print(\"ğŸ” ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\")\n",
                "        for i, text in enumerate(cleaned_texts[:10]):  # ì²˜ìŒ 10ì¤„ë§Œ\n",
                "            print(f\"  {i+1}: {text}\")\n",
                "        \n",
                "        if len(cleaned_texts) > 10:\n",
                "            print(f\"  ... (ì´ {len(cleaned_texts)}ì¤„ ì¤‘ 10ì¤„ë§Œ í‘œì‹œ)\")\n",
                "        \n",
                "        # ê²€ì‚¬ì¼ì‹œ ì¶”ì¶œ\n",
                "        exam_date = extract_exam_date(cleaned_texts)\n",
                "        print(f\"ğŸ“… ê²€ì‚¬ì¼ì‹œ: {exam_date}\")\n",
                "        \n",
                "        # í˜ˆì•¡ê²€ì‚¬ ë°ì´í„° ì¶”ì¶œ\n",
                "        blood_tests = extract_blood_test_data(cleaned_texts)\n",
                "        \n",
                "        # DataFrame ìƒì„±\n",
                "        if blood_tests:\n",
                "            df = pd.DataFrame(blood_tests)\n",
                "            df.attrs['exam_date'] = exam_date\n",
                "            df.attrs['layout_results'] = layout_results\n",
                "            \n",
                "            print(\"âœ… LayoutParser + Tesseractë¡œ ì¶”ì¶œëœ í˜ˆì•¡ê²€ì‚¬ ë°ì´í„°:\")\n",
                "            display(df)\n",
                "            print(f\"\\nğŸ“ˆ ì´ {len(df)}ê°œ í˜ˆì•¡ê²€ì‚¬ í•­ëª© ì¶”ì¶œë¨\")\n",
                "            \n",
                "            return df\n",
                "        else:\n",
                "            print(\"âš ï¸ í˜ˆì•¡ê²€ì‚¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "            empty_df = pd.DataFrame(columns=[\"í˜ˆì•¡í•­ëª©\", \"ì¸¡ì •ê°’\", \"ë‹¨ìœ„\"])\n",
                "            empty_df.attrs['exam_date'] = exam_date\n",
                "            empty_df.attrs['layout_results'] = layout_results\n",
                "            return empty_df\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"âŒ LayoutParser + Tesseract ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
                "        import traceback\n",
                "        print(f\"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}\")\n",
                "        empty_df = pd.DataFrame(columns=[\"í˜ˆì•¡í•­ëª©\", \"ì¸¡ì •ê°’\", \"ë‹¨ìœ„\"])\n",
                "        empty_df.attrs['exam_date'] = \"Not Found\"\n",
                "        empty_df.attrs['layout_results'] = []\n",
                "        return empty_df\n",
                "\n",
                "def extract_exam_date(texts: List[str]) -> str:\n",
                "    \"\"\"í…ìŠ¤íŠ¸ì—ì„œ ê²€ì‚¬ì¼ì‹œ ì¶”ì¶œ (ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì§€ì›)\"\"\"\n",
                "    \n",
                "    # ë‚ ì§œ íŒ¨í„´ ì •ì˜ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
                "    date_patterns = [\n",
                "        r'\\b(20\\d{2}[-:/]\\d{1,2}[-:/]\\d{1,2})\\b',  # yyyy-mm-dd, yyyy/mm/dd, yyyy:mm:dd\n",
                "        r'\\b(\\d{2}[-:/]\\d{1,2}[-:/]\\d{1,2})\\b',    # yy-mm-dd, yy/mm/dd, yy:mm:dd\n",
                "        r'\\b(20\\d{2}\\.\\d{1,2}\\.\\d{1,2})\\b',       # yyyy.mm.dd\n",
                "        r'\\b(\\d{2}\\.\\d{1,2}\\.\\d{1,2})\\b',         # yy.mm.dd\n",
                "        r'\\b(20\\d{2}\\s+\\d{1,2}\\s+\\d{1,2})\\b',     # yyyy mm dd (ê³µë°±)\n",
                "        r'\\b(\\d{2}\\s+\\d{1,2}\\s+\\d{1,2})\\b'        # yy mm dd (ê³µë°±)\n",
                "    ]\n",
                "    \n",
                "    found_dates = []\n",
                "    \n",
                "    for text in texts:\n",
                "        # ìƒë…„ì›”ì¼ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ëŠ” ì œì™¸\n",
                "        birth_keywords = ['ìƒì¼', 'ìƒë…„ì›”ì¼', 'Birth', 'DOB', 'Born', 'ì¶œìƒ']\n",
                "        if any(keyword in text for keyword in birth_keywords):\n",
                "            continue\n",
                "            \n",
                "        # ê²€ì‚¬ì¼ì‹œ ê´€ë ¨ í‚¤ì›Œë“œ ìš°ì„  ê²€ìƒ‰\n",
                "        exam_keywords = ['ê²€ì‚¬ì¼ì‹œ', 'ê²€ì‚¬ë‚ ì§œ', 'Date', 'Time', 'ì¼ì‹œ']\n",
                "        is_exam_date_line = any(keyword in text for keyword in exam_keywords)\n",
                "        \n",
                "        for pattern in date_patterns:\n",
                "            matches = re.findall(pattern, text)\n",
                "            for match in matches:\n",
                "                try:\n",
                "                    # ë‚ ì§œ í˜•ì‹ ì •ê·œí™”\n",
                "                    normalized_date = normalize_date(match)\n",
                "                    if normalized_date:\n",
                "                        # ê²€ì‚¬ì¼ì‹œ ë¼ë²¨ì´ ìˆëŠ” ê²½ìš° ìš°ì„ ìˆœìœ„ ë¶€ì—¬\n",
                "                        priority = 1 if is_exam_date_line else 2\n",
                "                        found_dates.append((normalized_date, priority, match))\n",
                "                except:\n",
                "                    continue\n",
                "    \n",
                "    if not found_dates:\n",
                "        return \"Not Found\"\n",
                "    \n",
                "    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬ (ê²€ì‚¬ì¼ì‹œ ë¼ë²¨ì´ ìˆëŠ” ê²ƒ ìš°ì„ , ê·¸ ë‹¤ìŒ ìµœì‹  ë‚ ì§œ)\n",
                "    found_dates.sort(key=lambda x: (x[1], -datetime.strptime(x[0], '%Y-%m-%d').timestamp()))\n",
                "    \n",
                "    return found_dates[0][0]\n",
                "\n",
                "def normalize_date(date_str: str) -> str:\n",
                "    \"\"\"ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ì„ yyyy-mm-ddë¡œ ì •ê·œí™”\"\"\"\n",
                "    \n",
                "    # êµ¬ë¶„ì í†µì¼ (-, /, :, ., ê³µë°±ì„ ëª¨ë‘ -ë¡œ)\n",
                "    normalized = re.sub(r'[-:/.*+\\s]+', '-', date_str.strip())\n",
                "    \n",
                "    try:\n",
                "        parts = normalized.split('-')\n",
                "        if len(parts) != 3:\n",
                "            return None\n",
                "            \n",
                "        year, month, day = parts\n",
                "        \n",
                "        # 2ìë¦¬ ì—°ë„ë¥¼ 4ìë¦¬ë¡œ ë³€í™˜\n",
                "        if len(year) == 2:\n",
                "            year_int = int(year)\n",
                "            if year_int <= 30:  # 00-30ì€ 2000ë…„ëŒ€\n",
                "                year = f\"20{year}\"\n",
                "            else:  # 31-99ëŠ” 1900ë…„ëŒ€\n",
                "                year = f\"19{year}\"\n",
                "        \n",
                "        # ì›”, ì¼ì„ 2ìë¦¬ë¡œ íŒ¨ë”©\n",
                "        month = month.zfill(2)\n",
                "        day = day.zfill(2)\n",
                "        \n",
                "        # ìœ íš¨í•œ ë‚ ì§œì¸ì§€ ê²€ì¦\n",
                "        datetime.strptime(f\"{year}-{month}-{day}\", '%Y-%m-%d')\n",
                "        \n",
                "        return f\"{year}-{month}-{day}\"\n",
                "        \n",
                "    except (ValueError, IndexError):\n",
                "        return None\n",
                "\n",
                "def extract_blood_test_data(texts: List[str]) -> List[Dict[str, str]]:\n",
                "    \"\"\"í…ìŠ¤íŠ¸ì—ì„œ í˜ˆì•¡ê²€ì‚¬ ë°ì´í„° ì¶”ì¶œ\"\"\"\n",
                "    \n",
                "    # í˜ˆì•¡ê²€ì‚¬ í•­ëª© íŒ¨í„´ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ìŒ)\n",
                "    blood_test_patterns = {\n",
                "        'RBC': r'\\b(RBC|ì í˜ˆêµ¬)\\b',\n",
                "        'WBC': r'\\b(WBC|ë°±í˜ˆêµ¬)\\b',\n",
                "        'HGB': r'\\b(HGB|HB|í—¤ëª¨ê¸€ë¡œë¹ˆ|í˜ˆìƒ‰ì†Œ)\\b',\n",
                "        'HCT': r'\\b(HCT|í—¤ë§ˆí† í¬ë¦¬íŠ¸)\\b',\n",
                "        'PLT': r'\\b(PLT|í˜ˆì†ŒíŒ)\\b',\n",
                "        'MCV': r'\\b(MCV)\\b',\n",
                "        'MCH': r'\\b(MCH)\\b',\n",
                "        'MCHC': r'\\b(MCHC)\\b',\n",
                "        'GLU': r'\\b(GLU|í¬ë„ë‹¹|í˜ˆë‹¹)\\b',\n",
                "        'CREA': r'\\b(CREA|í¬ë ˆì•„í‹°ë‹Œ)\\b',\n",
                "        'BUN': r'\\b(BUN|ìš”ì†Œì§ˆì†Œ)\\b',\n",
                "        'ALT': r'\\b(ALT|GPT)\\b',\n",
                "        'AST': r'\\b(AST|GOT)\\b',\n",
                "        'ALP': r'\\b(ALP|ì•Œì¹´ë¦¬í¬ìŠ¤íŒŒíƒ€ì œ)\\b',\n",
                "        'TP': r'\\b(TP|ì´ë‹¨ë°±)\\b',\n",
                "        'ALB': r'\\b(ALB|ì•Œë¶€ë¯¼)\\b'\n",
                "    }\n",
                "    \n",
                "    # ë‹¨ìœ„ íŒ¨í„´\n",
                "    unit_patterns = [\n",
                "        r'\\b(g/dL|mg/dL|Ã—10Â³/Î¼L|Ã—10â¶/Î¼L|/Î¼L|fl|pg|%|U/L|IU/L)\\b',\n",
                "        r'\\b(g/dl|mg/dl|x10Â³/Î¼l|x10â¶/Î¼l|/Î¼l)\\b',\n",
                "        r'\\b(mil/cmm|thou/cmm)\\b'\n",
                "    ]\n",
                "    \n",
                "    blood_tests = []\n",
                "    \n",
                "    # ê° í…ìŠ¤íŠ¸ ë¼ì¸ ë¶„ì„\n",
                "    for text in texts:\n",
                "        text_upper = text.upper()\n",
                "        \n",
                "        # í˜ˆì•¡ê²€ì‚¬ í•­ëª© ì°¾ê¸°\n",
                "        for test_name, pattern in blood_test_patterns.items():\n",
                "            if re.search(pattern, text_upper):\n",
                "                # ìˆ«ì ê°’ ì¶”ì¶œ (ì†Œìˆ˜ì  í¬í•¨)\n",
                "                number_match = re.search(r'\\b(\\d+\\.?\\d*)\\b', text)\n",
                "                if number_match:\n",
                "                    result = number_match.group(1)\n",
                "                    \n",
                "                    # ë‹¨ìœ„ ì¶”ì¶œ\n",
                "                    unit = \"\"\n",
                "                    for unit_pattern in unit_patterns:\n",
                "                        unit_match = re.search(unit_pattern, text)\n",
                "                        if unit_match:\n",
                "                            unit = unit_match.group(1)\n",
                "                            break\n",
                "                    \n",
                "                    blood_tests.append({\n",
                "                        \"í˜ˆì•¡í•­ëª©\": test_name,\n",
                "                        \"ì¸¡ì •ê°’\": result,\n",
                "                        \"ë‹¨ìœ„\": unit\n",
                "                    })\n",
                "                    break\n",
                "    \n",
                "    # ì¤‘ë³µ ì œê±° (ê°™ì€ í•­ëª©ì´ ì—¬ëŸ¬ ë²ˆ ì¶”ì¶œëœ ê²½ìš°)\n",
                "    seen_tests = set()\n",
                "    unique_tests = []\n",
                "    for test in blood_tests:\n",
                "        test_key = test[\"í˜ˆì•¡í•­ëª©\"]\n",
                "        if test_key not in seen_tests:\n",
                "            seen_tests.add(test_key)\n",
                "            unique_tests.append(test)\n",
                "    \n",
                "    return unique_tests\n",
                "\n",
                "print(\"ğŸ”§ LayoutParser + Tesseract ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ì˜ë£Œ ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ” LayoutParser + Tesseract ì˜ë£Œ ë¬¸ì„œ ë¶„ì„ ì‹œì‘...\n",
                        "============================================================\n",
                        "\n",
                        "ğŸ“‘ í˜ì´ì§€ 1 ë¶„ì„ ì¤‘...\n",
                        "----------------------------------------\n",
                        "ğŸ” LayoutParser + Tesseractë¡œ í˜ì´ì§€ 1 ë¶„ì„ ì¤‘...\n",
                        "ğŸ’¾ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ì €ì¥: output/processed_page_1.png\n",
                        "ğŸ”¤ Tesseractë§Œìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ OCR ìˆ˜í–‰...\n",
                        "ğŸ“ ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜: 34\n",
                        "ğŸ“ ì •ë¦¬ëœ í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜: 27\n",
                        "ğŸ” ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\n",
                        "  1: Date/Time: 2025-01-16 2 1:51:10                                         Performed By [ProCyte_DX]\n",
                        "  2: Name                          Unit            Min        Max      Result\n",
                        "  3: RBC                             10x6/uL            654          122         573 ww | 11] | ê·¸\n",
                        "  4: 00                               %               303         523         261 ww [  J][ | ê·¸\n",
                        "  5: HGB                              g/dl               98         162          78 ww [ [J [ | ê·¸\n",
                        "  6: mcv                               ê°œ               35.9         531         ass normal [_ | OF | ê·¸\n",
                        "  7: MCH                              09               118         173         136 normal [ | OD 1 ê³ \n",
                        "  8: MCHC                            g/dl              28.1          358         2g norma [| oO 1 ê·¸\n",
                        "  9: RDW-CV                           %                15           27         37 wich [ | | Jy 4\n",
                        "  10: RETIC%                            %                                        02\n",
                        "  ... (ì´ 27ì¤„ ì¤‘ 10ì¤„ë§Œ í‘œì‹œ)\n",
                        "ğŸ“… ê²€ì‚¬ì¼ì‹œ: 2025-01-16\n",
                        "âœ… LayoutParser + Tesseractë¡œ ì¶”ì¶œëœ í˜ˆì•¡ê²€ì‚¬ ë°ì´í„°:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>í˜ˆì•¡í•­ëª©</th>\n",
                            "      <th>ì¸¡ì •ê°’</th>\n",
                            "      <th>ë‹¨ìœ„</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>RBC</td>\n",
                            "      <td>654</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>HGB</td>\n",
                            "      <td>98</td>\n",
                            "      <td>g/dl</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>MCV</td>\n",
                            "      <td>35.9</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>MCH</td>\n",
                            "      <td>09</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>MCHC</td>\n",
                            "      <td>28.1</td>\n",
                            "      <td>g/dl</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>WBC</td>\n",
                            "      <td>18.5</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>PLT</td>\n",
                            "      <td>151</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   í˜ˆì•¡í•­ëª©   ì¸¡ì •ê°’    ë‹¨ìœ„\n",
                            "0   RBC   654      \n",
                            "1   HGB    98  g/dl\n",
                            "2   MCV  35.9      \n",
                            "3   MCH    09      \n",
                            "4  MCHC  28.1  g/dl\n",
                            "5   WBC  18.5      \n",
                            "6   PLT   151      "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ“ˆ ì´ 7ê°œ í˜ˆì•¡ê²€ì‚¬ í•­ëª© ì¶”ì¶œë¨\n",
                        "ğŸ’¾ ê²°ê³¼ ì €ì¥: output/page_1_layoutparser_tesseract_result.json\n",
                        "âœ… í˜ì´ì§€ 1 ë¶„ì„ ì™„ë£Œ\n",
                        "\n",
                        "ğŸ¯ ì „ì²´ ë¶„ì„ ì™„ë£Œ!\n",
                        "ğŸ“Š ì²˜ë¦¬ëœ í˜ì´ì§€: 1/1\n",
                        "ğŸ’¾ ìµœì¢… ê²°ê³¼: output/final_layoutparser_tesseract_analysis.json\n",
                        "ğŸ§ª ì´ ì¶”ì¶œëœ í˜ˆì•¡ê²€ì‚¬ í•­ëª©: 7ê°œ\n",
                        "ğŸ“… ê²€ì‚¬ì¼ì‹œ: 2025-01-16\n"
                    ]
                }
            ],
            "source": [
                "print(\"ğŸ” LayoutParser + Tesseract ì˜ë£Œ ë¬¸ì„œ ë¶„ì„ ì‹œì‘...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "all_results = []\n",
                "\n",
                "for i, img_array in enumerate(pdf_images):\n",
                "    print(f\"\\nğŸ“‘ í˜ì´ì§€ {i + 1} ë¶„ì„ ì¤‘...\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    # LayoutParser + Tesseract ë¶„ì„\n",
                "    analysis_result = extract_medical_data_with_layoutparser_tesseract(img_array, i)\n",
                "    \n",
                "    # ê²°ê³¼ ì €ì¥\n",
                "    if not analysis_result.empty:\n",
                "        # JSONìœ¼ë¡œ ì €ì¥\n",
                "        result_data = {\n",
                "            'page': i + 1,\n",
                "            'exam_date': analysis_result.attrs.get('exam_date', 'Not Found'),\n",
                "            'blood_tests': analysis_result.to_dict('records'),\n",
                "            'layout_analysis': analysis_result.attrs.get('layout_results', [])\n",
                "        }\n",
                "        \n",
                "        all_results.append(result_data)\n",
                "        \n",
                "        # í˜ì´ì§€ë³„ ê²°ê³¼ ì €ì¥\n",
                "        with open(f'output/page_{i+1}_layoutparser_tesseract_result.json', 'w', encoding='utf-8') as f:\n",
                "            json.dump(result_data, f, ensure_ascii=False, indent=2)\n",
                "        \n",
                "        print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥: output/page_{i+1}_layoutparser_tesseract_result.json\")\n",
                "    \n",
                "    print(f\"âœ… í˜ì´ì§€ {i + 1} ë¶„ì„ ì™„ë£Œ\")\n",
                "\n",
                "# ì „ì²´ ê²°ê³¼ í†µí•©\n",
                "if all_results:\n",
                "    # í†µí•© JSON ì €ì¥\n",
                "    final_result = {\n",
                "        'total_pages': len(pdf_images),\n",
                "        'processed_pages': len(all_results),\n",
                "        'processing_method': 'LayoutParser + Tesseract',\n",
                "        'timestamp': datetime.now().isoformat(),\n",
                "        'results': all_results\n",
                "    }\n",
                "    \n",
                "    with open('output/final_layoutparser_tesseract_analysis.json', 'w', encoding='utf-8') as f:\n",
                "        json.dump(final_result, f, ensure_ascii=False, indent=2)\n",
                "    \n",
                "    print(f\"\\nğŸ¯ ì „ì²´ ë¶„ì„ ì™„ë£Œ!\")\n",
                "    print(f\"ğŸ“Š ì²˜ë¦¬ëœ í˜ì´ì§€: {len(all_results)}/{len(pdf_images)}\")\n",
                "    print(f\"ğŸ’¾ ìµœì¢… ê²°ê³¼: output/final_layoutparser_tesseract_analysis.json\")\n",
                "    \n",
                "    # í†µê³„ ì¶œë ¥\n",
                "    total_blood_tests = sum(len(result['blood_tests']) for result in all_results)\n",
                "    print(f\"ğŸ§ª ì´ ì¶”ì¶œëœ í˜ˆì•¡ê²€ì‚¬ í•­ëª©: {total_blood_tests}ê°œ\")\n",
                "    \n",
                "    # ì¶”ì¶œëœ ê²€ì‚¬ì¼ì‹œë“¤\n",
                "    exam_dates = [result['exam_date'] for result in all_results if result['exam_date'] != 'Not Found']\n",
                "    if exam_dates:\n",
                "        print(f\"ğŸ“… ê²€ì‚¬ì¼ì‹œ: {', '.join(set(exam_dates))}\")\n",
                "    \n",
                "else:\n",
                "    print(\"âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "    print(\"ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ë³´ì„¸ìš”:\")\n",
                "    print(\"   - ì´ë¯¸ì§€ í’ˆì§ˆì´ ì¶©ë¶„í•œê°€?\")\n",
                "    print(\"   - Tesseractê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ê°€?\")\n",
                "    print(\"   - í•œêµ­ì–´ ì–¸ì–´íŒ©ì´ ì„¤ì¹˜ë˜ì—ˆëŠ”ê°€?\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ¨ ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”...\n",
                        "========================================\n",
                        "ğŸ“‘ í˜ì´ì§€ 1: ì‹œê°í™”í•  ë ˆì´ì•„ì›ƒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
                        "\n",
                        "âœ… ëª¨ë“  ì‹œê°í™” ì™„ë£Œ!\n",
                        "ğŸ“ output/ í´ë”ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
                    ]
                }
            ],
            "source": [
                "def visualize_layout_results(image: np.ndarray, layout_results: List[Dict], page_num: int):\n",
                "    \"\"\"LayoutParser ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
                "    \n",
                "    if not layout_results:\n",
                "        print(f\"ğŸ“‘ í˜ì´ì§€ {page_num + 1}: ì‹œê°í™”í•  ë ˆì´ì•„ì›ƒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "        return\n",
                "    \n",
                "    # ì´ë¯¸ì§€ ë³µì‚¬\n",
                "    vis_image = image.copy()\n",
                "    \n",
                "    # ìƒ‰ìƒ ì •ì˜ (BGR)\n",
                "    colors = {\n",
                "        'Text': (0, 255, 0),    # ë…¹ìƒ‰\n",
                "        'Title': (255, 0, 0),   # íŒŒë‘\n",
                "        'Table': (0, 0, 255),   # ë¹¨ê°•\n",
                "        'List': (255, 255, 0),  # ì²­ë¡\n",
                "        'Figure': (255, 0, 255) # ìí™\n",
                "    }\n",
                "    \n",
                "    # ê° ë ˆì´ì•„ì›ƒ ìš”ì†Œì— ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
                "    for result in layout_results:\n",
                "        bbox = result['bbox']\n",
                "        element_type = result['type']\n",
                "        \n",
                "        x1, y1, x2, y2 = bbox\n",
                "        color = colors.get(element_type, (128, 128, 128))\n",
                "        \n",
                "        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
                "        cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)\n",
                "        \n",
                "        # ë ˆì´ë¸” ì¶”ê°€\n",
                "        label = f\"{element_type}\"\n",
                "        cv2.putText(vis_image, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
                "    \n",
                "    # ì‹œê°í™” ê²°ê³¼ ì €ì¥\n",
                "    output_path = f\"output/page_{page_num + 1}_layout_visualization.png\"\n",
                "    cv2.imwrite(output_path, vis_image)\n",
                "    \n",
                "    print(f\"ğŸ–¼ï¸ ë ˆì´ì•„ì›ƒ ì‹œê°í™” ì €ì¥: {output_path}\")\n",
                "    print(f\"ğŸ“Š ê°ì§€ëœ ìš”ì†Œ: {', '.join([r['type'] for r in layout_results])}\")\n",
                "\n",
                "# ê° í˜ì´ì§€ì˜ ë ˆì´ì•„ì›ƒ ê²°ê³¼ ì‹œê°í™”\n",
                "if all_results:\n",
                "    print(\"ğŸ¨ ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”...\")\n",
                "    print(\"=\" * 40)\n",
                "    \n",
                "    for i, (img_array, result) in enumerate(zip(pdf_images, all_results)):\n",
                "        layout_results = result.get('layout_analysis', [])\n",
                "        visualize_layout_results(img_array, layout_results, i)\n",
                "    \n",
                "    print(\"\\nâœ… ëª¨ë“  ì‹œê°í™” ì™„ë£Œ!\")\n",
                "    print(\"ğŸ“ output/ í´ë”ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
                "else:\n",
                "    print(\"âš ï¸ ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. ì„±ëŠ¥ ë¹„êµ ë° ìš”ì•½\n",
                "\n",
                "### LayoutParser + Tesseract vs PaddleOCR ë¹„êµ\n",
                "\n",
                "| íŠ¹ì§• | LayoutParser + Tesseract | PaddleOCR |\n",
                "|------|-------------------------|----------|\n",
                "| **ë ˆì´ì•„ì›ƒ ì¸ì‹** | âœ… ìš°ìˆ˜ (êµ¬ì¡°í™”ëœ ë¬¸ì„œ ë¶„ì„) | âŒ ì œí•œì  |\n",
                "| **í…Œì´ë¸” ì²˜ë¦¬** | âœ… ë§¤ìš° ìš°ìˆ˜ | âš ï¸ ë³´í†µ |\n",
                "| **í•œêµ­ì–´ ì§€ì›** | âœ… ìš°ìˆ˜ (Tesseract í•œêµ­ì–´íŒ©) | âœ… ìš°ìˆ˜ |\n",
                "| **ì„¤ì¹˜ ë³µì¡ë„** | âš ï¸ ë³µì¡ (ì—¬ëŸ¬ ì˜ì¡´ì„±) | âœ… ê°„ë‹¨ |\n",
                "| **ì²˜ë¦¬ ì†ë„** | âš ï¸ ëŠë¦¼ (2ë‹¨ê³„ ì²˜ë¦¬) | âœ… ë¹ ë¦„ |\n",
                "| **ì •í™•ë„** | âœ… ë†’ìŒ (êµ¬ì¡° ê¸°ë°˜) | âš ï¸ ì¤‘ê°„ |\n",
                "| **ì˜ë£Œë¬¸ì„œ ì í•©ì„±** | âœ… ë§¤ìš° ì í•© | âš ï¸ ë³´í†µ ì í•© |\n",
                "\n",
                "### ê¶Œì¥ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤\n",
                "- **LayoutParser + Tesseract**: ë³µì¡í•œ ì˜ë£Œë¬¸ì„œ, ì •í™•í•œ í…Œì´ë¸” ì¶”ì¶œì´ í•„ìš”í•œ ê²½ìš°\n",
                "- **PaddleOCR**: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“Š LayoutParser + Tesseract ë¶„ì„ ì™„ë£Œ!\n",
                        "==================================================\n",
                        "\n",
                        "ğŸ¯ ì£¼ìš” ì„±ê³¼:\n",
                        "   ğŸ“„ ì²˜ë¦¬ëœ í˜ì´ì§€: 1ê°œ\n",
                        "   ğŸ§ª ì¶”ì¶œëœ í˜ˆì•¡ê²€ì‚¬: 2ê°œ\n",
                        "   ğŸ“Š ê°ì§€ëœ ë ˆì´ì•„ì›ƒ ìš”ì†Œ: 0ê°œ\n",
                        "\n",
                        "ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\n",
                        "   ğŸ“¸ output/*_preview.png - ì›ë³¸ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°\n",
                        "   ğŸ”§ output/processed_*.png - ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€\n",
                        "   ğŸ¨ output/*_layout_visualization.png - ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œê°í™”\n",
                        "   ğŸ“„ output/page_*_layoutparser_tesseract_result.json - í˜ì´ì§€ë³„ ê²°ê³¼\n",
                        "   ğŸ“‹ output/final_layoutparser_tesseract_analysis.json - ìµœì¢… í†µí•© ê²°ê³¼\n",
                        "\n",
                        "ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\n",
                        "   1. PaddleOCR ê²°ê³¼ì™€ ë¹„êµ ë¶„ì„\n",
                        "   2. ë” ì •í™•í•œ í›„ì²˜ë¦¬ ê·œì¹™ ê°œë°œ\n",
                        "   3. ì˜ë£Œì§„ ê²€í† ë¥¼ í†µí•œ ì •í™•ë„ ê²€ì¦\n",
                        "\n",
                        "âœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
                    ]
                }
            ],
            "source": [
                "print(\"ğŸ“Š LayoutParser + Tesseract ë¶„ì„ ì™„ë£Œ!\")\n",
                "print(\"=\" * 50)\n",
                "print(\"\\nğŸ¯ ì£¼ìš” ì„±ê³¼:\")\n",
                "print(f\"   ğŸ“„ ì²˜ë¦¬ëœ í˜ì´ì§€: {len(all_results) if all_results else 0}ê°œ\")\n",
                "if all_results:\n",
                "    total_tests = sum(len(r['blood_tests']) for r in all_results)\n",
                "    print(f\"   ğŸ§ª ì¶”ì¶œëœ í˜ˆì•¡ê²€ì‚¬: {total_tests}ê°œ\")\n",
                "    total_layouts = sum(len(r['layout_analysis']) for r in all_results)\n",
                "    print(f\"   ğŸ“Š ê°ì§€ëœ ë ˆì´ì•„ì›ƒ ìš”ì†Œ: {total_layouts}ê°œ\")\n",
                "\n",
                "print(\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\")\n",
                "print(\"   ğŸ“¸ output/*_preview.png - ì›ë³¸ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°\")\n",
                "print(\"   ğŸ”§ output/processed_*.png - ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€\")\n",
                "print(\"   ğŸ¨ output/*_layout_visualization.png - ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œê°í™”\")\n",
                "print(\"   ğŸ“„ output/page_*_layoutparser_tesseract_result.json - í˜ì´ì§€ë³„ ê²°ê³¼\")\n",
                "print(\"   ğŸ“‹ output/final_layoutparser_tesseract_analysis.json - ìµœì¢… í†µí•© ê²°ê³¼\")\n",
                "\n",
                "print(\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
                "print(\"   1. PaddleOCR ê²°ê³¼ì™€ ë¹„êµ ë¶„ì„\")\n",
                "print(\"   2. ë” ì •í™•í•œ í›„ì²˜ë¦¬ ê·œì¹™ ê°œë°œ\")\n",
                "print(\"   3. ì˜ë£Œì§„ ê²€í† ë¥¼ í†µí•œ ì •í™•ë„ ê²€ì¦\")\n",
                "\n",
                "print(\"\\nâœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Cat",
            "language": "python",
            "name": "cat-venv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
