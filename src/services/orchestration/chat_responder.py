"""ìŠ¤ëª°í†¡/ì¼ë°˜ ëŒ€í™” ì‘ë‹µê¸° (ChatResponder)

ì¼ë°˜ ëŒ€í™”, ê±´ê°• ì§ˆë¬¸ ë“±ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
ì¤‘ê°„ í’ˆì§ˆì˜ ëª¨ë¸(gpt-5-mini ë“±)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

from typing import TYPE_CHECKING, Iterator

from src.settings import settings
from src.services.llm.base import Message

from .models import OrchestrationContext

if TYPE_CHECKING:
    from src.services.llm.base import BaseLLMService


# ìŠ¤ëª°í†¡/ì¼ë°˜ ëŒ€í™”ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
CHAT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê°ì ì¸ ê³ ì–‘ì´ ê±´ê°• ìƒë‹´ ë„ìš°ë¯¸ 'ëƒ¥ë‹¥í„°'ì…ë‹ˆë‹¤.

## ê¸°ë³¸ ì„±ê²©
- ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤
- ê³ ì–‘ì´ì™€ ë°˜ë ¤ë™ë¬¼ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •ì„±ê» ë‹µë³€í•©ë‹ˆë‹¤

## ì¤‘ìš”í•œ ì•ˆì „ ìˆ˜ì¹™
- ì§ì ‘ì ì¸ ì˜ë£Œ ì§„ë‹¨ì´ë‚˜ ì²˜ë°©ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- ì‘ê¸‰ ìƒí™©ì´ ì˜ì‹¬ë˜ë©´ ì¦‰ì‹œ ë™ë¬¼ë³‘ì› ë°©ë¬¸ì„ ê¶Œìœ í•©ë‹ˆë‹¤
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "í™•ì‹¤í•˜ì§€ ì•Šë‹¤"ê³  ëª…ì‹œí•©ë‹ˆë‹¤
- ëª¨ë“  ê±´ê°• ê´€ë ¨ ì¡°ì–¸ì€ "ì°¸ê³ ìš©"ì„ì„ ì•ˆë‚´í•©ë‹ˆë‹¤

## ëŒ€í™” ìŠ¤íƒ€ì¼
- ì§§ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
- í•„ìš”ì‹œ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤ ğŸ±
- ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•´ ìƒí™©ì„ ë” ì˜ ì´í•´í•˜ë ¤ í•©ë‹ˆë‹¤
"""

# ì‘ê¸‰ ìƒí™© ëŒ€ì‘ í”„ë¡¬í”„íŠ¸
EMERGENCY_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê³ ì–‘ì´ ê±´ê°• ìƒë‹´ ë„ìš°ë¯¸ 'ëƒ¥ë‹¥í„°'ì…ë‹ˆë‹¤.

## ğŸš¨ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨
ì‚¬ìš©ìê°€ ì‘ê¸‰ ìƒí™©ì„ ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:

1. **ì¦‰ì‹œ ë™ë¬¼ë³‘ì› ë°©ë¬¸ì„ ê°•ë ¥íˆ ê¶Œìœ **í•˜ì„¸ìš”
2. ê°€ëŠ¥í•œ ì‘ê¸‰ ì¡°ì¹˜ë¥¼ ê°„ë‹¨íˆ ì•ˆë‚´í•˜ë˜, **ì ˆëŒ€ ì§„ë‹¨/ì²˜ë°©í•˜ì§€ ë§ˆì„¸ìš”**
3. 24ì‹œê°„ ë™ë¬¼ë³‘ì›ì´ë‚˜ ì‘ê¸‰ì‹¤ì„ ì°¾ë„ë¡ ì•ˆë‚´í•˜ì„¸ìš”
4. ì¹¨ì°©í•˜ë˜ ê¸´ê¸‰í•¨ì„ ì „ë‹¬í•˜ì„¸ìš”

ì‘ê¸‰ ìƒí™© ì˜ˆì‹œ: í˜¸í¡ê³¤ë€, ê²½ë ¨, ì˜ì‹ë¶ˆëª…, ì‹¬í•œ ì¶œí˜ˆ, ì¤‘ë… ì˜ì‹¬
"""


class ChatResponder:
    """ìŠ¤ëª°í†¡/ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„±ê¸°"""

    def __init__(self, llm_service: "BaseLLMService"):
        """
        Args:
            llm_service: LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
        """
        self.llm_service = llm_service
        self.model = settings.openai_model_chat

    def generate(
        self,
        context: OrchestrationContext,
        is_emergency: bool = False,
    ) -> str:
        """ì‘ë‹µ ìƒì„± (ë…¼-ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸
            is_emergency: ì‘ê¸‰ ìƒí™© ì—¬ë¶€

        Returns:
            ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        messages = self._build_messages(context, is_emergency)

        response = self.llm_service.generate(
            messages=messages,
            model=self.model,
        )

        return response.content

    def stream_generate(
        self,
        context: OrchestrationContext,
        is_emergency: bool = False,
    ) -> Iterator[str]:
        """ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸
            is_emergency: ì‘ê¸‰ ìƒí™© ì—¬ë¶€

        Yields:
            ì‘ë‹µ í…ìŠ¤íŠ¸ ì¡°ê°
        """
        messages = self._build_messages(context, is_emergency)

        yield from self.llm_service.stream_generate(
            messages=messages,
            model=self.model,
        )

    def _build_messages(
        self,
        context: OrchestrationContext,
        is_emergency: bool = False,
    ) -> list[Message]:
        """LLM ë©”ì‹œì§€ êµ¬ì„±

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸
            is_emergency: ì‘ê¸‰ ìƒí™© ì—¬ë¶€

        Returns:
            Message ë¦¬ìŠ¤íŠ¸
        """
        messages = []

        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = EMERGENCY_SYSTEM_PROMPT if is_emergency else CHAT_SYSTEM_PROMPT
        messages.append(Message(role="system", content=system_prompt))

        # 2. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¬í•¨ (ì¼ë°˜ ëŒ€í™”ì—ì„œë„ ì°¸ì¡° ê°€ëŠ¥)
        if context.has_document and context.document_context:
            messages.append(Message(
                role="user",
                content=f"[ì°¸ê³ : ì—…ë¡œë“œëœ ê²€ì§„ ê²°ê³¼]\n{context.document_context}"
            ))
            messages.append(Message(
                role="assistant",
                content="ë„¤, ê²€ì§„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ê² ìŠµë‹ˆë‹¤."
            ))

        # 3. ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬
        for msg in context.chat_history:
            messages.append(Message(role=msg["role"], content=msg["content"]))

        # 4. í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        messages.append(Message(role="user", content=context.user_input))

        return messages

