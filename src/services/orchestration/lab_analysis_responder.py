"""ê²€ì‚¬ì§€ ë¶„ì„ ì‘ë‹µê¸° (LabAnalysisResponder)

OCRë¡œ ì¶”ì¶œëœ ê²€ì§„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•©ë‹ˆë‹¤.
ê³ í’ˆì§ˆ ëª¨ë¸(gpt-4.1 ë“±)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

from typing import TYPE_CHECKING, Iterator

from src.settings import settings
from src.services.llm.base import Message

from .models import OrchestrationContext

if TYPE_CHECKING:
    from src.services.llm.base import BaseLLMService


# ê²€ì‚¬ì§€ ë¶„ì„ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
LAB_ANALYSIS_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê°ì ì¸ ê³ ì–‘ì´ ê±´ê°• ìƒë‹´ ë„ìš°ë¯¸ 'ëƒ¥ë‹¥í„°'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ê³ ì–‘ì´ì˜ ê±´ê°•ê²€ì§„ ê²°ê³¼ì§€ë¥¼ ì—…ë¡œë“œí–ˆê³ , ì´ì— ëŒ€í•œ ë¶„ì„ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.

## ì—­í• 
- OCRë¡œ ì¶”ì¶œëœ ê²€ì‚¬ ê²°ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´**ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤
- ê° ê²€ì‚¬ í•­ëª©ì´ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€, ì •ìƒ ë²”ìœ„ì™€ ë¹„êµí•´ ì–´ë–¤ ìƒíƒœì¸ì§€ ì„¤ëª…í•©ë‹ˆë‹¤
- ìˆ˜ì¹˜ê°€ ë†’ê±°ë‚˜ ë‚®ì€ í•­ëª©ì´ ìˆë‹¤ë©´ **ë¬´ì—‡ì„ ì˜ë¯¸í•  ìˆ˜ ìˆëŠ”ì§€** ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤

ìˆ˜ì˜ ë‚´ê³¼ ì „ë¬¸ì˜ë¡œì„œ, ì œê³µëœ ê²€ì‚¬ê²°ê³¼ í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•ˆì •ì ì´ê³  ì¬í˜„ ê°€ëŠ¥í•œ í•´ì„ì„ ì‘ì„±í•©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì•„ë˜ ì¶œë ¥ í˜•ì‹ì„ ì§€í‚¤ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹
1) **ë°ì´í„°í”„ë ˆì„ í‘œ** (ë§ˆí¬ë‹¤ìš´ í‘œ í—ˆìš©): ì»¬ëŸ¼ = [í•­ëª©, ê°’, ë‹¨ìœ„, ì°¸ê³ ë²”ìœ„, ì •ìƒì—¬ë¶€, ë°©í–¥, ì¤‘ì¦ë„]
   - ì •ìƒì—¬ë¶€: ì •ìƒ | ë¹„ì •ìƒ | ë¶ˆëª…(ë²”ìœ„ ì—†ìŒ)
   - ë°©í–¥: â†‘(ìƒ) | â†“(í•˜) | -
   - ì¤‘ì¦ë„: ê²½ë„ | ì¤‘ë“±ë„ | ì¤‘ì¦ (í•„ìš” ì‹œ)

2) **ì¢…í•© ì„ìƒ íŒë‹¨ê³¼ ì†Œê²¬**:
   - ë³‘íƒœìƒë¦¬
   - ê°ë³„ì§„ë‹¨ í›„ë³´
   - ê¶Œì¥ ì¶”ê°€ê²€ì‚¬ ë° ê´€ë¦¬
   - ì£¼ì˜ì‚¬í•­ ë° í•œê³„

## íŒì • ê·œì¹™
- ìš°ì„  ë¦¬í¬íŠ¸ì— í¬í•¨ëœ ì°¸ê³ ë²”ìœ„(reference_min/max ë˜ëŠ” low/high/reference_range)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ìƒ/ì´ìƒ íŒì •
- ë²”ìœ„ê°€ ëˆ„ë½ë˜ë©´ 'ë¶ˆëª…(ë²”ìœ„ ì—†ìŒ)'ìœ¼ë¡œ í‘œê¸°í•˜ê³  ì†Œê²¬ì—ì„œ ì¶œì²˜ ë¶€ì¡±ì„ ëª…ì‹œ
- ë‹¨ìœ„ê°€ ì˜ì‹¬ë˜ë©´ ë³€í™˜ í›„ë³´ë§Œ ì œì‹œí•˜ê³ , ì› ë‹¨ìœ„ë¥¼ ìœ ì§€í•˜ì—¬ ì‹ ì¤‘íˆ ê¸°ìˆ 
- ì‘ê¸‰/ì¤‘ì¦ ì„ê³„ê°’ì€ ë³´ìˆ˜ì ìœ¼ë¡œ í‘œì‹œí•˜ë˜ ê³¼ì¥ ê¸ˆì§€

## ì¤‘ìš”í•œ ì•ˆì „ ìˆ˜ì¹™ (ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”)
1. **ì ˆëŒ€ë¡œ ì§ì ‘ ì§„ë‹¨í•˜ì§€ ë§ˆì„¸ìš”**: "~ë³‘ì…ë‹ˆë‹¤", "~ì§ˆí™˜ì´ ìˆìŠµë‹ˆë‹¤" ê°™ì€ í™•ì •ì  ì§„ë‹¨ ê¸ˆì§€
2. **ì ˆëŒ€ë¡œ ì²˜ë°©í•˜ì§€ ë§ˆì„¸ìš”**: ì•½ë¬¼, ì¹˜ë£Œë²•, ìš©ëŸ‰ ë“±ì„ ê¶Œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
3. **ì‘ê¸‰ ì§•í›„ ì‹œ ì¦‰ì‹œ ë³‘ì› ê¶Œìœ **: ìœ„í—˜í•´ ë³´ì´ëŠ” ìˆ˜ì¹˜ê°€ ìˆìœ¼ë©´ "ë™ë¬¼ë³‘ì› ë°©ë¬¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
4. **ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ**: "~ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤", "ìˆ˜ì˜ì‚¬ì™€ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤" ë“±ìœ¼ë¡œ í‘œí˜„
5. **ì°¸ê³ ìš©ì„ì„ ì•ˆë‚´**: ë§ˆì§€ë§‰ì— "ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì§„ë‹¨ì€ ìˆ˜ì˜ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”"


## ëŒ€í™” ìŠ¤íƒ€ì¼
- ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤
- í•„ìš”ì‹œ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤ ğŸ±
- ê³µê°ì ì´ê³  ì•ˆì‹¬ì‹œí‚¤ëŠ” í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤
"""


class LabAnalysisResponder:
    """ê²€ì‚¬ì§€ ë¶„ì„ ì‘ë‹µ ìƒì„±ê¸°"""

    def __init__(self, llm_service: "BaseLLMService"):
        """
        Args:
            llm_service: LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
        """
        self.llm_service = llm_service
        self.model = settings.openai_model_analysis

    def generate(self, context: OrchestrationContext) -> str:
        """ì‘ë‹µ ìƒì„± (ë…¼-ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸ (document_context í•„ìˆ˜)

        Returns:
            ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        messages = self._build_messages(context)

        response = self.llm_service.generate(
            messages=messages,
            model=self.model,
        )

        return response.content

    def stream_generate(self, context: OrchestrationContext) -> Iterator[str]:
        """ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸ (document_context í•„ìˆ˜)

        Yields:
            ì‘ë‹µ í…ìŠ¤íŠ¸ ì¡°ê°
        """
        messages = self._build_messages(context)

        yield from self.llm_service.stream_generate(
            messages=messages,
            model=self.model,
        )

    def _build_messages(self, context: OrchestrationContext) -> list[Message]:
        """LLM ë©”ì‹œì§€ êµ¬ì„±

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸

        Returns:
            Message ë¦¬ìŠ¤íŠ¸
        """
        messages = []

        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        messages.append(Message(role="system", content=LAB_ANALYSIS_SYSTEM_PROMPT))

        # 2. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ (í•„ìˆ˜)
        if context.document_context:
            messages.append(Message(
                role="user",
                content=f"[ê²€ì§„ ê²°ê³¼ì§€ ë°ì´í„°]\n{context.document_context}"
            ))
            messages.append(Message(
                role="assistant",
                content="ê²€ì§„ ê²°ê³¼ì§€ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë¶„ì„í•´ ë“œë¦´ê²Œìš”."
            ))

        # 3. ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬
        for msg in context.chat_history:
            messages.append(Message(role=msg["role"], content=msg["content"]))

        # 4. í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        messages.append(Message(role="user", content=context.user_input))

        return messages

