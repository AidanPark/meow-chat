"""ë¼ìš°í„°/ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Router)

ì˜ë„ ë¶„ë¥˜ ê²°ê³¼ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ Responderë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
"""

from typing import TYPE_CHECKING, Iterator, Callable

from .models import Intent, IntentType, OrchestrationContext
from .intent_classifier import IntentClassifier
from .chat_responder import ChatResponder
from .lab_analysis_responder import LabAnalysisResponder

if TYPE_CHECKING:
    from src.services.llm.base import BaseLLMService


class Router:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¼ìš°í„°

    ì˜ë„ë¶„ë¥˜ â†’ ë¼ìš°íŒ… â†’ ì‘ë‹µìƒì„± íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """

    def __init__(self, llm_service: "BaseLLMService"):
        """
        Args:
            llm_service: LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
        """
        self.llm_service = llm_service

        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.intent_classifier = IntentClassifier(llm_service)
        self.chat_responder = ChatResponder(llm_service)
        self.lab_analysis_responder = LabAnalysisResponder(llm_service)

    def classify_intent(self, user_input: str) -> Intent:
        """ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥

        Returns:
            Intent ê°ì²´
        """
        return self.intent_classifier.classify(user_input)

    def route(
        self,
        context: OrchestrationContext,
    ) -> tuple[str, Callable[[], Iterator[str]]]:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ Responderë¡œ ë¼ìš°íŒ…

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸

        Returns:
            (route_type, stream_generator_factory) íŠœí”Œ
            - route_type: "chat", "analysis", "upload_guide", "emergency" ì¤‘ í•˜ë‚˜
            - stream_generator_factory: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±ê¸°ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        """
        intent = context.intent

        if intent is None:
            # ì˜ë„ ë¶„ë¥˜ê°€ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ë¨¼ì € ë¶„ë¥˜
            intent = self.classify_intent(context.user_input)
            context.intent = intent

        # ë¼ìš°íŒ… ê²°ì •
        route_type, stream_factory = self._decide_route(context)

        return route_type, stream_factory

    def _decide_route(
        self,
        context: OrchestrationContext,
    ) -> tuple[str, Callable[[], Iterator[str]]]:
        """ë¼ìš°íŒ… ê²°ì • ë¡œì§

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸

        Returns:
            (route_type, stream_generator_factory) íŠœí”Œ
        """
        intent = context.intent
        intent_type = intent.intent_type

        # 1. ì‘ê¸‰ ìƒí™© â†’ ì‘ê¸‰ ëŒ€ì‘ (ChatResponder with emergency flag)
        if intent_type == IntentType.EMERGENCY:
            return "emergency", lambda: self.chat_responder.stream_generate(
                context, is_emergency=True
            )

        # 2. ê²€ì‚¬ì§€ ë¶„ì„ ìš”ì²­
        if intent_type == IntentType.LAB_ANALYSIS:
            # ë¬¸ì„œê°€ ìˆìœ¼ë©´ ë¶„ì„ ìˆ˜í–‰
            if context.has_document:
                return "analysis", lambda: self.lab_analysis_responder.stream_generate(
                    context
                )
            # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì—…ë¡œë“œ ì•ˆë‚´
            else:
                return "upload_guide", lambda: iter([self._get_upload_guide_message()])

        # 3. ì—…ë¡œë“œ ë°©ë²• ë¬¸ì˜
        if intent_type == IntentType.UPLOAD_HELP:
            return "upload_guide", lambda: iter([self._get_upload_help_message()])

        # 4. ì¼ë°˜ ê±´ê°• ì§ˆë¬¸ (ë¬¸ì„œ ìˆìœ¼ë©´ ì°¸ì¡°)
        if intent_type == IntentType.HEALTH_QUESTION:
            return "chat", lambda: self.chat_responder.stream_generate(context)

        # 5. ìŠ¤ëª°í†¡ / ê¸°íƒ€
        return "chat", lambda: self.chat_responder.stream_generate(context)

    def process(self, context: OrchestrationContext) -> Iterator[str]:
        """ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸

        Yields:
            ì‘ë‹µ í…ìŠ¤íŠ¸ ì¡°ê°
        """
        # 1. ì˜ë„ ë¶„ë¥˜
        if context.intent is None:
            context.intent = self.classify_intent(context.user_input)

        # 2. ë¼ìš°íŒ… ë° ì‘ë‹µ ìƒì„±
        route_type, stream_factory = self.route(context)

        # 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
        yield from stream_factory()

    def process_sync(self, context: OrchestrationContext) -> str:
        """ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë…¼-ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        # ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ ë°˜í™˜
        chunks = list(self.process(context))
        return "".join(chunks)

    def _get_upload_guide_message(self) -> str:
        """ê²€ì‚¬ì§€ ë¶„ì„ ìš”ì²­ ì‹œ ì—…ë¡œë“œ ì•ˆë‚´ ë©”ì‹œì§€"""
        return (
            "ğŸ” **ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”!**\n\n"
            "ê²€ì§„ ê²°ê³¼ì§€ë¥¼ ë¶„ì„í•˜ë ¤ë©´ ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.\n\n"
            "**ì—…ë¡œë“œ ë°©ë²•:**\n"
            "1. ì•„ë˜ 'ğŸ“ ê²€ì§„ ê²°ê³¼ì§€ ì²¨ë¶€' ë²„íŠ¼ì„ í´ë¦­\n"
            "2. ê²€ì§„ ê²°ê³¼ì§€ ì´ë¯¸ì§€(JPG, PNG) ë˜ëŠ” PDF ì„ íƒ\n"
            "3. 'ğŸš€ Send' ë²„íŠ¼ìœ¼ë¡œ ì „ì†¡\n\n"
            "ì¼ë°˜ì ì¸ ê±´ê°• ìƒë‹´ì„ ì›í•˜ì‹œë©´ ê·¸ëƒ¥ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
        )

    def _get_upload_help_message(self) -> str:
        """ì—…ë¡œë“œ ë°©ë²• ì•ˆë‚´ ë©”ì‹œì§€"""
        return (
            "ğŸ“ **íŒŒì¼ ì—…ë¡œë“œ ë°©ë²•ì„ ì•ˆë‚´í•´ ë“œë¦´ê²Œìš”!**\n\n"
            "1. í™”ë©´ ì•„ë˜ìª½ì˜ 'ğŸ“ ê²€ì§„ ê²°ê³¼ì§€ ì²¨ë¶€' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”\n"
            "2. ê³ ì–‘ì´ ê±´ê°•ê²€ì§„ ê²°ê³¼ì§€ ì´ë¯¸ì§€ë‚˜ PDFë¥¼ ì„ íƒí•˜ì„¸ìš”\n"
            "   - ì§€ì› í˜•ì‹: JPG, JPEG, PNG, PDF, WEBP\n"
            "3. ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  'ğŸš€ Send' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”\n\n"
            "**íŒ:** ğŸ“· ì‚¬ì§„ì€ ë°ê³  ì„ ëª…í•˜ê²Œ ì°ì–´ì£¼ì„¸ìš”!\n"
            "ê¸€ì”¨ê°€ ì˜ ë³´ì¼ìˆ˜ë¡ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•´ìš” ğŸ±"
        )

    def get_route_info(self, context: OrchestrationContext) -> dict:
        """ë¼ìš°íŒ… ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…/ë¡œê¹…ìš©)

        Args:
            context: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ë¼ìš°íŒ… ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if context.intent is None:
            context.intent = self.classify_intent(context.user_input)

        route_type, _ = self.route(context)

        return {
            "intent_type": context.intent.intent_type.value,
            "confidence": context.intent.confidence,
            "has_document": context.has_document,
            "route_type": route_type,
            "intent_model": self.intent_classifier.model,
            "chat_model": self.chat_responder.model,
            "analysis_model": self.lab_analysis_responder.model,
        }

